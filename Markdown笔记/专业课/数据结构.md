---
title: 数据结构
chrome:
    format: "A4"
    headerTemplate: '<div></div>'
    footerTemplate: '<div style="width:100%; text-align:center; border-top: 1pt solid #eeeeee; margin:  10px 10px 20px; font-size: 8pt;"> 
    <span class=pageNumber></span> / <span class=totalPages></span></div>'
    displayHeaderFooter: true
    margin:
        top: '40px'
        bottom: '80px'
        left: '60px'
        right: '60px'
---

<h1>数据结构</h1>

<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [第1章 绪论](#第1章-绪论)
  - [1.1 数据结构的研究内容](#11-数据结构的研究内容)
  - [1.2 基本概念和术语](#12-基本概念和术语)
    - [1.2.1 数据、数据元素、数据项和数据对象](#121-数据-数据元素-数据项和数据对象)
    - [1.2.2 数据结构](#122-数据结构)
      - [1.2.2.1 逻辑结构](#1221-逻辑结构)
      - [1.2.2.2 存储结构](#1222-存储结构)
    - [1.2.3 数据类型和抽象数据类型](#123-数据类型和抽象数据类型)
  - [1.3 抽象数据类型的表示与实现](#13-抽象数据类型的表示与实现)
  - [1.4 算法和算法分析](#14-算法和算法分析)
    - [1.4.1 算法的定义及特性](#141-算法的定义及特性)
    - [1.4.2 评价算法优劣的基本标准](#142-评价算法优劣的基本标准)
    - [1.4.3 算法的时间复杂度](#143-算法的时间复杂度)
      - [1.4.3.1 问题规模和语句频度](#1431-问题规模和语句频度)
      - [1.4.3.2 算法的时间复杂度定义](#1432-算法的时间复杂度定义)
      - [1.4.3.3 算法的时间复杂度分析](#1433-算法的时间复杂度分析)
      - [1.4.3.4 最好、最坏和平均时间复杂度](#1434-最好-最坏和平均时间复杂度)
    - [1.4.4 算法的空间复杂度](#144-算法的空间复杂度)
- [第2章 线性表](#第2章-线性表)
  - [2.1 线性表的定义和特点](#21-线性表的定义和特点)
  - [2.2 线性表的类型定义](#22-线性表的类型定义)
  - [2.3 线性表的顺序表示和实现](#23-线性表的顺序表示和实现)
    - [2.3.1 线性表的顺序存储表示](#231-线性表的顺序存储表示)
    - [2.3.2 顺序表中基本操作的实现](#232-顺序表中基本操作的实现)
      - [2.3.2.1 初始化](#2321-初始化)
      - [2.3.2.2 取值](#2322-取值)
      - [2.3.2.3 查找](#2323-查找)
      - [2.3.2.4 插入](#2324-插入)
      - [2.3.2.5 删除](#2325-删除)
  - [2.4 线性表的链式表示和实现](#24-线性表的链式表示和实现)
    - [2.4.1 单链表的定义和表示](#241-单链表的定义和表示)
    - [2.4.2 单链表基本操作的实现](#242-单链表基本操作的实现)
      - [2.4.2.1 初始化](#2421-初始化)
      - [2.4.2.2 取值](#2422-取值)
      - [2.4.2.3 查找](#2423-查找)
      - [2.4.2.4 插入](#2424-插入)
      - [2.4.2.5 删除](#2425-删除)
      - [2.4.2.6 创建单链表](#2426-创建单链表)
    - [2.4.3 循环链表](#243-循环链表)
    - [2.4.4 双向链表](#244-双向链表)
  - [2.5 顺序表和链表的比较](#25-顺序表和链表的比较)
    - [2.5.1 空间性能的比较](#251-空间性能的比较)
    - [2.5.2 时间性能的比较](#252-时间性能的比较)
  - [2.6 线性表的应用](#26-线性表的应用)
    - [2.6.1 线性表的合并](#261-线性表的合并)
    - [2.6.2 有序表的合并](#262-有序表的合并)
    - [2.6.3 一元多项式的运算](#263-一元多项式的运算)
    - [2.6.4 稀疏多项式的运算](#264-稀疏多项式的运算)
- [第3章 栈和队列](#第3章-栈和队列)
  - [3.1 栈](#31-栈)
    - [3.1.1 栈的定义和特点](#311-栈的定义和特点)
    - [3.1.2 栈的类型定义](#312-栈的类型定义)
    - [3.1.3 顺序栈的表示和实现](#313-顺序栈的表示和实现)
    - [3.1.4 链栈的表示和实现](#314-链栈的表示和实现)
  - [3.2 栈与递归](#32-栈与递归)
    - [3.2.1 采用递归算法解决的问题](#321-采用递归算法解决的问题)
      - [3.2.1.1 定义是递归的](#3211-定义是递归的)
      - [3.2.1.2 数据结构是递归的](#3212-数据结构是递归的)
      - [3.2.1.3 问题的解法是递归的](#3213-问题的解法是递归的)
    - [3.2.2 递归过程与递归工作栈](#322-递归过程与递归工作栈)
    - [3.2.3 递归算法的效率分析](#323-递归算法的效率分析)
      - [3.2.3.1 时间复杂度的分析](#3231-时间复杂度的分析)
      - [3.2.3.2 空间复杂度的分析](#3232-空间复杂度的分析)
    - [3.2.4 利用栈将递归转换为非递归的方法](#324-利用栈将递归转换为非递归的方法)
  - [3.3 队列](#33-队列)
    - [3.3.1 队列的定义和特点](#331-队列的定义和特点)
    - [3.3.2 队列的类型定义](#332-队列的类型定义)
    - [3.3.3 循环队列——队列的顺序表示和实现](#333-循环队列队列的顺序表示和实现)
    - [3.3.4 链队——队列的链式表示和实现](#334-链队队列的链式表示和实现)
  - [3.4 栈和队列的应用](#34-栈和队列的应用)
    - [3.4.1 数制转换](#341-数制转换)
    - [3.4.2 括号匹配的检验](#342-括号匹配的检验)
    - [3.4.3 表达式求值](#343-表达式求值)
- [第4章 串、数组和广义表](#第4章-串-数组和广义表)
  - [4.1 串](#41-串)
    - [4.1.1 串的定义](#411-串的定义)
    - [4.1.2 串的抽象类型定义](#412-串的抽象类型定义)
    - [4.1.3 串的存储结构](#413-串的存储结构)
      - [4.1.3.1 串的顺序存储](#4131-串的顺序存储)
      - [4.1.3.2 串的链式存储](#4132-串的链式存储)
    - [4.1.4 串的模式匹配算法](#414-串的模式匹配算法)
      - [4.1.4.1 BF（Brute-Force）算法](#4141-bfbrute-force算法)
      - [4.1.4.2 KMP算法](#4142-kmp算法)
  - [4.2 数组](#42-数组)
    - [4.2.1 数组的类型定义](#421-数组的类型定义)
    - [4.2.2 数组的顺序存储](#422-数组的顺序存储)
    - [4.2.3 矩阵的数组表示](#423-矩阵的数组表示)
    - [4.2.4 特殊矩阵的压缩存储](#424-特殊矩阵的压缩存储)
      - [4.2.4.1 对称矩阵](#4241-对称矩阵)
      - [4.2.4.2 三角矩阵](#4242-三角矩阵)
      - [4.2.4.3 对角矩阵](#4243-对角矩阵)
      - [4.2.4.4 稀疏矩阵](#4244-稀疏矩阵)
  - [4.3 广义表](#43-广义表)
    - [4.3.1 广义表的定义](#431-广义表的定义)
    - [4.3.2 广义表的存储结构](#432-广义表的存储结构)
      - [4.3.2.1 头尾链表的存储结构](#4321-头尾链表的存储结构)
      - [4.3.2.2 扩展线性链表的存储结构](#4322-扩展线性链表的存储结构)
  - [4.4 环状模式串的模式匹配](#44-环状模式串的模式匹配)
- [第5章 树和二叉树](#第5章-树和二叉树)
  - [5.1 树的基本概念](#51-树的基本概念)
    - [5.1.1 树的定义](#511-树的定义)
    - [5.1.2 树的基本术语](#512-树的基本术语)
  - [5.2 二叉树](#52-二叉树)
    - [5.2.1 二叉树的定义](#521-二叉树的定义)
    - [5.2.2 二叉树的抽象数据类型定义](#522-二叉树的抽象数据类型定义)
    - [5.2.3 二叉树的性质](#523-二叉树的性质)
    - [5.2.4 二叉树的存储结构](#524-二叉树的存储结构)
      - [5.2.4.1 顺序存储结构](#5241-顺序存储结构)
      - [5.2.4.2 链式存储结构](#5242-链式存储结构)
    - [5.2.5 二叉树的遍历](#525-二叉树的遍历)
      - [5.2.5.1 遍历二叉树算法描述](#5251-遍历二叉树算法描述)
      - [5.2.5.2 根据遍历序列确定二叉树](#5252-根据遍历序列确定二叉树)
      - [5.2.5.3 二叉树遍历算法的应用](#5253-二叉树遍历算法的应用)
  - [5.3 线索二叉树](#53-线索二叉树)
    - [5.3.1 线索二叉树的基本概念](#531-线索二叉树的基本概念)
    - [5.3.2 构造线索二叉树](#532-构造线索二叉树)
    - [5.3.3 遍历线索二叉树](#533-遍历线索二叉树)
  - [5.4 树和森林](#54-树和森林)
    - [5.4.1 树的抽象数据类型定义](#541-树的抽象数据类型定义)
    - [5.4.2 树的存储结构](#542-树的存储结构)
      - [5.4.2.1 双亲表示法](#5421-双亲表示法)
      - [5.4.2.2 孩子表示法](#5422-孩子表示法)
      - [5.4.2.3 孩子兄弟法](#5423-孩子兄弟法)
    - [5.4.3 树与二叉树的转换](#543-树与二叉树的转换)
      - [5.4.3.1 树转换成二叉树](#5431-树转换成二叉树)
      - [5.4.3.2 二叉树转换成树](#5432-二叉树转换成树)
      - [5.4.3.3 森林转换成二叉树](#5433-森林转换成二叉树)
      - [5.4.3.4 二叉树转换成森林](#5434-二叉树转换成森林)
    - [5.4.4 树和森林的遍历](#544-树和森林的遍历)
      - [5.4.4.1 树的遍历](#5441-树的遍历)
      - [5.4.4.2 森林的遍历](#5442-森林的遍历)
    - [5.4.5 树的顺序表示](#545-树的顺序表示)
  - [5.5 哈夫曼树及其应用](#55-哈夫曼树及其应用)
    - [5.5.1 哈夫曼树的基本概念](#551-哈夫曼树的基本概念)
    - [5.5.2 哈夫曼树的构造算法](#552-哈夫曼树的构造算法)
    - [5.5.3 哈夫曼编码](#553-哈夫曼编码)
  - [5.6 树和二叉树的应用](#56-树和二叉树的应用)
    - [5.6.1 表达式求值](#561-表达式求值)
    - [5.6.2 并查集](#562-并查集)
      - [5.6.2.1 并查集的定义](#5621-并查集的定义)
      - [5.6.2.2 并查集的实现](#5622-并查集的实现)
      - [5.6.2.3 并查集的优化](#5623-并查集的优化)
      - [5.6.2.4 等价类](#5624-等价类)
- [第6章 图](#第6章-图)
  - [6.1 图的定义和基本术语](#61-图的定义和基本术语)
    - [6.1.1 图的定义](#611-图的定义)
    - [6.1.2 图的基本术语](#612-图的基本术语)
  - [6.2 图的类型定义](#62-图的类型定义)
  - [6.3 图的存储结构](#63-图的存储结构)
    - [6.3.1 邻接矩阵](#631-邻接矩阵)
    - [6.3.2 邻接表](#632-邻接表)
    - [6.3.3 十字链表](#633-十字链表)
    - [6.3.4 邻接多重表](#634-邻接多重表)
  - [6.4 图的遍历](#64-图的遍历)
    - [6.4.1 深度优先搜索](#641-深度优先搜索)
    - [6.4.2 广度优先搜索](#642-广度优先搜索)
  - [6.5 图的应用](#65-图的应用)
    - [6.5.1 最小生成树](#651-最小生成树)
      - [6.5.1.1 普里姆（Prim）算法](#6511-普里姆prim算法)
      - [6.5.1.2 克鲁斯卡尔（Kruskal）算法](#6512-克鲁斯卡尔kruskal算法)
    - [6.5.2 最短路径](#652-最短路径)
      - [6.5.2.1 从某个源点到其余各顶点的最短路径](#6521-从某个源点到其余各顶点的最短路径)
      - [6.5.2.2 每一对顶点之间的最短路径](#6522-每一对顶点之间的最短路径)
    - [6.5.3 拓扑排序](#653-拓扑排序)
    - [6.5.4 关键路径](#654-关键路径)
    - [6.5.5 可及性及传递闭包算法](#655-可及性及传递闭包算法)
    - [6.5.6 连通分量](#656-连通分量)
- [第7章 查找](#第7章-查找)
  - [7.1 查找的基本概念](#71-查找的基本概念)
  - [7.2 线性表的查找](#72-线性表的查找)
    - [7.2.1 顺序查找](#721-顺序查找)
    - [7.2.2 折半查找](#722-折半查找)
    - [7.2.3 分块查找](#723-分块查找)
  - [7.3 树表的查找](#73-树表的查找)
    - [7.3.1 二叉排序树](#731-二叉排序树)
      - [7.3.1.1 二叉排序树的定义](#7311-二叉排序树的定义)
      - [7.3.1.2 二叉排序树的查找](#7312-二叉排序树的查找)
      - [7.3.1.3 二叉排序树的插入](#7313-二叉排序树的插入)
      - [7.3.1.4 二叉排序树的创建](#7314-二叉排序树的创建)
      - [7.3.1.5 二叉排序树的删除](#7315-二叉排序树的删除)
    - [7.3.2 平衡二叉树](#732-平衡二叉树)
      - [7.3.2.1 平衡二叉树的定义](#7321-平衡二叉树的定义)
      - [7.3.2.2 平衡二叉树的平衡调整方法](#7322-平衡二叉树的平衡调整方法)
      - [7.3.2.3 平衡二叉树的插入](#7323-平衡二叉树的插入)
    - [7.3.3 B-树](#733-b-树)
      - [7.3.3.1 B-树的定义](#7331-b-树的定义)
      - [7.3.3.2 B-树的查找](#7332-b-树的查找)
      - [7.3.3.3 B-树的插入](#7333-b-树的插入)
      - [7.3.3.4 B-树的删除](#7334-b-树的删除)
    - [7.3.4 B+树](#734-b树)
  - [7.4 散列表的查找](#74-散列表的查找)
    - [7.4.1 散列表的基本概念](#741-散列表的基本概念)
    - [7.4.2 散列函数的构造方法](#742-散列函数的构造方法)
      - [7.4.2.1 数字分析法](#7421-数字分析法)
      - [7.4.2.2 平方取中法](#7422-平方取中法)
      - [7.4.2.3 折叠法](#7423-折叠法)
      - [7.4.2.4 除留余数法](#7424-除留余数法)
    - [7.4.3 处理冲突的方法](#743-处理冲突的方法)
      - [7.4.3.1 开放地址法](#7431-开放地址法)
      - [7.4.3.2 链地址法](#7432-链地址法)
    - [7.4.4 散列表的查找](#744-散列表的查找)
- [第8章 排序](#第8章-排序)
  - [8.1 基本概念和排序方法概述](#81-基本概念和排序方法概述)
    - [8.1.1 排序的基本概念](#811-排序的基本概念)
    - [8.1.2 内部排序方法的分类](#812-内部排序方法的分类)
    - [8.1.3 待排序记录的存储方式](#813-待排序记录的存储方式)
  - [8.2 插入排序](#82-插入排序)
    - [8.2.1 直接插入排序](#821-直接插入排序)
    - [8.2.2 折半插入排序](#822-折半插入排序)
    - [8.2.3 希尔排序](#823-希尔排序)
  - [8.3 交换排序](#83-交换排序)
    - [8.3.1 冒泡排序](#831-冒泡排序)
    - [8.3.2 快速排序](#832-快速排序)
  - [8.4 选择排序](#84-选择排序)
    - [8.4.1 简单选择排序](#841-简单选择排序)
    - [8.4.2 树形选择排序](#842-树形选择排序)
    - [8.4.3 堆排序](#843-堆排序)
  - [8.5 归并排序](#85-归并排序)
  - [8.6 基数排序](#86-基数排序)
  - [8.7 外部排序](#87-外部排序)
    - [8.7.1 外部排序的基本方法](#871-外部排序的基本方法)
    - [8.7.2 多路平衡归并的实现](#872-多路平衡归并的实现)
    - [8.7.3 置换-选择排序](#873-置换-选择排序)
    - [8.7.4 最佳归并树](#874-最佳归并树)
  - [8.8 小结](#88-小结)

<!-- /code_chunk_output -->

# 第1章 绪论

## 1.1 数据结构的研究内容

数据结构是一门研究非数值计算程序设计中的操作对象，以及这些对象之间的关系和操作的学科。

## 1.2 基本概念和术语

### 1.2.1 数据、数据元素、数据项和数据对象

**数据**（Data）是客观事物的符号表示，是所有能输入到计算机中并被计算机程序处理的符号的总称。

**数据元素**（Data Element）是数据的基本单位，在计算机中通常作为一个整体进行考虑和处理。在有些情况下，数据元素也称为元素、记录等。数据元素用于完整地描述一个对象。

**数据项**（Data Item）是组成数据元素的、有独立含义的、不可分割的最小单位。

**数据对象**（Data Object）是性质相同的数据元素的集合，是数据的一个子集。不论数据元素集合是无限集（如整数集），或是有限集（如字母字符集），还是由多个数据项组成的复合数据元素（如学生表）的集合，只要集合内元素的性质均相同，都可称之为一个数据对象。

### 1.2.2 数据结构

**数据结构**（Data Structure）是相互之间存在一种或多种特定关系的数据元素的集合。换句话说，数据结构是带“结构”的数据元素的集合，“结构”就是指数据元素之间存在的关系。

数据结构包括逻辑结构和存储结构两个层次。

#### 1.2.2.1 逻辑结构

数据的**逻辑结构**是从逻辑关系上描述数据，它与数据的存储无关，是独立于计算机的。因此，数据的逻辑结构可以看作是从具体问题抽象出来的数学模型。

数据的逻辑结构有两个要素： 一是数据元素，二是关系。一个逻辑结构可以被形式化地定义为一个二元组 $L=(N,R)$，其中 $N$ 是有限的结点集合，$R$ 是定义在集合 $N$ 上的二元关系 $r$ 的集合。

关系是指数据元素间的逻辑关系。根据数据元素之间关系的不同特性，通常有四类基本结构：集合结构、线性结构、树结构、图结构。它们的复杂程度依次递进，如图 1.1 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图1.1-基本逻辑结构.7b7sqbouqb80.png">
    <br>
    图 1.1&nbsp;&nbsp;&nbsp; 基本逻辑结构
</div>

1. 集合结构：数据元素之间除了“属于同一集合”的关系外，别无其他关系。
2. 线性结构：数据元素之间存在一对一的关系。
3. 树结构：数据元素之间存在一对多的关系。
4. 图结构或网状结构：数据元素之间存在多对多的关系。

其中集合结构、树结构和图结构都属于非线性结构。

线性结构包括线性表、栈和队列、字符串、数组、广义表。非线性结构包括树和二叉树、有向图和无向图。这几种逻辑结构可以用一个层次图描述，如图 1.2 所示。

<div align="center">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图1.2-逻辑结构层次图.1bkw97q3uirk.png">
    <br>
    图 1.2&nbsp;&nbsp;&nbsp; 逻辑结构层次图
</div>

#### 1.2.2.2 存储结构

数据对象在计算机中的存储表示称为数据的**存储结构**，也称为**物理结构**。

数据的存储结构建立一种由逻辑结构到存储结构的映射：对于逻辑结构 $L=(N,R)$，$r\in R$，建立结点集合 $N$ 到存储区域 $M$ 的映射 $N\to M$，其中每个结点 $j\in N$ 都对应唯一的连续存储单元 $c\in M$。

数据元素在计算机中有两种基本的存储结构，分别是顺序存储结构和链式存储结构。

1. 顺序存储结构：将所有的元素依次存放在一片连续的存储空间中，元素间的逻辑关系由元素在存储器中的相对位置关系来表示。
2. 链式存储结构：为了表示结点之间的关系，在每个结点中附加指针字段，用于存放后继元素的存储地址。

### 1.2.3 数据类型和抽象数据类型

**数据类型**（Data Type）是一个值的集合和定义在这个值集上的一组操作的总称。

**抽象数据类型**（Abstract Data Type，ADT）一般指由用户定义的、表示应用问题的数学模型，以及定义在这个模型上的一组操作的总称，具体包括三部分：数据对象、数据对象上关系的集合以及对数据对象的基本操作的集合。

抽象数据类型的定义格式如下：

```text
ADT 抽象数据类型名 {
    数据对象：<数据对象的定义>
    数据关系：<数据关系的定义>
    基本操作：<基本操作的定义>
} ADT 抽象数据类型名
```

其中，数据对象和数据关系的定义采用数学符号和自然语言描述，基本操作的定义格式为：

```text
基本操作名(参数表)
初始条件：<初始条件描述>
操作结果：<操作结果描述>
```

基本操作有两种参数：赋值参数只为操作提供输入值；引用参数以 "&" 打头，除可提供输入值外，还将返回操作结果。“初始条件”描述了操作执行之前数据结构和参数应满足的条件，若初始条件为空，则省略。“操作结果”说明了操作正常完成之后，数据结构的变化状况和应返回的结果。

## 1.3 抽象数据类型的表示与实现

以复数为例，给出一个完整的抽象数据类型的定义、表示和实现。

定义部分：

```text
ADT Complex {
    数据对象：D={e1,e2 | e1,e2∈R,R是实数集}
    数据关系：S={<e1,e2> | e1是复数的实部,e2是复数的虚部}
    基本操作：
        Creat (&C, x, y) 
            操作结果：构造复数C, 其实部和虚部分别被赋以参数x和y的值。
        GetReal(C) 
            初始条件：复数C已存在。
            操作结果：返回复数C的实部值。
        GetImag (C) 
            初始条件：复数C已存在。
            操作结果：返回复数C的虚部值。
        Add(C1, C2) 
            初始条件：C1, C2 是复数。
            操作结果：返回两个复数 C1 和 C2 的和。
        Sub(C1, C2) 
            初始条件：C1, C2 是复数。
            操作结果：返回两个复数 C1 和 C2 的差。
} ADT Complex 
```

表示部分：

```C{.line-numbers}
// 复数类型
typedef struct
{
    float Realpart; // 实部
    float Imagepart; // 虚部
} Complex;
```

实现部分：

```C{.line-numbers}
// 构造一个复数
void Create(&Complex C, float x, float y)
{
    C.Realpart = x;
    C.Imagepart = y;
}

// 取复数 C=x+yi 的实部
float GetReal(Complex C)
{
    return C.Realpart;
}

// 取复数 C=x+yi 的虚部
float GetImag(Complex C)
{
    return C.Imagepart;
}

// 求两个复数 C1 和 C2 的和
Complex Add(Complex C1, Complex C2)
{
    Complex sum;
    sum.Realpart = C1.Realpart + C2.Realpart;
    sum.Imagepart = C1.Imagepart + C2.Imagepart;
    return sum;
}

// 求两个复数 C1 和 C2 的差
Complex Sub(Complex C1, Complex C2)
{
    Complex difference; 
    difference.Realpart = C1.Realpart - C2.Realpart; 
    difference.Imagepart = C1.Imagepart - C2.Imagepart; 
    return difference;
}
```

## 1.4 算法和算法分析

### 1.4.1 算法的定义及特性

**算法**（Algorithm）是为了解决某类问题而规定的一个有限长的操作序列。

一个算法必须满足以下五个重要特性：

1. 有穷性。一个算法必须总是在执行有穷步后结束，且每一步都必须在有穷时间内完成。
2. 确定性。对于每种情况下所应执行的操作，在算法中都有确切的规定，不会产生二义性，使算法的执行者或阅读者都能明确其含义及如何执行。
3. 可行性。算法中的所有操作都可以通过已经实现的基本操作运算执行有限次来实现。
4. 输入。一个算法有 0 个或多个输入。
5. 输出。一个算法有 1 个或多个输出。

### 1.4.2 评价算法优劣的基本标准

1. 正确性。在合理的数据输入下，能够在有限的运行时间内得到正确的结果。
2. 可读性。可读性强的算法有助于人们对算法的理解，而难懂的算法易于隐藏错误，且难于调试和修改。
3. 健壮性。当输入的数据非法时，好的算法能适当地做出正确反应或进行相应处理，而不会产生一些莫名其妙的输出结果。
4. 高效性。高效性包括时间和空间两个方面。时间高效是指算法设计合理，执行效率高，可以用时间复杂度来度量；空间高效是指算法占用存储容量合理，可以用空间复杂度来度量。时间复杂度和空间复杂度是衡量算法的两个主要指标。

### 1.4.3 算法的时间复杂度

#### 1.4.3.1 问题规模和语句频度

不考虑计算机的软硬件等环境因素，影响算法时间代价的最主要因素是问题规模。**问题规模**是算法求解问题输入量的多少，是问题大小的本质表示，一般用整数 $n$ 表示。问题规模 $n$ 对不同的问题含义不同，例如，在排序运算中 $n$ 为参加排序的记录数，在矩阵运算中 $n$ 为矩阵的阶数，在多项式运算中 $n$ 为多项式的项数，在集合运算中 $n$ 为集合中元素的个数，在树的有关运算中 $n$ 为树的结点个数，在图的有关运算中 $n$ 为图的顶点数或边数。显然，$n$ 越大算法的执行时间越长。

一个算法的执行时间大致上等于其所有语句执行时间的总和，而语句的执行时间则为该条语句的重复执行次数和执行一次所需时间的乘积。

一条语句的重复执行次数称作**语句频度**（Frequency Count）。

设每条语句执行一次所需的时间均是单位时间，则一个算法的执行时间可用该算法中所有语句频度之和来度量。

#### 1.4.3.2 算法的时间复杂度定义

**基本语句**指的是算法中重复执行次数和算法的执行时间成正比的语句，它对算法运行时间的贡献最大。

**定义**&nbsp;&nbsp;&nbsp;&nbsp;设 $f(n)$ 和 $g(n)$ 是定义在正整数集合上的两个函数，则 $g(n)= O(f(n))$ 表示存在正的常数 $C$ 和 $n_0$，使得对于任意的 $n\geqslant n_0$，有 $0\leqslant g(n)\leqslant Cf(n)$。

一般情况下，算法中基本语句重复执行的次数是问题规模 $n$ 的某个函数 $f(n)$, 算法的时间量度记作

$$
T(n)=O(f(n))
$$

它表示随问题规模 $n$ 的增大，算法执行时间的增长率和 $f(n)$ 的增长率相同，称做算法的**渐近时间复杂度**，简称**时间复杂度**（Time Complexity）。

该定义说明了函数 $T(n)$ 和 $f(n)$ 具有相同的增长趋势，并且 $T(n)$ 的增长至多趋向于函数 $f(n)$ 的增长。符号 $O$ 用来描述增长率的上限，它表示当问题规模 $n>n_0$ 时，算法的执行时间不会超过 $f(n)$。

**定义**&nbsp;&nbsp;&nbsp;&nbsp;设 $f(n)$ 和 $g(n)$ 是定义在正整数集合上的两个函数，则 $g(n)= \varOmega(f(n))$ 表示存在正的常数 $C$ 和 $n_0$，使得对于任意的 $n\geqslant n_0$，有 $g(n)\geqslant Cf(n)$。

**定义**&nbsp;&nbsp;&nbsp; 设 $f(n)$ 和 $g(n)$ 是定义在正整数集合上的两个函数，则 $g(n)= \varTheta(f(n))$ 表示存在正的常数 $C_1$、$C_2$ 和 $n_0$，使得对于任意的 $n\geqslant n_0$，有 $C_1 f(n)\leqslant g(n)\leqslant C_2 f(n)$。

如果 $g(n)=O(f(n))$ 且 $g(n)=\varOmega(f(n))$，则 $g(n)=\varTheta(f(n))$。

#### 1.4.3.3 算法的时间复杂度分析

分析算法时间复杂度的基本方法为：找出所有语句中语句频度最大的那条语句作为基本语句，计算基本语句的频度得到问题规模 $n$ 的某个函数 $f(n)$， 取其数量级用符号 $O$ 表示即可。计算数量级时，可以遵循以下定理。

**定理 1.1**&nbsp;&nbsp;&nbsp;&nbsp;若 $f(n)=a_m n^m+a_{m-1} n^{m-1}+\dots+a_1 n+a_0$ 是一个 $m$ 次多项式，则 $O(f(n))=O(n^m)$。

定理 1.1 说明，在计算算法时间复杂度时，可以忽略所有低次幕项和最高次幕的系数，这样可以简化算法分析，也体现出了增长率的含义。

常见的时间复杂度按数量级递增排列依次为：

$$
O(1)<O(\log_2 n)<O(n)<O(n\log_2 n)<O(n^2)<O(n^3)<\dots<O(n^k)<O(2^n)
$$

#### 1.4.3.4 最好、最坏和平均时间复杂度

称算法在最好情况下的时间复杂度为**最好时间复杂度**，指的是算法计算量可能达到的最小值；称算法在最坏情况下的时间复杂度为**最坏时间复杂度**，指的是算法计算量可能达到的最大值；算法的**平均时间复杂度**是指算法在所有可能情况下，按照输入实例以等概率出现时，算法计算量的加权平均值。

### 1.4.4 算法的空间复杂度

我们采用**渐近空间复杂度**作为算法所需存储空间的扯度，简称**空间复杂度**（Space Complexity），它也是问题规模 $n$ 的函数，记作：

$$
S(n)=O(f(n))
$$

# 第2章 线性表

## 2.1 线性表的定义和特点

由 $n\,(n\geqslant0)$ 个数据特性相同的元素构成的有限序列称为**线性表**，用 $(a_1,a_2,\cdots,a_n)$ 表示。线性表中元素的个数 $n\,(n\geqslant0)$ 定义为线性表的长度，$n=0$ 时称为**空表**。

当 $n\geqslant 1$ 时，称 $a_1$ 为线性表的**表头**，称 $a_n$ 为线性表的**表尾**。当 $n\geqslant 2$ 时，称 $a_i$ 为 $a_{i+1}$ 的前驱，称 $a_{i+1}$ 为 $a_i$ 的后继，其中 $1\leqslant i<n$。

对于非空的线性表或线性结构，其特点是：

1. 存在唯一的一个被称作“第一个”的数据元素；
2. 存在唯一的一个被称作“最后一个”的数据元素；
3. 除第一个之外，结构中的每个数据元素均只有一个前驱；
4. 除最后一个之外，结构中的每个数据元素均只有一个后继。

## 2.2 线性表的类型定义

$$
\begin{aligned}
    &\texttt{ADT List \{}\\
    &\texttt{\quad 数据对象：$D=\{a_i\,|\,a_i\in\text{ElemSet},\,i=1,2,\cdots,n,\,n\geqslant 0\}$}\\
    &\texttt{\quad 数据关系：$R=\{\textrm{<}a_{i-1},a_i\textrm{>}|\,a_{i-1},a_i\in D,\,i=1,2,\cdots,n\}$}\\
    &\texttt{\quad 基本操作：}\\
    &\texttt{\qquad InitList(\&L)}\\
    &\texttt{\qquad\quad 操作结果：构造一个空的线性表\,L}\\
    &\texttt{\qquad DestroyList(\&L)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：销毁线性表\,L}\\
    &\texttt{\qquad ClearList(\&L)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：将\,L\,重置为空表}\\
    &\texttt{\qquad ListEmpty(L)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：若\,L为空表，则返回\,true，否则返回\,false}\\
    &\texttt{\qquad ListLength(L)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：返回\,L\,中数据元素个数}\\
    &\texttt{\qquad GetElem(L, i, \&e)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在，且 $1\leqslant i\leqslant \operatorname{ListLength}(L)$}\\
    &\texttt{\qquad\quad 操作结果：用\,e\,返回\,L\,中第\,i\,个数据元素的值}\\
    &\texttt{\qquad LocateElem(L, e)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：返回\,L\,中第一个值与\,e\,相同的元素在\,L\,中的位置。}\\
    &\texttt{\qquad\qquad\qquad\qquad 若这样的数据元素不存在，则返回\,0}\\
    &\texttt{\qquad PriorElem(L, cur\_e, \&pre\_e)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：若\,cur\_e\,是\,L\,的数据元素，且不是第一个，则用\,pre\_e\,返回其前驱；}\\
    &\texttt{\qquad\qquad\qquad\qquad 否则操作失败，pre\_e\,无定义}\\
    &\texttt{\qquad NextElem(L, cur\_e, \&next\_e)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：若\,cur\_e\,是\,L\,的数据元素，且不是最后一个，则用\,next\_e\,返回其后继；}\\
    &\texttt{\qquad\qquad\qquad\qquad 否则操作失败，next\_e\,无定义}\\
    &\texttt{\qquad ListInsert(\&L, i, e)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在，且 $1\leqslant i\leqslant \operatorname{ListLength}(L)+1$}\\
    &\texttt{\qquad\quad 操作结果：在\,L\,中第\,i\,个位置之前插入新的数据元素\,e，L\,的长度加\,}1\\
    &\texttt{\qquad ListDelete(\&L, i)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在，且 $1\leqslant i\leqslant \operatorname{ListLength}(L)$}\\
    &\texttt{\qquad\quad 操作结果：删除\,L\,的第\,i\,个数据元素，L\,的长度减\,}1\\
    &\texttt{\qquad TraverseList(L)}\\
    &\texttt{\qquad\quad 初始条件：线性表\,L\,已存在}\\
    &\texttt{\qquad\quad 操作结果：对线性表\,L\,进行遍历，在遍历过程中对\,L\,的每个结点访问一次}\\
    &\texttt{\} ADT List}
\end{aligned}
$$

## 2.3 线性表的顺序表示和实现

### 2.3.1 线性表的顺序存储表示

线性表的顺序表示指的是用一组地址连续的存储单元依次存储线性表的数据元素，这种表示也称作线性表的顺序存储结构或顺序映像。通常，称这种存储结构的线性表为**顺序表**（Sequential List）。其特点是，逻辑上相邻的数据元素，其物理次序也是相邻的。

假设线性表的每个元素需占用 $l$ 个存储单元， 并以所占的第一个单元的存储地址作为数据元素的存储起始位置，则线性表中第 $i+1$ 个数据元素的存储位置 $\text{LOC}(a_{i+1})$ 和第 $i$ 个数据元素的存储位置 $\text{LOC}(a_i)$ 之间满足下列关系：

$$
\text{LOC}(a_{i+1})=\text{LOC}(a_i)+l
$$

一般来说，线性表的第 $i$ 个数据元素 $a_i$ 的存储位置为：

$$
\text{LOC}(a_i)=\text{LOC}(a_1)+(i-1)\times l
$$

其中 $\text{LOC}(a_1)$ 是线性表的第一个数据元素 $a_1$ 的存储位置，通常称作线性表的起始位置或基地址。每一个数据元素的存储位置都和线性表的起始位置相差一个常数，这个常数和数据元素在线性表中的位序成正比。由此，只要确定了存储线性表的起始位置，线性表中任一数据元素都可随机存取，所以线性表的顺序存储结构是一种可以随机存取的存储结构。

在 C 语言中可以用动态分配的一维数组表示线性表，描述如下：

```C{.line-numbers}
//--------顺序表的存储结构---------
#define MAXSIZE 100 // 顺序表可能达到的最大长度

typedef struct
{
    ElemType *elem; // 存储空间的基地址
    int length; // 当前长度
} SqList;
```

### 2.3.2 顺序表中基本操作的实现

#### 2.3.2.1 初始化

顺序表的初始化操作就是构造一个空的顺序表。

> **算法 2.1**&nbsp;&nbsp;&nbsp;&nbsp;顺序表的初始化
>
> 1. 为顺序表`L`动态分配一个预定义大小的数组空间，使`elem`指向这段空间的基地址。
> 2. 将表的当前长度设为 0。

```C{.line-numbers}
// 构造一个空的顺序表 L
Status InitList(SqList &L)
{
    L.elem = new ElemType[MAXSIZE]; // 为顺序表分配一个大小为 MAXSIZE 的数组空间
    if (!L.elem) exit(OVERFLOW); // 存储分配失败
    L.length = 0; // 空表长度为 0
    return OK;
}
```

#### 2.3.2.2 取值

取值操作是根据指定的位置序号`i`，获取顺序表中第`i`个数据元素的值。

> **算法 2.2**&nbsp;&nbsp;&nbsp;&nbsp;顺序表的取值
>
> 1. 判断指定的位置序号`i`是否合理（`1 <= i <= L.length`），若不合理，返回 ERROR。
> 2. 若`i`值合理，则将第`i`个数据元素`L.elem[i - 1]`赋给参数`e`，通过`e`返回第`i`个数据元素的值。

```C{.line-numbers}
Status GetElem(SqList L, int i, ElemType &e)
{
    if (i < 1 || i > L.length) return ERROR; // 判断 i 值是否合理，若不合理，返回 ERROR
    e = L.elem[i - 1];
    return OK;
}
```

顺序表取值算法的时间复杂度为 $O(1)$。

#### 2.3.2.3 查找

查找操作是根据指定的元素值`e`, 查找顺序表中第一个与`e`相等的元素。若查找成功，则返回该元素在表中的位置序号；若查找失败，则返回 0。

> **算法 2.3**&nbsp;&nbsp;&nbsp;&nbsp;顺序表的查找
>
> 1. 从第一个元素起，依次和`e`相比较，若找到与`e`相等的元素`L.elem[i]`，则查找成功，返回该元素的序号`i + 1`。
> 2. 若查遍整个顺序表都没有找到，则查找失败，返回 0。

```C{.line-numbers}
// 在顺序表 L 中查找值为 e 的数据元素，返回其序号
int LocateElem(SqList L, ElemType e)
{
    for (int i = 0; i < L.length; i++)
    {
        if (L.elem[i] == e) return i + 1; // 查找成功，返回序号 i+1
    }
    return 0; // 查找失败，返回 0
}
```

在查找时，为确定元素在顺序表中的位置，需和给定值进行比较的数据元素个数的期望值称为查找算法在查找成功时的**平均查找长度**（Average Search Length，ASL）。

假设 $p_i$ 是查找第 $i$ 个元素的概率，$C_i$ 为找到表中其关键字与给定值相等的第 $i$ 个记录时，和给定值已进行过比较的关键字个数，则在长度为 $n$ 的线性表中，查找成功时的平均查找长度为：

$$
ASL=\sum_{i=1}^n p_i C_i
$$

$C_i$ 取决于所查元素在表中的位置，一般情况下 $C_i=i$。假设每个元素的查找概率相等，即 $p_i=\dfrac{1}{n}$，则平均查找长度为：

$$
ASL=\frac{1}{n}\sum_{i=1}^n i=\frac{n+1}{2}
$$

由此可见，顺序表按值查找算法的平均时间复杂度为 $O(n)$。

#### 2.3.2.4 插入

线性表的插入操作是指在表的第 $i$ 个位置插入一个新的数据元素 $e$，使长度为 $n$ 的线性表

$$
(a_1,\cdots,a_{i-1},a_i,\cdots,a_n)
$$

变成长度为 $n+1$ 的线性表

$$
(a_1,\cdots,a_{i-1},e,a_i,\cdots,a_n)
$$

> **算法 2.4**&nbsp;&nbsp;&nbsp;&nbsp;顺序表的插入
>
> 1. 判断插入位置 $i$ 是否合法，若不合法则返回 ERROR。
> 2. 判断顺序表的存储空间是否已满，若满则返回 ERROR。
> 3. 将第 $n$ 个至第 $i$ 个位置的元素依次向后移动一个位置，空出第 $i$ 个位置。
> 4. 将要插入的新元素`e`放入第 $i$ 个位置。
> 5. 表长加 1。

```C{.line-numbers}
// 在顺序表 L 中第 i 个位置之前插入新元素 e
Status ListInsert(SqList &L, int i, ElemType e)
{
    if (i < 1 || i > L.length + 1) return ERROR; // i 值不合法
    if (L.length == MAXSIZE) return ERROR; // 当前存储空间已满

    for (int j = L.length - 1; j >= i - 1; j--)
    {
        L.elem[j + 1] = L.elem[j]; // 插入位置及之后的元素后移
    }
    L.elem[i - 1] = e; // 将新元素放入第 i 个位置
    L.length++; // 表长加 1
    return OK;
}
```

当在顺序表中某个位置上插入一个数据元素时，其时间主要耗费在移动元素上，而移动元素的个数取决于插入元素的位置。

假设 $p_i$ 是在第 $i$ 个元素之前插入一个元素的概率，$E_{\text{ins}}$ 为在长度为 $n$ 的线性表中插入一个元素时所需移动元素次数的期望值，则有

$$
E_{\text{ins}}=\sum_{i=1}^{n+1}p_i(n-i+1)
$$

假设在线性表的任何位置上插入元素都是等概率的，即 $p_i=\dfrac{1}{n+1}$，则有

$$
E_{\text{ins}}=\frac{1}{n+1}\sum_{i=1}^{n+1}(n-i+1)=\frac{n}{2}
$$

由此可见，顺序表插入算法的平均时间复杂度为 $O(n)$。

#### 2.3.2.5 删除

线性表的删除操作是指将表的第 $i$ 个元素删去，将长度为 $n$ 的线性表

$$
(a_1,\cdots,a_{i-1},a_i,a_{i+1},\cdots,a_n)
$$

变成长度为 $n-1$ 的线性表

$$
(a_1,\cdots,a_{i-1},a_{i+1},\cdots,a_n)
$$

> **算法 2.5**&nbsp;&nbsp;&nbsp;&nbsp;顺序表的删除
>
> 1. 判断删除位置 $i$ 是否合法，若不合法则返回 ERROR。
> 2. 将第 $i+1$ 个至第 $n$ 个元素依次向前移动一个位置。
> 3. 表长减 1。

```C{.line-numbers}
// 在顺序表 L 中删除第 i 个元素
Status ListDelete(SqList &L, int i)
{
    if (i < 1 || i > L.length + 1) return ERROR; // i 值不合法

    for (int j = i; j <= L.length - 1; j++)
    {
        L.elem[j - 1] = L.elem[j]; // 被删除元素之后的元素前移
    }
    L.length--; // 表长减 1
    return OK;
}
```

当在顺序表中某个位置上删除一个数据元素时，其时间主要耗费在移动元素上，而移动元素的个数取决于删除元素的位置。

假设 $p_i$ 是删除第 $i$ 个元素的概率，$E_{\text{del}}$ 为在长度为 $n$ 的线性表中删除一个元素时所需移动元素次数的期望值，则有

$$
E_{\text{del}}=\sum_{i=1}^n p_i(n-i)
$$

假设在线性表的任何位置上删除元素都是等概率的，即 $p_i=\dfrac{1}{n}$，则有

$$
E_{\text{del}}=\frac{1}{n}\sum_{i=1}^n (n-i)=\frac{n-1}{2}
$$

由此可见，顺序表删除算法的平均时间复杂度为 $O(n)$。

## 2.4 线性表的链式表示和实现

### 2.4.1 单链表的定义和表示

线性表链式存储结构的特点是：用一组任意的存储单元存储线性表的数据元素，这组存储单元可以是连续的，也可以是不连续的。

为了表示每个数据元素 $a_i$ 与其直接后继数据元素 $a_{i+1}$ 之间的逻辑关系，对数据元素 $a_i$ 来说，除了存储其本身的信息之外，还需存储一个指示其直接后继的信息，这两部分信息组成数据元素 $a_i$ 的存储映像，称为**结点**（node），它包括两个域：存储数据元素信息的域称为**数据域**，存储直接后继存储位置的域称为**指针域**。指针域中存储的信息称作**指针**或**链**。$n$ 个结点链接成一个**链表**，即为线性表 $(a_1,a_2,\cdots,a_n)$ 的链式存储结构。又由于此链表的每个结点中只包含一个指针域，故又称**线性链表**或**单链表**。

在线性表的单链表存储结构中，整个链表的存取必须从头指针开始进行，**头指针**指示链表中第一个结点（即第一个数据元素的存储映像，也称**首元结点**）的存储位置。由于最后一个数据元素没有直接后继，则单链表中最后一个结点的指针为空。

用单链表表示线性表时，数据元素之间的逻辑关系是由结点中的指针指示的。指针为数据元素之间的逻辑关系的映像，则逻辑上相邻的两个数据元素其存储的物理位置不要求紧邻，由此，这种存储结构为非顺序映像或链式映像。

单链表可由头指针唯一确定，在 C 语言中可用“结构指针”来描述：

```C{.line-numbers}
//--------------单链表的存储结构------------------
typedef struct LNode
{
    ElemType data; // 结点的数据域
    struct LNode *next; // 结点的指针域
} LNode, *LinkList;
```

单链表是由表头指针唯一确定，因此单链表可以用头指针的名字来命名。若头指针名是 L，则简称该链表为表 L。

为了处理方便，可以在单链表的第一个结点之前附设一个结点，称为**头结点**。链表增加头结点的作用有：

1. 便于首元结点的处理。增加了头结点后，首元结点的地址保存在头结点的指针域中，则对链表的第一个数据元素的操作与其他数据元素相同，无需进行特殊处理。
2. 便于空表和非空表的统一处理。当链表不设头结点时，假设 L 为单链表的头指针，它应该指向首元结点，则当单链表为空时，L 指针为空；增加头结点后，无论链表是否为空，头指针都是指向头结点的非空指针。

首元结点、头结点、头指针三个概念容易混淆，说明如下：

1. 首元结点是指链表中存储第一个数据元素 $a_1$ 的结点。
1. 头结点是在首元结点之前附设的一个结点，其指针域指向首元结点。头结点的数据域可以不存储任何信息，也可以存储于数据元素类型相同的其他附加信息。
1. 头指针是指向链表中第一个结点的指针。若链表有头结点，则头指针指向头结点；若链表没有头结点，则头指针指向首元结点。

在单链表中，各个元素的存储位置都是随意的，每个元素的存储位置都包含在其直接前驱结点的信息之中。由此，单链表是非随机存取的存储结构，要取得第 $i$ 个数据元素必须从头指针出发顺链进行寻找，也称为**顺序存取**的存取结构。

### 2.4.2 单链表基本操作的实现

#### 2.4.2.1 初始化

单链表的初始化操作就是构造一个空表。

> **算法 2.6**&nbsp;&nbsp;&nbsp;&nbsp;单链表的初始化
>
> 1. 生成新结点作为头结点，用头指针`L`指向头结点。
> 2. 头结点的指针域置空。

```C++{.line-numbers}
// 构造一个空的单链表 L
Status InitList(LinkList &L)
{
    L = new LNode; // 生成新结点作为头结点，用头指针 L 指向头结点
    L->next = NULL; // 头结点的指针域置空
    return OK;
}
```

#### 2.4.2.2 取值

> **算法 2.7**&nbsp;&nbsp;&nbsp;&nbsp;单链表的取值
>
> 1. 用指针`p`指向首元结点，用`j`做计数器并赋初值为 1。
> 2. 从首元结点开始依次顺着指针域`next`向下访问，只要指向当前结点的指针`p`不为空，并且没有到达序号为`i`的结点，则循环执行以下操作：
>    （1）`p`指向下一个结点。
>    （2）计数器`j`加 1。
> 3. 退出循环时，如果指针`p`为空，或者计数器`j`大于`i`，说明指定的序号`i`不合法，取值失败，返回 ERROR；否则取值成功，此时 $j=i$，`p`所指的结点就是要找的第 $i$ 个结点，用参数`e`保存当前结点的数据域，返回 OK。

```C{.line-numbers}
// 在带头结点的单链表 L 中根据序号 i 获取元素的值，用 e 返回 L 中第 i 个数据元素的值
Status GetElem(LinkList L, int i, ElemType &e)
{
    // 初始化
    LNode *p = L->next; // p 指向首元结点
    int j = 1; // 计数器 j 初值为 1
    
    // 顺着链向后扫描，直到 p 为空或 p 指向第 i 个元素
    while (p && j < i)
    {
        p = p->next; // p 指向下一个结点
        j++; // 计数器加 1
    }
    
    if (!p || j > i) return ERROR;
    e = p->data;
    return OK;
}
```

该算法的基本操作是比较 $j$ 和 $i$ 并后移指针`p`，`while`循环体中的语句频度与位置 $i$ 有关。若 $1\leqslant i \leqslant n$，则频度为 $i-1$，一定能取值成功；若 $i>n$，则频度为 $n$，取值失败。因此算法 2.7 的最坏时间复杂度为 $O(n)$。

最好情况下，时间复杂度为 $O(1)$。

假设每个位置上元素的取值概率相等，即 $p_i=\dfrac{1}{n}$，则

$$
ASL=\sum_{i=1}^n p_i(i-1)=\dfrac{1}{n}\sum_{i=1}^n (i-1)=\dfrac{n-1}{2}
$$

由此可见，单链表取值算法的平均时间复杂度为 $O(n)$。

#### 2.4.2.3 查找

> **算法 2.8**&nbsp;&nbsp;&nbsp;&nbsp;单链表的按值查找
>
> 1. 用指针`p`指向首元结点。
> 2. 从首元结点开始依次顺着指针域`next`向下查找，只要指向当前结点的指针`p`不为空，并且`p`所指结点的数据域不等于给定值`e`，则循环执行以下操作：`p`指向下一个结点。
> 3. 返回`p`。若查找成功，`p`此时即为结点的地址；若查找失败，`p`的值为`NULL`。

```C{.line-numbers}
// 在带头结点的单链表 L 中查找值为 e 的元素
LNode* LocateElem(LinkList L, ElemTpe e)
{
    LNode *p = L->next; // 初始化，p 指向首元结点
    while (p && p->data != e) // 顺着链向后扫描，直到 p 为空或 p 所指结点的数据域等于 e
    {
        p = p->next; // p 指向下一个结点
    }
    return p;
}
```

该算法的平均时间复杂度分析类似于算法 2.7，也是 $O(n)$。

#### 2.4.2.4 插入

> **算法 2.9**&nbsp;&nbsp;&nbsp;&nbsp;单链表的插入
>
> 将值为`e`的新结点插入到表的第 $i$ 个结点的位置上，即插入到结点 $a_{i-1}$ 与 $a_i$ 之间。
>
> 1. 查找结点 $a_{i-1}$ 并由指针`p`指向该结点。
> 2. 生成一个新结点`*s`。
> 3. 将新结点`*s`的数据域置为`e`。
> 4. 将新结点`*s`的指针域指向结点 $a_i$。
> 5. 将结点`*p`的指针域指向新结点`*s`。

```C++{.line-numbers}
// 在带头结点的单链表 L 中第 i 个位置插入值为 e 的新结点
Status ListInsert(LinkList &L, int i, ElemType e)
{
    LNode *p = L;
    int j = 0;
    
    // 查找第 i-1 个结点，p 指向该结点
    while (p && j < i - 1)
    {
        p = p->next;
        j++;
    }
    if (!p || j > i - 1) return ERROR;
    
    LNode *s = new LNode; // 生成新结点 *s
    s->data = e; // 将结点 *s 的数据域置为 e
    s->next = p->next; // 将结点 *s 的指针域指向结点 ai
    p->next = s; // 将结点 *p 的指针域指向结点 *s
    return OK;
}
```

注意：插入位置可能为链表头部，因此初始化时指针`p`指向头结点而不是首元结点，计数器为 0 而不是 1。

为了在第 $i$ 个结点之前插入一个新结点，必须首先找到第 $i-1$ 个结点，其平均时间复杂度与算法 2.7 相同，为 $O(n)$。

#### 2.4.2.5 删除

> **算法 2.10**&nbsp;&nbsp;&nbsp;&nbsp;单链表的删除
>
> 删除单链表的第 $i$ 个结点 $a_i$。
>
> 1. 查找结点 $a_{i-1}$ 并由指针`p`指向该结点。
> 2. 临时保存待删除结点 $a_i$ 的地址在`q`中，以备释放。
> 3. 将结点`*p`的指针域指向 $a_i$ 的直接后继结点。
> 4. 释放结点 $a_i$ 的空间。

```C++{.line-numbers}
// 在带头结点的单链表 L 中，删除第 i 个元素
Status ListDelete(LinkList &L, int i)
{
    LNode *p = L;
    int j = 0;
    
    // 查找第 i-1 个结点，p 指向该结点
    while (p->next && j < i - 1)
    {
        p = p->next;
        j++;
    }
    if (!(p->next) || j > i - 1) return ERROR;
    
    q = p->next; // 临时保存被删结点的地址以备释放
    p->next = q->next;
    delete q; // 释放删除结点的空间
    return OK;
}
```

注意：删除算法中的循环条件（`p->next && j < i - 1`）和插入算法中的循环条件（`p && j < i - 1`）有所区别。因为插入操作中合法的插入位置有 $n+1$ 个，而删除操作中合法的删除位置只有 $n$ 个，如果使用与插入操作相同的循环条件，则会出现引用空指针的情况，使删除操作失败。

删除算法的时间复杂度类似于插入算法，也是 $O(n)$。

#### 2.4.2.6 创建单链表

建立线性表的链式存储结构的过程就是一个动态生成链表的过程，即从空表的初始状态起，依次建立各元素结点，并逐个插入链表。

根据结点插入位置的不同，链表的创建方法可分为前插法和后插法。

前插法是通过将新结点逐个插入链表的头部（头结点之后）来创建链表。

> **算法 2.11**&nbsp;&nbsp;&nbsp;&nbsp;前插法创建单链表
>
> 1. 创建一个只有头结点的空链表。
> 2. 根据待创建链表包括的元素个数 $n$，循环 $n$ 此执行以下操作：
>    （1）生成一个新结点`*p`。
>    （2）输入元素值赋给新结点`*p`的数据域。
>    （3）将新结点`*p`插入到头结点之后。

```C++{.line-numbers}
void CreateList_H(LinkList &L, int n)
{
    L = new LNode;
    L->next = NULL; // 建立一个带头结点的空链表
    
    for (int i = 0; i < n; i++)
    {
        // 生成新结点 *p
        LNode *p = new LNode;

        // 输入元素值赋给新结点 *p 的数据域
        cin >> p->data;

        // 将新结点插入到头结点之后
        p->next = L->next;
        L->next = p;
    }
}
```

后插法是通过将新结点逐个插入到链表的尾部来创建链表。为了使新结点能够插入到表尾，需要增加一个尾指针`r`指向链表的尾结点。

> **算法 2.12**&nbsp;&nbsp;&nbsp;&nbsp;后插法创建单链表
>
> 1. 创建一个只有头结点的空链表。
> 2. 尾指针`r`初始化，指向头结点。
> 3. 根据待创建链表包括的元素个数 $n$，循环 $n$ 此执行以下操作：
>    （1）生成一个新结点`*p`。
>    （2）输入元素值赋给新结点`*p`的数据域。
>    （3）将新结点`*p`插入到尾结点`*r`之后。
>    （4）尾指针`r`指向新的尾结点`*p`。

```C++{.line-numbers}
void CreateList_R(LinkList &L, int n)
{
    L = new LNode;
    L->next = NULL; // 建立一个带头结点的空链表
    LNode *r = L; // 尾指针 r 指向头结点
    
    for (int i = 0; i < n; i++)
    {
        // 生成新结点 *p
        LNode *p = new LNode;

        // 输入元素值赋给新结点 *p 的数据域
        cin >> p->data;

        // 将新结点插入到尾结点之后
        p->next = L->next;
        r->next = p;

        // r 指向新的尾结点 *p
        r = p;
    }
}
```

这两个算法的时间复杂度为 $O(n)$。

### 2.4.3 循环链表

**循环链表**（Circular Linked List）是另一种形式的链式存储结构。其特点是表中最后一个结点的指针域指向头结点，整个链表形成一个环。由此，从表中任一结点出发均可找到表中其他结点。

循环单链表的操作和单链表基本一致，差别仅在于：当链表遍历时，判别当前指针`p`是否指向表尾结点的终止条件不同。在单链表中，判别条件为`p != NULL`或`p->next != NULL`，而循环单链表的判别条件为`p != L`或`p->next != L`。

在某些情况下，若在循环链表中设立尾指针而不设头指针，可使一些操作简化。例如，将两个线性表合并成一个表时，仅需将第一个表的尾指针指向第二个表的第一个结点， 第二个表的尾指针指向第一个表的头结点， 然后释放第二个表的头结点。假设`A`和`B`分别是两个循环链表的尾指针，则合并操作的主要语句如下：

```C
p = B->next->next; // p 指向 B 链表的首元结点
B->next = A->next; // B 链表的尾指针指向 A 链表的头结点
A->next = p; // A 链表的尾指针指向 B 链表的首元结点
```

### 2.4.4 双向链表

单链表的结点中只有一个指示直接后继的指针域，由此，从某个结点出发只能顺指针向后寻查其他结点。若要寻查结点的直接前驱，则必须从表头指针出发。换句话说，在单链表中，查找直接后继结点的执行时间为 $O(1)$，而查找直接前驱的执行时间为 $O(n)$。为克服单链表这种单向性的缺点，可以使用**双向链表**（Double Linked List）。

在双向链表的结点中有两个指针域，一个指向直接后继，另一个指向直接前驱。双向链表的结点结构在 C 语言中可以描述如下：

```C{.line-numbers}
typedef struct DuLNode
{
    ElemType data; // 数据域
    struct DuLNode *prior; // 直接前驱
    struct DuLNode *next; // 直接后继
} DuLNode, *DuLinkList;
```

和单链的循环表类似， 双向链表也可以有循环表。

在双向链表中，取值和查找操作仅需涉及一个方向的指针，则它们的算法描述和单链表的操作相同。但是在插入、删除时，需要同时修改两个方向上的指针，此时的操作与单链表不同。

> **算法 2.13**&nbsp;&nbsp;&nbsp;&nbsp;双向链表的插入

```C++{.line-numbers}
// 在带头结点的双向链表 L 中第 i 个位置之前插入元素 e
Status ListInsert_DuL(DuLinkList &L, int i, ElemType e)
{
    if (!(p = GetElem_DuL(L, i))) // 在 L 中确定第 i 个元素的位置指针 p
    {
        return ERROR;
    }
    DuLNode *s = new DuLNode; // 生成新结点 *s
    s->data = e; // 将结点 *s 数据域置为 e
    s->prior = p->prior; // s 的前驱是 p 的前驱
    p->prior->next = s; // p 的前驱的后继是 s
    s->next = p; // s 的后继是 p
    p->prior = s; // p 的前驱是 s
    return OK;
}
```

> **算法 2.14**&nbsp;&nbsp;&nbsp;&nbsp;双向链表的删除

```C++{.line-numbers}
// 删除带头结点的双向链表 L 中的第 i 个元素
Status ListDelete_DuL(DuLinkList &L, int i)
{
    if (!(p = GetElem_DuL(L, i))) // 在 L 中确定第 i 个元素的位置指针 p
    {
        return ERROR;
    }
    p->prior->next = p->next; // p 的前驱的后继是 p 的后继
    p->next->prior = p->prior; // p 的后继的前驱是 p 的前驱
    delete p;
    return OK;
}
```

这两个算法的时间复杂度均为 $O(n)$。

单链表、循环链表和双向链表的比较如图 2.1 所示。

<div align="center">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图2.1-单链表、循环链表和双向链表的比较.63z6i565ykw0.png">
    <br>
    图 2.1&nbsp;&nbsp;&nbsp;&nbsp;单链表、循环链表和双向链表的比较
</div>

## 2.5 顺序表和链表的比较

### 2.5.1 空间性能的比较

1. 存储空间的分配

顺序表的存储空间必须预先分配，元素个数扩充受一定限制，易造成存储空间浪费或空间溢出现象；而链表不需要为其预先分配空间，只要内存空间允许，链表中的元素个数就没有限制。

2. 存储密度的大小

**存储密度**是指数据元素本身所占用的存储量和整个结点结构所占用的存储量之比，即

$$
存储密度=\dfrac{数据元素本身占用的存储量}{结点结构占用的存储量}
$$

存储密度越大，存储空间的利用率就越高。顺序表的存储密度为 1，而链表的存储密度小于 1。如果每个元素数据域占据的空间较小，则指针的结构性开销就占用了整个结点的大部分空间，这样存储密度较小。

因此，当线性表的长度变化较大，难以预估存储规模时，宜采用链表作为存储结构；线性表的长度变化不大，易于事先确定其大小时，为了节约存储空间，宜采用顺序表作为存储结构。

### 2.5.2 时间性能的比较

1. 存取元素的效率：顺序表是由数组实现的，它是一种随机存取结构，指定任意一个位置序号`i`，都可以在 $O(1)$ 时间内直接存取该位置上的元素，即取值操作的效率高；而链表是一种顺序存储结构，按位置访问链表中第`i`个元素时，只能从表头开始依次向后遍历链表，直到找到第`i`个位置上的元素，时间复杂度为 $O(n)$，即取值操作的效率低。
2. 插入和删除操作的效率：对于链表，在确定插入或删除的位置后，插入或删除操作无需移动数据，只需要修改指针，时间复杂度为 $O(1)$；而对于顺序表，进行插入或删除时，平均要移动表中近一半的结点，时间复杂度为 $O(n)$。尤其是当每个结点的信息量较大时，移动结点的时间开销就相当可观。

因此，若线性表的主要操作是和元素位置紧密相关的这类取值操作，很少做插入或删除时，宜采用顺序表作为存储结构；对于频繁进行插入或删除操作的线性表，宜采用链表作为存储结构。

顺序表和链表的比较如图 2.2 所示。

<div align="center">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图2.2-顺序表与链表的比较.3hggm8u93ck0.png">
    <br>
    图 2.2&nbsp;&nbsp;&nbsp;&nbsp;顺序表与链表的比较
</div>

## 2.6 线性表的应用

### 2.6.1 线性表的合并

> **算法 2.15**&nbsp;&nbsp;&nbsp;&nbsp;线性表的合并
>
> 1. 分别获取`LA`表长 $m$ 和`LB`表长 $n$。
> 2. 从`LB`中第 1 个数据元素开始，循环 $n$ 次执行以下操作：
>    （1）从`LB`中查找第 $i$ 个数据元素赋给`e`；
>    （2）在`LA`中查找元素`e`，如果不存在，将`e`插在表`LA`的最后。

```C{.line-numbers}
// 将所有在线性表 LB 中但不在 LA 中的数据元素插入到 LA 中
void MergeList(List &LA, List LB)
{
    // 求线性表的长度
    int m = ListLength(LA);
    int n = ListLength(LB);
    
    for (int i = 1; i <= n; i++)
    {
        ElemType e;
        GetElem(LB, i, e); // 取 LB 中第 i 个数据元素赋给 e
        if (!LocateElem(LA, e)) // LA 中不存在和 e 相同的数据元素
        {
            m++; // LA 长度加 1
            ListInsert(LA, m, e); // 将 e 插在 LA 的最后
        }
    }
}
```

上述算法的时间复杂度取决于抽象数据类型`List`定义中基本操作的执行时间。假设`LA`和`LB`的表长分别为 $m$ 和 $n$，循环执行 $n$ 次，则：

1. 当采用顺序存储结构时，在每次循环中，`GetElem`和`ListInsert`这两个操作的执行时间和表长无关，`LocateElem`的执行时间和表长 $m$ 成正比。因此，算法 2.15 的时间复杂度为 $O(mn)$。
2. 当采用链式存储结构时，在每次循环中，`ListInsert`的执行时间和表长无关，`GetElem`的执行时间和表长 $n$ 成正比，`LocateElem`的执行时间和表长 $m$ 成正比。因此，若假设 $m>n$，算法 2.15 的时间复杂度也为 $O(mn)$。

### 2.6.2 有序表的合并

若线性表中的数据元素相互之间可以比较，并且数据元素在线性表中依值非递减或非递增有序排列，则称该线性表为**有序表**（Ordered List）。

> **算法 2.16**&nbsp;&nbsp;&nbsp;&nbsp;顺序有序表的合并
>
> 1. 创建一个表长为 $m+n$ 的空表`LC`。
> 2. 指针`pc`初始化，指向`LC`的第一个元素。
> 3. 指针`pa`和`pb`初始化，分别指向`LA`和`LB`的第一个元素。
> 4. 当指针`pa`和`pb`均未到达相应表尾时，则依次比较`pa`和`pb`所指向的元素值，从`LA`或`LB`中摘取元素值较小的结点插入到`LC`的最后。
> 5. 如果`pb`已到达`LB`的表尾，依次将`LA`的剩余元素插入`LC`的最后。
> 6. 如果`pa`已到达`LA`的表尾，依次将`LB`的剩余元素插入`LC`的最后。

```C{.line-numbers}
// 已知顺序有序表 LA 和 LB 的元素按值非递减排列
// 合并 LA 和 LB 得到新的顺序有序表 LC，LC 的元素也按值非递减排列
void MergeList_Sq(SqList LA, SqList LB, SqList &LC)
{
    LC.length = LA.length + LB.length; // 新表长度为待合并两表的长度之和
    LC.elem = new ElemType[LC.length]; // 为合并后的新表分配一个数据空间
    ElemType *pc = LC.elem; // 指针 pc 指向新表的第一个元素
    ElemType *pa = LA.elem; // 指针 pa 指向 LA 的第一个元素
    ElemType *pb = LB.elem; // 指针 pb 指向 LB 的第一个元素
    
    ElemType *pa_last = LA.elem + LA.length - 1; // 指针 pa_last 指向 LA 的最后一个元素
    ElemType *pb_last = LB.elem + LB.length - 1; // 指针 pb_last 指向 LB 的最后一个元素
    
    // LA 和 LB 均未到达表尾
    while (pa <= pa_last && pb <= pb_last)
    {
        if (*pa <= *pb) // 摘取两表中值较小的结点插入到 LC 的最后
        {
            *pc = *pa;
            pa++;
        }
        else
        {
            *pc = *pb;
            pb++;
        }
        pc++;
    }
    
    // LB 已到达表尾，依次将 LA 的剩余元素插入 LC 的最后
    while (pa <= pa_last)
    {
        *pc = *pa;
        pa++;
        pc++;
    }
    
    // LA 已到达表尾，依次将 LB 的剩余元素插入 LC 的最后
    while (pb <= pb_last)
    {
        *pc = *pb;
        pb++;
        pc++;
    }
}
```

在算法 2.16 中，由于 LA 和 LB 中元素依值非递减，则对 LB 中的每个元素，不需要在 LA 中从表头至表尾进行全程搜索。如果两个表长分别记为 $m$ 和 $n$，则算法 2.16 循环最多执行的总次数为 $m+n$，所以算法的时间复杂度为 $O(m+n)$。

此算法在合并时，需要开辟新的辅助空间，所以空间复杂度也为 $O(m+n)$，空间复杂度较高。

> **算法 2.17**&nbsp;&nbsp;&nbsp;&nbsp;链式有序表的合并
>
> 1. 指针`pa`和`pb`初始化，分别指向`LA`和`LB`的第一个结点。
> 2. `LC`的结点取值为`LA`的头结点。
> 3. 指针`pc`初始化，指向`LC`的头结点。
> 4. 当指针`pa`和`pb`均未到达相应表尾时，则依次比较`pa`和`pb`所指向的元素值，从`LA`或`LB`中摘取元素值较小的结点插入到`LC`的最后。
> 5. 将非空表的剩余段插入到`pc`所指结点之后。
> 6. 释放`LB`的头结点。

```C++{.line-numbers}
// 已知单链表 LA 和 LB 的元素按值非递减排列
// 合并 LA 和 LB 得到新的单链表 LC，LC 的元素也按值非递减排列
void MergeList_L(LinkList &LA, LinkList &LB, LinkList &LC)
{
    // pa 和 pb 的初值分别指向两个表的第一个结点
    LNode *pa = LA->next;
    LNode *pb = LB->next;
    
    LNode *pc = LC; // pc 的初值指向 LC 的头结点
    
    // LA 和 LB 均未到达表尾，依次摘取两表中值较小的结点插入到 LC 的最后
    while (pa && pb)
    {
        if (pa->data <= pb->data) // 摘取 pa 所指结点
        {
            pc->next = pa;
            pc = pa;
            pa = pa->next;
        }
        else // 摘取 pb 所指结点
        {
            pc->next = pb;
            pc = pb;
            pb = pb->next
        }
    }
    
    pc->next = pa ? pa : pb; // 将非空表的剩余段插入到 pc 所指结点之后
    delete LB; // 释放 LB 的头结点
}
```

算法 2.17 的时间复杂度和算法 2.16 相同，但空间复杂度不同。在合并链表时，不需要另建新表的结点空间，而只需将原来两个链表中结点之间的关系解除，重新按元素值非递减的关系将所有结点链接成一个链表即可，所以空间复杂度为 $O(1)$。

### 2.6.3 一元多项式的运算

在数学上，一个一元 n 次多项式 $P_n(x)$ 可按升幂写成：

$$
P_n(x)=p_0+p_1 x+p_2 x^2+\cdots+p_n x^n
$$

一元 n 次多项式可由 $n+1$ 个系数唯一确定，因此，可以将一元 n 次多项式 $P_n(x)$ 抽象为一个由 $n+1$ 个元素组成的有序序列，用一个线性表 $P$ 来表示：

$$
P=(p_0,p_1,p_2,\cdots,p_n)
$$

这时，每一项的指数 $i$ 隐含在其系数 $p_i$ 的序号中。

假设 $Q_m(x)$ 是一元 m 次多项式，同样可以用线性表 $Q$ 来表示：

$$
Q=(q_0,q_1,q_2,\cdots,q_m)
$$

不失一般性，设 $m\leqslant n$，则两个多项式相加的结果 $R_n(x)=P_n(x)+Q_m(x)$ 可用线性表 $R$ 表示：

$$
R=(p_0+q_0,p_1+q_1,p_2+q_2,\cdots,p_m+q_m,p_{m+1},\cdots,p_n)
$$

可以采用数组来表示一元多项式。数组`p`中每个分量`p[i]`表示多项式每项的系数 $p_i$，数组分量的下标`i`对应每项的指数。

用数组表示一元多项式时，多项式相加的算法为：把两个数组对应的分量项相加。

### 2.6.4 稀疏多项式的运算

例如，在处理形如 $S(x)=1+3x^{10000}+2x^{20000}$ 的多项式时，需要用一个长度为 20001 的线性表来表示，而表中只有 3 个非零元素，此时将会造成存储空间的很大浪费。

一般情况下的一元 n 次多项式可写成

$$
P_n(x)=p_1 x^{e_1}+p_2 x^{e_2}+\cdots+p_m x^{e_m}
$$

其中，$p_i$ 是指数为 $e_i$ 的项的非零系数，且满足

$$
0\leqslant e_1<e_2<\cdots<e_m=n
$$

若用一个长度为 $m$ 且每个元素有两个数据项（系数项和指数项）的线性表

$$
((p_1,e_1),(p_2,e_2),\cdots,(p_m,e_m))
$$

便可唯一确定多项式 $P_n(x)$。在最坏情况下，$n+1$ 个系数都不为零，则比只存储每项系数的方案要多存储一倍的数据。但是，对于类似 $S(x)$ 的稀疏多项式，这种表示将大大节省空间。

如果多项式属于非稀疏多项式，且只对多项式进行“求值”等不改变多项式的系数和指数的运算，可采用数组表示的顺序存储结构。

稀疏多项式采用数组表示法的缺点：

1. 存储空间分配不够灵活。因为事先无法确定多项式的非零项数，所以需要根据预期估计可能的最大值定义数组的大小，这种分配方式可能会带来两种问题：
   （1）实际非零项数比较小，浪费了大量存储空间。
   （2）实际非零项式超过了最大值，存储空间不够。
2. 在实现多项式相加时，需要开辟一个新的数组保存结果多项式，导致算法的空间复杂度较高。

对于稀疏多项式，更好的办法是利用链式存储结构表示多项式的有序序列。

用链表表示多项式时，每个链表结点存储多项式中的一个非零项，包括系数和指数两个数据域以及一个指针域。对应的数据结构定义为：

```C{.line-numbers}
typedef struct PNode
{
    float coef; // 系数
    int expn; // 指数
    struct PNode *next; // 指针域
} PNode, *Polynomial;
```

一个多项式可以表示成由这些结点链接起来的单链表。

> **算法 2.18**&nbsp;&nbsp;&nbsp;&nbsp;多项式的创建
>
> 1. 创建一个只有头结点的空链表。
> 2. 根据多项式的项的个数 $n$，循环 $n$ 次执行以下操作：
>    （1）生成一个新结点`*s`。
>    （2）输入多项式当前项的系数和指数赋给新结点`*s`的数据域。
>    （3）设置一前驱指针`pre`，用于指向待找到的第一个大于输入项指数的结点的前驱。`pre`初值指向头结点。
>    （4）指针`q`初始化，指向首元结点。
>    （5）循链向下逐个比较链表中当前结点与输入项指数，找到第一个大于输入项指数的结点`*q`。
>    （6）将输入项结点`*s`插入到结点`*q`之前。

```C++{.line-numbers}
// 输入 n 项的系数和指数，建立表示多项式的有序链表 P
void CreatePolyn(Polynomial &P, int n)
{
    // 建立一个带头结点的单链表
    P = new PNode;
    P->next = NULL;
    
    // 依次输入 n 个非零项
    for (int i = 1; i <= n; i++)
    {
        PNode *s = new PNode; // 生成新结点
        cin >> s->coef >> s->expn; // 输入系数和指数

        PNode *pre = P; // pre 用于保存 q 的前驱，初值为头结点
        PNode *q = P->next; // q 初始化，指向首元结点
        
        // 通过比较指数找到第一个大于输入项指数的项 *q
        while (q && q->expn < s->expn)
        {
            pre = q;
            q = q->next;
        }
        
        // 将输入项 s 插入到 q 和 pre 之间
        s->next = q;
        pre->next = s;
    }
}
```

创建一个项数为 $n$ 的有序多项式链表，需要执行 $n$ 次循环逐个输入各项，而每次循环又都需要从前向后比较输入项与各项的指数。在最坏情况下，第 $n$ 次循环需要做 $n$ 次比较，因此，时间复杂度为 $O(n^2)$。

> **算法 2.19**&nbsp;&nbsp;&nbsp;&nbsp;多项式的相加
>
> 1. 指针`p1`和`p2`初始化，分别指向`Pa`和`Pb`的首元结点。
> 2. `p3`指向和多项式的当前结点，初值为`Pa`的头结点。
> 3. 当指针`p1`和`p2`均未到达相应表尾时，则循环比较`p1`和`p2`所指结点对应的指数值，有 3 种情况：
>    （1）当`p1->expn == p2->expn`时，将两个结点中的系数相加。若和不为零，则修改`p1`所指结点的系数值，同时删除`p2`所指结点；若和为零，则删除`p1`和`p2`所指结点。
>    （2）当`p1->expn < p2->expn`时，摘取`p1`所指结点插入到和多项式链表中去。
>    （3）当`p1->expn > p2->expn`时，摘取`p2`所指结点插入到和多项式链表中去。
> 4. 将非空多项式的剩余段插入到`p3`所指结点之后。
> 5. 释放`Pb`的头结点。

```C++{.line-numbers}
// 多项式加法：Pa=Pa+Pb，利用两个多项式的结点构成和多项式
void AddPolyn(Polynomial &Pa, Polynomial &Pb)
{
    PNode *p1 = Pa->next; // p1 初值指向 Pa 的首元结点
    PNode *p2 = Pb->bext; // p2 初值指向 Pb 的首元结点
    PNode *p3 = Pa; // p3 指向和多项式的当前结点，初值为 Pa
    
    while (p1 && p2)
    {
        if (p1->expn == p2->expn) // 指数相等
        {
            sum = p1->coef + p2->coef; // sum 保存两项的系数和
            if (sum != 0) // 系数和不为 0
            {
                p1->coef = sum; // 将 Pa 当前结点的系数值修改为系数和
                p3->next = p1; // 将修改后的 Pa 当前结点链在 p3 之后
                p3 = p1; // p3 向后移动
                p1 = p1->next; // p1 向后移动
                // 删除 Pb 当前结点
                PNode *r = p2;
                p2 = p2->next;
                delete r;
            }
            else // 系数和为 0
            {
                // 删除 Pa 当前结点
                PNode *r = p1;
                p1 = p1->next;
                delete r;
                // 删除 Pb 当前结点
                r = p2;
                p2 = p2->next;
                delete r;
            }
        }
        else if (p1->expn < p2->expn) // Pa 当前结点的指数值小
        {
            p3->next = p1; // 将 p1 链在 p3 之后
            p3 = p1; // p3 向后移动
            p1 = p1->next; // p1 向后移动
        }
        else // Pb 当前结点的指数值小
        {
            p3->next = p2; // 将 p2 链在 p3 之后
            p3 = p2; // p3 向后移动
            p2 = p2->next; // p2 向后移动
        }
    }
    
    p3->next = p1 ? p1 : p2; // 插入非空多项式的剩余段
    delete Pb; // 释放 Pb 的头结点
}
```

假设两个多项式的项数分别为 $m$ 和 $n$，该算法的时间复杂度为 $O(m+n)$，空间复杂度为 $O(1)$。

一元多项式的减法和乘法运算可以利用多项式加法的算法来实现。对于减法运算，只需要对要减的多项式的每项系数进行取反，然后再调用加法运算`AddPolyn`即可。

多项式的乘法运算可以分解为一系列的加法运算。假设 $A(x)$ 和 $B(x)$ 为多项式，则

$$
\begin{equation*}
\begin{split}
    M(x)&=A(x)B(x)\\
    &=A(x)\times(b_1x^{e_1}+b_2x^{e_2}+\cdots+b_nx^{e_n})\\
    &=\sum_{i=1}^n b_iA(x)x^{e_i}
\end{split}
\end{equation*}
$$

# 第3章 栈和队列

## 3.1 栈

### 3.1.1 栈的定义和特点

**栈**（stack）是限定仅在表尾进行插入或删除操作的线性表。栈的表尾端称为**栈顶**（top），表头端称为**栈底**（bottom）。不含元素的空表称为**空栈**。

假设栈 $S=(a_1,a_2,\cdots,a_n)$，则称 $a_1$ 为栈底元素，$a_n$ 为栈顶元素。栈中元素按 $a_1,a_2,\cdots,a_n$ 的次序进栈，退栈的第一个元素应为栈顶元素。栈的修改是按后进先出的原则进行的，因此，栈又称为**后进先出**（Last In First Out，LIFO）的线性表。

### 3.1.2 栈的类型定义

栈的抽象数据类型定义：

$$
\begin{aligned}
    &\texttt{ADT Stack \{}\\
    &\texttt{\quad 数据对象：$D=\{a_i\,|\,a_i\in \text{ElemSet},\,i=1,2,\cdots,n,\,n\geqslant0\}$}\\
    &\texttt{\quad 数据关系：$R=\{\textrm{<}a_{i-1},a_i\textrm{>}|\,a_{i-1},a_i\in D,\,i=2,\cdots,n\}$}\\
    &\texttt{\qquad\qquad\qquad 约定\,$a_n$\,为栈顶，$a_1$\,为栈底}\\
    &\texttt{\quad 基本操作：}\\
    &\texttt{\qquad InitStack(\&S)}\\
    &\texttt{\qquad\quad 操作结果：构造一个空栈\,S}\\
    &\texttt{\qquad DestroyStack(\&S)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在}\\
    &\texttt{\qquad\quad 操作结果：栈\,S\,被销毁}\\
    &\texttt{\qquad ClearStack(\&S)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在}\\
    &\texttt{\qquad\quad 操作结果：将\,S\,清空}\\
    &\texttt{\qquad StackEmpty(S)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在}\\
    &\texttt{\qquad\quad 操作结果：若栈\,S\,为空栈，则返回\,true，否则返回\,false}\\
    &\texttt{\qquad StackLength(S)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在}\\
    &\texttt{\qquad\quad 操作结果：返回\,S\,的元素个数，即栈的长度}\\
    &\texttt{\qquad GetTop(S)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在且非空}\\
    &\texttt{\qquad\quad 操作结果：返回\,S\,的栈顶元素，不修改栈顶指针}\\
    &\texttt{\qquad Push(\&S, e)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在}\\
    &\texttt{\qquad\quad 操作结果：插入元素\,e\,为新的栈顶元素}\\
    &\texttt{\qquad Pop(\&S, \&e)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在且非空}\\
    &\texttt{\qquad\quad 操作结果：删除\,S\,的栈顶元素，并用\,e\,返回其值}\\
    &\texttt{\qquad StackTraverse(S)}\\
    &\texttt{\qquad\quad 初始条件：栈\,S\,已存在且非空}\\
    &\texttt{\qquad\quad 操作结果：从栈底到栈顶依次对\,S\,的每个数据元素进行访问}\\
    &\texttt{\} ADT Stack}
\end{aligned}
$$

和线性表类似，栈也有两种存储表示方法，分别称为顺序栈和链栈。

### 3.1.3 顺序栈的表示和实现

顺序栈的定义如下：

```C{.line-numbers}
#define MAXSIZE 100 // 顺序栈存储空间的初始分配量

typedef struct
{
    SElemType *base; // 栈底指针
    SElemType *top; // 栈顶指针
    int stacksize; // 栈可用的最大容量
} SqStack;
```

`base`为栈底指针，初始化完成后，`base`始终指向栈底的位置。若`base`的值为`NULL`，则表明栈结构不存在。`top`为栈顶指针，其初值指向栈底。每当插入新的栈顶元素时，指针`top`增 1；删除栈顶元素时，指针`top`减 1。因此，栈空时，`top`和`base`的值相等，都指向栈底；栈非空时，`top`始终指向栈顶元素的上一个位置。

> **算法 3.1**&nbsp;&nbsp;&nbsp;&nbsp;顺序栈的初始化
>
> 1. 为顺序栈动态分配一个最大容量为`MAXSIZE`的数组空间，使`base`指向这段空间的基地址，即栈底。
> 2. 栈顶指针`top`初始化为`base`，表示栈为空。
> 3. `stacksize`置为栈的最大容量`MAXSIZE`。

```C++{.line-numbers}
// 构造一个空栈 S
Status InitStack(SqStack &S)
{
    S.base = new SElemType[MAXSIZE]; // 为顺序栈动态分配一个最大容量为 MAXSIZE 的数组空间
    if (!S.base) exit(OVERFLOW); // 存储分配失败
    
    S.top = S.base; // top 初始为 base，空栈
    S.stacksize = MAXSIZE; // stacksize 置为栈的最大容量 MAXSIZE
    return OK;
}
```

> **算法 3.2**&nbsp;&nbsp;&nbsp;&nbsp;顺序栈的入栈
>
> 1. 判断栈是否满，若满则返回`ERROR`。
> 2. 将新元素压入栈顶，栈顶指针加 1。

```C{.line-numbers}
// 插入元素 e 为新的栈顶元素
Status Push(SqStack &S, SElemType e)
{
    if (S.top - S.base == S.stacksize) // 栈满
        return ERROR;
    *S.top = e; // 元素 e 压入栈顶
    S.top++; // 栈顶指针加 1
    return OK;
}
```

> **算法 3.3**&nbsp;&nbsp;&nbsp;&nbsp;顺序栈的出栈
>
> 1. 判断栈是否空，若空则返回`ERROR`。
> 2. 栈顶指针减 1，栈顶元素出栈。

```C{.line-numbers}
// 删除 S 的栈顶元素，用 e 返回其值
Status Pop(SqStack &S, SElemType &e)
{
    if (S.top == S.base) // 栈空
        return ERROR;
    S.top--; // 栈顶指针减 1
    e = *S.top; // 将栈顶元素赋给 e
    return
}
```

> **算法 3.4**&nbsp;&nbsp;&nbsp;&nbsp;取顺序栈的栈顶元素

```C{.line-numbers}
// 返回 S 的栈顶元素，不修改栈顶指针
SElemType GetTop(SqStack S)
{
    if (S.top != S.base) // 栈非空
        return *(S.top - 1); // 返回栈顶元素的值
}
```

### 3.1.4 链栈的表示和实现

链栈是指采用链式存储结构实现的栈。通常链栈用单链表来表示。链栈的结点结构与单链表的结构相同，在此用`StackNode`表示，定义如下：

```C{.line-numbers}
typedef struct StackNode
{
    SElemType data;
    struct StackNode *next;
} StackNode, *LinkStack;
```

由于栈的主要操作是在栈顶插入和删除，因此以链表的头部作为栈顶是最方便的，而且不必要附加头结点。

> **算法 3.5**&nbsp;&nbsp;&nbsp;&nbsp;链栈的初始化

```C{.line-numbers}
// 构造一个空栈 S，栈顶指针置空
Status InitStack(LinkStack &S)
{
    S = NULL;
    return OK;
}
```

> **算法 3.6**&nbsp;&nbsp;&nbsp;&nbsp;链栈的入栈
>
> 1. 为入栈元素`e`分配空间，用指针`p`指向。
> 2. 将新结点数据域置为`e`。
> 3. 将新结点插入栈顶。
> 4. 修改栈顶指针为`p`。

```C++{.line-numbers}
// 在栈顶插入元素 e
Status Push(LinkStack &S, SElemType e)
{
    StackNode *p = new StackNode; // 生成新结点
    p->data = e; // 将新结点数据域置为 e
    p->next = S; // 将新结点插入栈顶
    S = p; // 栈顶指针修改为 p
    return OK;
}
```

> **算法 3.7**&nbsp;&nbsp;&nbsp;&nbsp;链栈的出栈
>
> 1. 判断栈是否为空，若空则返回`ERROR`。
> 2. 将栈顶元素赋给`e`。
> 3. 临时保存栈顶元素的空间，以备释放。
> 4. 修改栈顶指针，指向新的栈顶元素。
> 5. 释放原栈顶元素的空间。

```C++{.line-numbers}
// 删除 S 的栈顶元素，用 e 返回其值
Status Pop(LinkStack &S, SElemType &e)
{
    if (S == NULL) return ERROR; // 栈空
    e = S->data; // 将栈顶元素赋给 e
    StackNode *p = S; // 用 p 临时保存栈顶元素空间，以备释放
    S = S->next; // 修改栈顶指针
    delete p; // 释放原栈顶元素的空间
    return OK;
}
```

> **算法 3.8**&nbsp;&nbsp;&nbsp;&nbsp;取链栈的栈顶元素

```C{.line-numbers}
SElemType GetTop(LinkStack S)
{
    if (S != NULL) // 栈非空
        return S->data; // 返回栈顶元素的值
}
```

## 3.2 栈与递归

### 3.2.1 采用递归算法解决的问题

所谓递归是指，若在一个函数、过程或者数据结构定义的内部又直接（或间接）出现定义本身的应用，则称它们是递归的，或者是递归定义的。在以下三种情况下，常常使用递归的方法。

#### 3.2.1.1 定义是递归的

例如，阶乘函数是递归定义的：

$$
\text{Fact}(n)=\begin{cases}
    1 &n=0\\
    n\times\text{Fact}(n-1) &n>0
\end{cases}
$$

可以使用递归过程来求解阶乘函数。

```C{.line-numbers}
long Fact(long n)
{
    if (n == 0) // 递归终止条件
        return 1;
    else // 递归步骤
        return n * Fact(n - 1);
}
```

又如，二阶 Fibonacci 数列也是递归定义的：

$$
\text{Fib}(n)=\begin{cases}
    1 &n=1\,或\,n=2\\
    \text{Fib}(n-1)+\text{Fib}(n-2) &其他
\end{cases}
$$

Fibonacci 数列的递归程序如下：

```C{.line-numbers}
long Fib(long n)
{
    if (n == 1 || n == 2) // 递归终止条件
        return 1;
    else // 递归步骤
        return Fib(n - 1) + Fib(n - 2);
}
```

对于这类复杂问题，如果能够分解成几个相对简单且解法相同或类似的子问题来求解，便称作递归求解。这种分解-求解的策略叫做“分治法”。

采取“分治法”进行递归求解的问题需要满足以下三个条件：

1. 能将一个问题转变成一个新问题，而新问题与原问题的解法相同或类同，不同的仅是处理的对象，并且这些处理对象更小且变化有规律。
2. 可以通过上述转化而是问题简化。
3. 必须有一个明确的递归出口，或称递归的边界。

“分治法”求解递归问题算法的一般形式为：

```C
void p(参数表)
{
    if (递归结束条件成立) // 递归终止条件
        可直接求解;
    else // 递归步骤
        p(较小的参数);
}
```

#### 3.2.1.2 数据结构是递归的

某些数据结构本身具有递归的特性，则它们的操作可以递归地描述。例如，对于链表，其结点`LNode`的定义由数据域`data`和指针域`next`组成，而指针域是一种指向`LNode`类型的指针，即`LNode`的定义中又用到了其自身，所以链表是一种递归的数据结构。

对于递归的数据结构，相应算法采用递归的方法来实现特别方便。例如，遍历链表结点的递归算法如下：

> **算法 3.9**&nbsp;&nbsp;&nbsp;&nbsp;遍历链表结点的递归算法
>
> 1. 如果`p`为`NULL`，递归结束返回。
> 2. 否则输出`p->data`，`p`指向后继结点继续递归。

```C++{.line-numbers}
void TraverseList(LinkList p)
{
    if (p == NULL) // 递归终止
        return;
    else
    {
        cout << p->data << endl;
        TraverseList(p->next); // p 指向后继结点继续递归
    }
}
```

在递归算法中，如果当递归结束条件成立，只执行`return`操作时，“分治法”求解递归问题算法的一般形式可以简化为：

```C
void p(参数表)
{
    if (递归结束条件不成立)
        p(较小的参数);
}
```

因此，算法 3.9 可以简化为：

```C++{.line-numbers}
void TraverseList(LinkList p)
{
    if (p)
    {
        cout << p->data << endl;
        TraverseList(p->next);
    }
}
```

#### 3.2.1.3 问题的解法是递归的

**【例 3.1】**&nbsp;&nbsp;&nbsp;&nbsp;n 阶 Hanoi 塔问题

假设有 3 个分别命名为 A、B 和 C 的塔座，在塔座 A 上插有 $n$ 个直径大小各不相同，从小到大编号为 $1,2,\cdots,n$ 的圆盘（如图 3.1 所示）。要求将塔座 A 上的 $n$ 个圆盘移动到塔座 C 上，并仍按同样顺序叠排。圆盘移动时必须遵循下列规则：

1. 每次只能移动一个圆盘。
2. 圆盘可以插在 A、B 和 C 中的任一塔座上。
3. 任何时刻都不能将一个较大的圆盘压在较小的圆盘之上。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图3.1-Hanoi塔问题.2bgubikxiysk.png">
    <br>
    图 3.1&nbsp;&nbsp;&nbsp;&nbsp;Hanoi 塔问题
</div>

**解：** 设 A 柱上最初的圆盘总数为 $n$，则当 $n=1$ 时，只要将编号为 1 的圆盘从塔座 A 直接移至塔座 C 上即可；否则，执行以下三步：

1. 用 C 柱做过渡，将 A 柱上的 $n-1$ 个圆盘移到 B 柱上；
2. 将 A 柱上最后一个圆盘直接移到 C 柱上；
3. 用 A 柱做过渡，将 B 柱上的 $n-1$ 个圆盘移到 C 柱上。

具体移动过程如图 3.1 所示，图中 $n=4$。

根据这种解法，如何将 $n-1$ 个圆盘从一个塔座移至另一个塔座的问题是一个和原问题具有相同特征属性的问题，只是问题的规模小 1，因此可以用同样的方法求解。

> **算法 3.10**&nbsp;&nbsp;&nbsp;&nbsp;Hanoi 塔问题的递归算法
>
> 1. 如果 $n=1$，则直接将编号为 1 的圆盘从 A 移到 C，递归结束。
> 2. 否则：
>    （1）递归，将 A 上编号为 1 至 $n-1$ 的圆盘移到 B，C 做辅助塔。
>    （2）直接将编号为 $n$ 的圆盘从 A 移到 C。
>    （3）递归，将 B 上编号为 1 至 $n-1$ 的圆盘移到 C，A 做辅助塔。
>
> 为了便于描述算法，将搬动操作定义为`move(A, n, C)`，是指将编号为 n 的圆盘从 A 移到 C。同时设置一个初值为 0 的全局变量`m`，对搬动进行计数。

```C++{.line-numbers}
int m = 0;

void move(char A, int n, char C)
{
    m++;
    cout << m << "," << n << "," << A << "," << C << endl;
}

// 将塔座 A 上的 n 个圆盘按规则搬到 C 上，B 做辅助塔
void Hanoi(int n, char A, char B, char C)
{
    if (n == 1)
    {
        move(A, 1, C); // 将编号为 1 的圆盘从 A 移到 C
    }
    else
    {
        Hanoi(n - 1, A, C, B); // 将 A 上编号为 1 至 n-1 的圆盘搬到 B 上，C 做辅助塔
        move(A, n, C); // 编号为 n 的圆盘从 A 移到 C
        Hanoi(n - 1, B, A, C); // 将 B 上编号为 1 至 n-1 的圆盘搬到 C 上，A 做辅助塔
    }
}
```

### 3.2.2 递归过程与递归工作栈

在高级语言编制的程序中，调用函数和被调用函数之间的链接及信息交换需要通过栈来进行。

当在一个函数的运行期间调用另一个函数时，在运行被调用函数之前，系统需先完成 3 件事：

1. 将所有的实参、返回地址等信息传递给被调用函数保存。
2. 为被调用函数的局部变量分配存储区。
3. 将控制转移到被调函数的入口。

从被调用函数返回调用函数之前，系统也应完成 3 件工作：

1. 保存被调用函数的计算结果。
2. 释放被调用函数的数据区。
3. 依照被调用函数保存的返回地址将控制转移到调用函数。

当有多个函数构成嵌套调用时，按照“后调用先返回”原则，上述函数之间的信息传递和控制转移必须通过栈来实现。系统将整个程序运行时所需的数据空间安排在一个栈中，每当调用一个函数时，就为它在栈顶分配一个存储区；每当从一个函数退出时，就释放它的存储区。当前正在运行的函数的数据区必在栈顶。

一个递归函数的运行过程类似于多个函数的嵌套调用，只是调用函数和被调用函数是同一个函数。假设调用该递归函数的主函数为第 0 层，则从主函数调用递归函数为进入第 1 层；从第 $i$ 层递归调用本函数为进入下一层，即第 $i+1$ 层；退出第 $i$ 层递归应返回至上一层，即第 $i$ 层。

为了保证递归函数正确执行，系统需设立一个**递归工作栈**作为整个递归函数运行期间使用的数据存储区。每一层递归所需信息构成一个**工作记录**，其中包括所有的实参、所有的局部变量，以及上一层的返回地址。每进入一层递归，就产生一个新的工作记录压入栈顶；每退出一层递归，就从栈顶弹出一个工作记录。当前执行层的工作记录必是递归工作栈栈顶的工作记录，称这个记录为**活动记录**。

### 3.2.3 递归算法的效率分析

#### 3.2.3.1 时间复杂度的分析

当一个算法中包含递归调用时，其时间复杂度的分析可以转化为一个递归方程求解。迭代法是求解递归方程的一种常用方法，其基本步骤是迭代地展开递归方程的右端，使之成为一个非递归的和式，然后通过对和式的估计来达到对方程左端的估计。

下面以阶乘函数`Fact(n)`为例，说明通过迭代法求解递归方程来计算时间复杂度的方法。

设`Fact(n)`的执行时间是 $T(n)$。此递归函数中语句`if (n == 0) return 1;`的执行时间是 $O(1)$，递归调用`Fact(n - 1)`的执行时间是 $T(n-1)$，所以`else return n * Fact(n - 1);`的执行时间是 $O(1)+T(n-1)$。其中，设两数相乘和赋值操作的执行时间为 $O(1)$，则对某常数 $C$、$D$ 有如下递归方程：

$$
T(n)=\begin{cases}
    D & n=0\\
    C+T(n-1) & n\geqslant 1
\end{cases}
$$

设 $n>2$，利用上式对 $T(n-1)$ 展开，即在上式中用 $n-1$ 代替 $n$ 得到

$$
T(n-1)=C+T(n-2)
$$

再代入 $T(n)=C+T(n-1)$ 中，有

$$
T(n)=2C+T(n-2)
$$

同理，当 $n>3$ 时有

$$
T(n)=3C+T(n-3)
$$

以此类推，当 $n>i$ 时有

$$
T(n)=iC+T(n-i)
$$

最后，当 $i=n$ 时有

$$
T(n)=nC+T(0)=Cn+D
$$

求得递归方程的解为：$T(n)=O(n)$。

采用这种方法计算 Fibonacci 数列和 Hanoi 塔问题递归算法的时间复杂度均为 $O(2^n)$。

#### 3.2.3.2 空间复杂度的分析

递归函数在执行时，系统需设立一个递归工作栈存储每一层递归所需的信息，此工作栈是递归函数执行的辅助空间。因此，分析递归算法的空间复杂度需要分析工作栈的大小。

对于递归算法，空间复杂度为

$$
S(n)=O(f(n))
$$

其中，$f(n)$ 为递归工作栈中工作记录的个数与问题规模 $n$ 的函数关系。

根据这种分析方法可得，阶乘函数、Fibonacci 数列、Hanoi 塔问题的递归算法的空间复杂度均为 $O(n)$。

### 3.2.4 利用栈将递归转换为非递归的方法

递归程序在执行时需要系统提供隐式栈来实现。对于一般的递归过程，仿照递归算法执行过程中递归工作栈的状态变化可直接写出相应的非递归算法。这种利用栈消除递归过程的步骤如下：

1. 设置一个工作栈存放递归工作记录（包括实参、返回地址及局部变量等）。
2. 进入非递归调用入口，将调用程序传来的实参和返回地址入栈。
3. 进入递归调用入口：当不满足递归结束条件时，逐层递归，将实参、返回地址即局部变量入栈。这一过程可用循环语句来实现——模拟递归分解的过程。
4. 递归结束条件满足，将达到递归出口的给定常数作为当前的函数值。
5. 返回处理：在栈不空的情况下，反复退出栈顶记录，根据记录中的返回地址进行题意规定的操作。即逐层计算当前函数值，直至栈空为止——模拟递归求值过程。

通过以上步骤，可将任何递归算法改写成非递归算法。但改写后的非递归算法和原来比较起来，结构不够清晰，可读性差，有的还需要经过一系列的优化。

## 3.3 队列

### 3.3.1 队列的定义和特点

**队列**（queue）是一种**先进先出**（First In First Out，FIFO）的线性表。它只允许在表的一端进行插入，在另一端删除元素。在队列中，允许插入的一端称为**队尾**（rear），允许删除的一端称为**队头**（front）。

假设队列为 $q=(a_1,a_2,\cdots,a_n)$，则 $a_1$ 为队头元素，$a_n$ 为队尾元素。队列中的元素按照 $a_1,a_2,\cdots,a_n$ 的次序入队，退出队列也只能按照这个次序依次退出。

### 3.3.2 队列的类型定义

$$
\begin{aligned}
    &\texttt{ADT Queue \{}\\
    &\texttt{\quad 数据对象：$D=\{a_i\,|\,a_i\in \text{ElemSet},\,i=1,2,\cdots,n,\,n\geqslant0\}$}\\
    &\texttt{\quad 数据关系：$R=\{\textrm{<}a_{i-1},a_i\textrm{>}|\,a_{i-1},a_i\in D,\,i=2,\cdots,n\}$}\\
    &\texttt{\qquad\qquad\qquad 约定\,$a_1$\,为队列头，$a_n$\,为队列尾}\\
    &\texttt{\quad 基本操作：}\\
    &\texttt{\qquad InitQueue(\&Q)}\\
    &\texttt{\qquad\quad 操作结果：构造一个空队列\,Q}\\
    &\texttt{\qquad DestroyQueue(\&Q)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在}\\
    &\texttt{\qquad\quad 操作结果：队列\,Q\,被销毁}\\
    &\texttt{\qquad ClearQueue(\&Q)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在}\\
    &\texttt{\qquad\quad 操作结果：将\,Q\,清空}\\
    &\texttt{\qquad QueueEmpty(Q)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在}\\
    &\texttt{\qquad\quad 操作结果：若\,Q\,为空栈，则返回\,true，否则返回\,false}\\
    &\texttt{\qquad QueueLength(Q)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在}\\
    &\texttt{\qquad\quad 操作结果：返回\,Q\,的元素个数，即队列的长度}\\
    &\texttt{\qquad GetHead(Q)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在且非空}\\
    &\texttt{\qquad\quad 操作结果：返回\,Q\,的队头元素}\\
    &\texttt{\qquad EnQueue(\&Q, e)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在}\\
    &\texttt{\qquad\quad 操作结果：插入元素\,e\,为新的队尾元素}\\
    &\texttt{\qquad DeQueue(\&Q, \&e)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在且非空}\\
    &\texttt{\qquad\quad 操作结果：删除\,Q\,的队头元素，并用\,e\,返回其值}\\
    &\texttt{\qquad QueueTraverse(Q)}\\
    &\texttt{\qquad\quad 初始条件：队列\,Q\,已存在且非空}\\
    &\texttt{\qquad\quad 操作结果：从队头到队尾依次对\,Q\,的每个数据元素进行访问}\\
    &\texttt{\} ADT Queue}
\end{aligned}
$$

### 3.3.3 循环队列——队列的顺序表示和实现

队列的顺序存储结构表示如下：

```C{.line-numbers}
#define MAXQSIZE 100 // 队列可能达到的最大长度

typedef struct
{
    QElemType *base; // 存储空间的基地址
    int front; // 头指针
    int rear; // 尾指针
} SqQueue;
```

为了在 C 语言中描述方便起见，在此约定：初始化创建空队列时，令`front = rear = 0`；每当插入新的队尾元素时，尾指针`rear`增 1；每当删除队头元素时，头指针`front`增 1。因此，在非空队列中，头指针始终指向队头元素，尾指针始终指向队尾元素的下一个位置，如图 3.2 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图3.2-顺序分配的队列中头、尾指针和元素之间的关系.1pm44tbltc00.png">
    <br>
    图 3.2&nbsp;&nbsp;&nbsp;&nbsp;顺序分配的队列中头、尾指针和元素之间的关系
</div>

当队列处于图 3.2(d) 所示的状态时不可再继续插入新的队尾元素，否则会出现溢出现象。事实上，此时队列的实际可用空间并未占满，所以这种现象称为“假溢出”。这是由“队尾入队，队头出队”这种受限制的操作造成的。

解决“假溢出”问题的办法是将顺序队列变为一个环状的空间，称之为**循环队列**，如图 3.3 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图3.3-循环队列.4rcsaqpyjx40.png">
    <br>
    图 3.3&nbsp;&nbsp;&nbsp;&nbsp;循环队列
</div>

头、尾指针以及队列元素之间的关系不变，只是在循环队列中，头、尾指针“依环状增 1”的操作可用模运算来实现。通过取模，头指针和尾指针就可以在顺序表空间内以头尾衔接的方式循环移动。

对于循环队列，不能以头、尾指针的值是否相同来判别队列空间是满还是空。如图 3.4 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图3.4-循环队列中头、尾指针和元素之间的关系.6lydueg0tuo0.png">
    <br>
    图 3.4&nbsp;&nbsp;&nbsp;&nbsp;循环队列中头、尾指针和元素之间的关系
</div>

在图 3.4(b) 中，队列空间被占满，此时头、尾指针相同。在图 3.4(c) 中，队列为空，此时头、尾指针也是相同的。因此，不能以头、尾指针的值是否相同来判别循环队列是满还是空。

判断循环队列是满还是空的方法有两种：

1. 少用一个元素空间，即队列空间大小为 $m$ 时，有 $m-1$ 个元素就认为是队满，如图 3.4(d) 所示。此时判断队空的条件为`Q.front == Q.rear`，判断队满的条件为`(Q.rear + 1) % MAXSIZE == Q.front`。
2. 另设一个标志位以区别队列是空还是满。

下面给出用第一种方法实现循环队列的操作。

> **算法 3.11**&nbsp;&nbsp;&nbsp;&nbsp;循环队列的初始化
>
> 1. 为队列分配数组空间，`base`指向数组空间的首地址。
> 2. 头指针和尾指针置为零，表示队列为空。

```C++{.line-numbers}
// 构造一个空队列
Status InitQueue(SqQueue &Q)
{
    Q.base = new QElemType[MAXSIZE]; // 为队列分配数组空间
    if (!Q.base) // 存储分配失败
        exit(OVERFLOW);
    
    Q.front = 0; // 头指针置为 0
    Q.rear = 0; // 尾指针置为 0
    return OK;
}
```

> **算法 3.12**&nbsp;&nbsp;&nbsp;&nbsp;求循环队列的长度

```C{.line-numbers}
int QueueLength(SqQueue Q)
{
    return (Q.rear - Q.front + MAXSIZE) % MAXSIZE;
}
```

> **算法 3.13**&nbsp;&nbsp;&nbsp;&nbsp;循环队列的入队
>
> 1. 判断队列是否满，若满则返回`ERROR`。
> 2. 将新元素插入队尾。
> 3. 尾指针加 1。

```C{.line-numbers}
// 将元素 e 插入 Q 的队尾
Status EnQueue(SqQueue &Q, QElemType e)
{
    if ((Q.rear + 1) % MAXSIZE == Q.front) // 队满
        return ERROR;
    
    Q.base[Q.rear] = e; // 将新元素插入队尾
    Q.rear = (Q.rear + 1) % MAXSIZE; // 尾指针加 1
    return OK;
}
```

> **算法 3.14**&nbsp;&nbsp;&nbsp;&nbsp;循环队列的出队
>
> 1. 判断队列是否为空，若为空则返回`ERROR`。
> 2. 保存队头元素。
> 3. 头指针加 1。

```C{.line-numbers}
// 删除 Q 的队头元素，用 e 返回其值
Status DeQueue(SqQueue &Q, QElemType &e)
{
    if (Q.front == Q.rear) // 队空
        return ERROR;
    
    e = Q.base[Q.front]; // 保存队头元素
    Q.front = (Q.front + 1) % MAXSIZE; // 头指针加 1
    return OK;
}
```

> **算法 3.15**&nbsp;&nbsp;&nbsp;&nbsp;取循环队列的队头元素

```C{.line-numbers}
// 返回 Q 的队头元素，不修改头指针
QElemType GetHead(SqQueue Q)
{
    if (Q.front != Q.rear) // 队列非空
        return Q.base[Q.front]; // 返回队头元素
}
```

### 3.3.4 链队——队列的链式表示和实现

链队是指采用链式存储结构实现的队列。通常链队用单链表来表示。

一个链队需要两个分别指示队头和队尾的指针才能唯一确定。为了操作方便起见，给链队添加一个头结点，并令头指针始终指向头结点。队列的链式存储结构表示如下：

```C{.line-numbers}
typedef struct QNode
{
    QElemType data;
    struct QNode *next;
} QNode, *QueuePtr;

typedef struct
{
    QueuePtr front; // 头指针
    QueuePtr rear; // 尾指针
} LinkQueue;
```

> **算法 3.16**&nbsp;&nbsp;&nbsp;&nbsp;链队的初始化
>
> 1. 生成新结点作为头结点，队头和队尾指针指向此结点。
> 2. 头结点的指针域置空。

```C++{.line-numbers}
// 构造一个空队列 Q
Status InitQueue(LinkQueue &Q)
{
    Q.front = new QNode; // 生成新结点作为头结点
    Q.rear = Q.front; // 队尾指针指向头结点
    Q.front->next = NULL; // 头结点的指针域置空
    return OK;
}
```

> **算法 3.17**&nbsp;&nbsp;&nbsp;&nbsp;链队的入队
>
> 1. 为入队元素分配结点空间，用指针`p`指向。
> 2. 将新结点数据域置为`e`。
> 3. 将新结点插入到队尾。
> 4. 修改队尾指针为`p`。

```C++{.line-numbers}
// 将元素 e 插入 Q 的队尾
Status EnQueue(LinkQueue &Q, QElemType e)
{
    QNode *p = new QNode; // 为入队元素分配结点空间
    p->data = e; // 设置新结点的数据域
    p->next = NULL; // 新结点的指针域设置为空
    Q.rear->next = p; // 将新结点插入到队尾
    Q.rear = p; // 修改队尾指针
    return OK;
}
```

> **算法 3.18**&nbsp;&nbsp;&nbsp;&nbsp;链队的出队
>
> 1. 判断队列是否为空，若空则返回`ERROR`。
> 2. 临时保存队头元素的空间，以备释放。
> 3. 修改队头指针，指向下一个结点。
> 4. 判断出队元素是否为最后一个元素，若是，则将队尾指针指向头结点。
> 5. 释放原队头元素的空间。

```C++{.line-numbers}
// 删除 Q 的队头元素，用 e 返回其值
Status DeQueue(LinkQueue &Q, QElemType &e)
{
    if (Q.front == Q.rear) // 若队列为空，则返回 ERROR
        return ERROR;
    
    QNode *p = Q.front->next; // p 指向队头元素
    e = p->data; // e 保存队头元素的值
    Q.front->next = p->next; // 修改头指针
    
    if (Q.rear == p) // 如果是最后一个元素，则将队尾指针指向头结点
        Q.rear = Q.front;
    delete p; // 释放原队头元素的空间
    return OK;
}
```

> **算法 3.19**&nbsp;&nbsp;&nbsp;&nbsp;取链队的队头元素

```C{.line-numbers}
// 返回 Q 的队头元素
QElemType GetHead(LinkQueue Q)
{
    if (Q.front != Q.rear) // 队列非空
        return Q.front->next->data; // 返回队头元素的值
}
```

## 3.4 栈和队列的应用

### 3.4.1 数制转换

十进制数 $N$ 到其他 $d$ 进制数的转换算法基于下列原理：

$$
N=(N\space\text{div}\space d)\times d+N\bmod d
$$

其中，$\text{div}$ 为整除运算，$\bmod$ 为求余运算。

例如，$(1348)_{10}=(2504)_8$，计算过程如下：

| $N$  | $N\space\text{div}\space 8$ | $N\bmod 8$ |
| :--: | :-------------------------: | :--------: |
| 1348 |             168             |     4      |
| 168  |             21              |     0      |
|  21  |              2              |     5      |
|  2   |              0              |     2      |

上述计算过程是从低位到高位顺序产生 $d$ 进制数的各个数位，而输出过程应从高位到低位进行，恰好和计算过程相反，因此可以使用栈来解决这个问题。在计算过程中依次将得到的余数压入栈中，计算完毕后，再依次弹出栈中的余数并输出。

> **算法 3.20**&nbsp;&nbsp;&nbsp;&nbsp;数制的转换
>
> 1. 初始化一个空栈`S`。
> 2. 当十进制数 $N$ 非零时，循环执行以下操作：
>    （1）把 $N$ 与 $d$ 求余得到的余数压入栈`S`。
>    （2）$N$ 更新为 $N$ 与 $d$ 的商。
> 3. 当栈`S`非空时，循环执行以下操作：
>    （1）弹出栈顶元素`e`。
>    （2）输出`e`。

```C++{.line-numbers}
// 对于任意一个非负十进制整数，打印输出与其等值的 d 进制数
void conversion(int N, int d)
{
    InitStack(S); // 初始化空栈 S
    
    while (N != 0) // 当 N 非零时，循环
    {
        Push(S, N % d); // 把 N 与 d 求余得到的余数压入栈 S
        N = N / d; // N 更新为 N 与 d 的商
    }
    
    while (!StackEmpty(S)) // 当栈 S 非空时，循环
    {
        Pop(S, e); // 弹出栈顶元素 e
        cout << e; // 输出 e
    }
}
```

该算法的时间和空间复杂度均为 $O(\log_d N)$。

### 3.4.2 括号匹配的检验

假设表达式中允许包含两种括号：圆括号和方括号，其嵌套的顺序随意。检验括号是否匹配时，每当读入一个左括号，则直接入栈，等待相匹配的同类右括号；每当读入一个右括号，若与当前栈顶的左括号类型相同，则二者匹配，将栈顶的左括号出栈，直到表达式扫描完毕。

当读入右括号时，如果栈为空或栈顶的左括号与当前右括号类型不同，则匹配失败。如果表达式扫描结束时栈不为空，说明匹配失败。

> **算法 3.21**&nbsp;&nbsp;&nbsp;&nbsp;括号的匹配
>
> 1. 初始化一个空栈`S`。
> 2. 设置一个标记性变量`flag`，用来标记匹配结果以控制循环及返回结果，`true`表示正确匹配，`false`表示错误匹配。`flag`初值为`true`。
> 3. 扫描表达式，依次读入字符`ch`，如果表达式没有扫描完毕或`flag`非零，则循环执行以下操作：
>    - 若`ch`是左括号`[`或`(`，则将其压入栈。
>    - 若`ch`是右括号`)`，则根据当前栈顶元素的值分情况考虑：若栈非空且栈顶元素是`(`，则正确匹配；否则错误匹配，`flag`置为`false`。
>    - 若`ch`是右括号`]`，则根据当前栈顶元素的值分情况考虑：若栈非空且栈顶元素是`[`，则正确匹配；否则错误匹配，`flag`置为`false`。
> 4. 退出循环后，如果栈空且`flag`值为`true`，则匹配成功，返回`true`，否则返回`false`。

```C{.line-numbers}
// 检验表达式中所含括号是否正确匹配，如果匹配则返回 true，否则返回 false
// 表达式以 # 结束
Status Matching()
{
    InitStack(S); // 初始化空栈
    bool flag = true; // 设置标记变量
    
    char ch;
    cin >> ch; // 读入第一个字符
    while(ch != '#' && flag)
    {
        switch (ch)
        {
            case '[':
            case '(':
                Push(S, ch); // 若是左括号，则将其压入栈
                break;
            case ')':
                if (!StackEmpty(S) && GetTop(S) == '(')
                    Pop(S, x); // 若栈非空且栈顶元素是'('，则正确匹配
                else
                    flag = false; // 否则，错误匹配
                break;
            case ']':
                if (!StackEmpty(S) && GetTop(S) == '[')
                    Pop(S, x); // 若栈非空且栈顶元素是'['，则正确匹配
                else
                    flag = false; // 否则，错误匹配
                break;
        }
        cin >> ch;
    }
    
    if (StackEmpty(S) && flag) // 若栈为空且 flag 为 true，则匹配成功
        return true;
    else
        return false;
}
```

此算法从头到尾扫描表达式中每个字符，若表达式的字符串长度为 $n$，则此算法的时间复杂度为 $O(n)$。算法在运行时所占用的辅助空间主要取决于栈的大小，而栈的空间大小不会超过 $n$，所以此算法的空间复杂度为 $O(n)$。

### 3.4.3 表达式求值

任何一个表达式都是由操作数（operand）、运算符（operator）和界限符（delimiter）组成的，统称它们为单词。一般地，操作数既可以是常数，也可以是被说明为变量或常量的标识符；运算符可以分为算术运算符、关系运算符和逻辑运算符 3 类；基本界限符有左右括号和表达式结束符等。

这里仅讨论简单算数表达式的求值问题，这种表达式只含加、减、乘、除 4 种运算符。下面把运算符和界限符统称为算符。

算符优先法根据算术四则运算规则确定的运算优先关系，实现对表达式的编译或解释执行。在表达式计算中先出现的运算符不一定先运算，具体运算顺序需要通过运算符优先关系的比较，确定合适的运算时机，而运算时机的确定可以借助栈来完成。将扫描到的不能进行运算的运算数和运算符先分别压入运算数栈和运算符栈中，在满足条件时再分别从栈中弹出进行运算。

算术四则运算遵循以下 3 条规则：

1. 先乘除，后加减。
2. 从左到右。
3. 先括号内，后括号外。

根据上述 3 条运算规则，在运算的每一步中，任意两个相继出现的算符 $\theta_1$ 和 $\theta_2$ 之间的优先关系，至多是下面 3 种关系之一：

1. $\theta_1<\theta_2$，$\theta_1$ 的优先权低于 $\theta_2$。
2. $\theta_1=\theta_2$，$\theta_1$ 的优先权等于 $\theta_2$。
3. $\theta_1>\theta_2$，$\theta_1$ 的优先权高于 $\theta_2$。

下表定义了算符之间的这种优先关系。

<div align="center">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/表3.1-算符间的优先关系.6j7iymcab8w0.png">
</div>

由规则 1，先乘除后加减，所以有 $“+”<“*”$、$“+”<“/”$、$“*”>“+”$、$“/”>“+”$ 等。

由规则 2，运算遵循左结合性，当两个运算符相同时，先出现的运算符优先级高，所以有 $“+”>“+”$、$“-”>“-”$、$“*”>“*”$、$“/”>“/”$。

由规则 3，括号内的优先级高，$+$、$-$、$*$ 和 $/$ 为 $\theta_1$ 时的优先级均低于 $($ 但高于 $)$。

表中的 $“(”=“)”$ 表示当左右括号相遇时，括号内的运算已经完成。为了便于实现，假设每个表达式均以 “#” 开始，以 “#” 结束，所以 $“\#”=“\#”$ 表示整个表达式求值完毕。$“)”$ 与 $“(”$、$“\#”$ 与 $“)”$ 以及 $“(”$ 与 $“\#”$ 之间无优先关系，这是因为表达式中不允许它们相继出现，一旦遇到这种情况，则可以认为出现了语法错误。

为实现算符优先算法，可以使用两个工作栈，一个称作`OPTR`，用以寄存运算符；另一个称作`OPND`，用以寄存操作数或运算结果。

> **算法 3.22**&nbsp;&nbsp;&nbsp;&nbsp;表达式求值
>
> 1. 初始化`OPTR`栈和`OPND`栈，将表达式起始符 “#” 压入`OPTR`栈。
> 2. 扫描表达式，读入第一个字符`ch`，如果表达式没有扫描完毕至 “#” 或`OPTR`的栈顶元素不为 “#” 时，则循环执行以下操作：
>    - 若`ch`不是运算符，则压入`OPND`栈，读入下一个字符`ch`。
>    - 若`ch`是运算符，则根据`OPTR`的栈顶元素和`ch`的优先级比较结果，做不同的处理：
>      - 若是`ch`优先级更高，则`ch`压入`OPTR`栈，读入下一字符`ch`。
>      - 若是栈顶元素优先级更高，则弹出`OPTR`栈顶的运算符，从`OPND`栈弹出两个数，进行相应运算，结果压入`OPND`栈。
>      - 若是等于，则`OPTR`的栈顶元素是 “(” 且`ch`是 “)”，这时弹出`OPTR`栈顶的 “(”，相当于括号匹配成功，然后读入下一字符`ch`。
> 3. `OPND`栈顶元素即为表达式求值结果，返回此元素。

```C++{.line-numbers}
// 算术表达式求值的算符优先算法，设 OPTR 和 OPND 分别为运算符栈和操作数栈
char EvaluateExpression()
{
    InitStack(OPND); // 初始化 OPND 栈
    InitStack(OPTR); // 初始化 OPTR 栈
    Push(OPTR, '#'); // 将表达式起始符 '#' 压入 OPTR 栈
    
    char ch;
    cin >> ch;
    while (ch != '#' || GetTop(OPTR) != '#')
    {
        if (!In(ch)) // ch 不是运算符则进 OPND 栈
        {
            Push(OPND, ch);
            cin >> ch;
        }
        else
        {
            switch (Precede(GetTop(OPTR), ch)) // 比较 OPTR 的栈顶元素和 ch 的优先级
            {
                case '<':
                    Push(OPTR, ch); // 当前字符 ch 压入 OPTR 栈
                    cin >> ch; // 读入下一字符
                    break;
                case '>':
                    Pop(OPTR, theta); // 弹出 OPTR 栈顶的运算符
                    Pop(OPND, b); // 弹出 OPND 栈顶的两个运算数
                    Pop(OPND, a);
                    Push(OPND, Operate(a, theta, b)); // 将运算结果压入 OPND 栈
                    break;
                case '=': // OPTR 的栈顶元素是 '('，且 ch 是 ')'
                    Pop(OPTR, x); // 弹出 OPTR 栈顶的 '('
                    cin >> ch; // 读入下一字符
                    break;
            }
        }
    }
    return GetTop(OPND); // OPND 栈顶元素即为表达式求值结果
}
```

算法中用到了 3 个自定义函数：`In`用于判定读入的字符`ch`是否为运算符，`Precede`用于判定`OPTR`栈顶元素与读入的运算符之间的优先关系，`Operate`用于进行二元运算。

上述算法中的操作数只能是一位数，因为这里使用的`OPND`栈是字符栈。如果要进行多位数的运算，需要将`OPND`栈改为数栈，读入的数字字符拼成数之后再入栈。

此算法从头到尾扫描表达式中每个字符，若表达式的字符串长度为 $n$，则此算法的时间复杂度为 $O(n)$。算法在运行时所占用的辅助空间主要取决于`OPTR`栈和`OPND`栈的大小，它们的空间大小之和不会超过 $n$，所以此算法的空间复杂度为 $O(n)$。

# 第4章 串、数组和广义表

## 4.1 串

### 4.1.1 串的定义

**字符串**（string）是由零个或多个字符顺序排列组成的有限序列，简称为**串**，一般记为

$$
s=“a_1\ a_2\cdots a_n”\quad(n\geqslant 0)
$$

其中，$s$ 是串的名，用双引号括起来的字符序列是串的值，$a_i\,(1\leqslant i\leqslant n)$ 可以是字母、数字或其他字符，串中字符的数目 $n$ 称为串的长度。零个字符的串称为**空串**（null string），其长度为零。

串中任意个连续的字符组成的子序列称为该串的**子串**，包含子串的串相应地称为**主串**。通常称字符在序列中的序号为该字符在串中的位置。子串在主串中的位置以子串的第一个字符在主串中的位置来表示。

称两个串是相等的，当且仅当这两个串的值相等。也就是说，只有当两个串的长度相等，并且各个对应位置的字符都相等时才相等。

由一个或多个空格组成的串称为**空格串**（blank string），其长度为串中空格字符的个数。为了清楚起见，使用符号 $\text{\O}$ 来表示空串。

### 4.1.2 串的抽象类型定义

$$
\begin{aligned}
    &\texttt{ADT String \{}\\
    &\texttt{\quad 数据对象：$D=\{a_i\,|\,a_i\in\text{CharacterSet},\,i=1,2,\cdots,n,\,n\geqslant 0\}$}\\
    &\texttt{\quad数据关系：$Rl=\{\textrm{<}a_{i-1},a_i\textrm{>}|\,a_{i-1},a_i\in D,\,i=1,2,\cdots,n\}$}\\
    &\texttt{\quad 基本操作：}\\
    &\texttt{\qquad StrAssign(\&T, chars)}\\
    &\texttt{\qquad\quad 初始条件：chars\,是字符串常量}\\
    &\texttt{\qquad\quad 操作结果：生成一个其值等于\,chars\,的串\,T}\\
    &\texttt{\qquad StrCopy(\&T, S)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,存在}\\
    &\texttt{\qquad\quad 操作结果：由串\,S\,复制得串\,T}\\
    &\texttt{\qquad StrEmpty(S)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,存在}\\
    &\texttt{\qquad\quad 操作结果：若\,S\,为空串，则返回\,true，否则返回\,false}\\
    &\texttt{\qquad StrCompare(S, T)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,和\,T\,存在}\\
    &\texttt{\qquad\quad 操作结果：若\,S$>$T，则返回值大于\,0；若\,S$=$T，则返回值为\,0；}\\
    &\texttt{\qquad\qquad\qquad\qquad 若\,S$<$T，则返回值小于\,0}\\
    &\texttt{\qquad StrLength(S)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,存在}\\
    &\texttt{\qquad\quad 操作结果：返回\,S\,的元素个数，称为串的长度}\\
    &\texttt{\qquad ClearString(\&S)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,存在}\\
    &\texttt{\qquad\quad 操作结果：将\,S\,清为空串}\\
    &\texttt{\qquad Concat(\&T, S1, S2)}\\
    &\texttt{\qquad\quad 初始条件：串\,S1\,和\,S2\,存在}\\
    &\texttt{\qquad\quad 操作结果：用\,T\,返回由\,S1\,和\,S2\,连接而成的新串}\\
    &\texttt{\qquad SubString(\&Sub, S, pos, len)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,存在，$1\leqslant\text{pos}\leqslant\text{StrLength(S)}$且$\,0\leqslant\text{len}\leqslant\text{StrLength(S)}-\text{pos}+1$}\\
    &\texttt{\qquad\quad 操作结果：用\,Sub\,返回串\,S\,的第\,pos\,个字符起长度为\,len\,的子串}\\
    &\texttt{\qquad Index(S, T, pos)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,和\,T\,存在，T\,是非空串，$1\leqslant\text{pos}\leqslant\text{StrLength(S)}$}\\
    &\texttt{\qquad\quad 操作结果：若主串\,S\,中存在和串\,T\,值相同的子串，则返回它在主串\,S\,中第\,pos}\\
    &\texttt{\qquad\qquad\qquad\qquad 个字符之后第一次出现的位置；否则返回值为\,0}\\
    &\texttt{\qquad Replace(\&S, T, V)}\\
    &\texttt{\qquad\quad 初始条件：串\,S、T\,和\,V\,存在，T\,是非空串}\\
    &\texttt{\qquad\quad 操作结果：用\,V\,替换主串\,S\,中出现的所有与\,T\,相等的不重叠的子串}\\
    &\texttt{\qquad StrInsert(\&S, pos, T)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,和\,T\,存在，$1\leqslant\text{pos}\leqslant\text{StrLength(S)}+1$}\\
    &\texttt{\qquad\quad 操作结果：在串\,S\,的第\,pos\,个字符之前插入串\,T}\\
    &\texttt{\qquad StrDelete(\&S, pos, len)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,存在，$1\leqslant\text{pos}\leqslant\text{StrLength(S)}-\text{len}+1$}\\
    &\texttt{\qquad\quad 操作结果：从串\,S\,中删除第\,pos\,个字符起长度为\,len\,的子串}\\
    &\texttt{\qquad DestroyString(\&S)}\\
    &\texttt{\qquad\quad 初始条件：串\,S\,存在}\\
    &\texttt{\qquad\quad 操作结果：串\,S\,被销毁}\\
    &\texttt{\} ADT String}
\end{aligned}
$$

### 4.1.3 串的存储结构

与线性表类似，串也有两种基本存储结构：顺序存储和链式存储。但考虑到存储效率和算法的方便性，串多采用顺序存储结构。

#### 4.1.3.1 串的顺序存储

类似于线性表的顺序存储结构，用一组地址连续的存储单元存储串值的字符序列。

按照预定义的大小，为每个定义的串变量分配一个固定长度的存储区，则可用定长数组如下描述：

```C{.line-numbers}
//-------串的定长顺序存储结构-------
#define MAXLEN 255 // 串的最大长度

typedef struct
{
    char ch[MAXLEN + 1]; // 存储串的一维数组
    int length; // 串的当前长度
} SString;
```

这种定义方式是静态的，在编译时刻就确定了串空间的大小。但多数情况下，串的操作是以串的整体形式参与的，串变量之间的长度相差较大，在操作中串值长度的变化也较大，这样为串变量设定固定大小的空间不尽合理。最好是根据实际需要，在程序执行过程中动态地分配和释放字符数组空间。

在 C 语言中，存在一个称之为“堆”（heap）的自由存储区，可以为每个新产生的串动态分配一块实际串长所需的存储空间，若分配成功，则返回一个指向起始地址的指针，作为串的基址。这种字符串的存储方式也称为串的堆式顺序存储结构，定义如下：

```C{.line-numbers}
//-----串的堆式顺序存储结构-----
typedef struct
{
    char *ch; // 若是非空串，则按串长分配存储区，否则 ch 为 NULL
    int length; // 串的当前长度
} HString;
```

为了便于说明问题，本章后面算法描述当中所用到的顺序存储的字符串都是从下标为 1 的数组分量开始存储的，下标为 0 的分量闲置不用。

#### 4.1.3.2 串的链式存储

顺序串的插入和删除操作不方便，需要移动大量的字符。因此，可以采用单链表方式存储串。

在用链表存储串时，每个结点可以存放一个字符，也可以存放多个字符。当结点大小大于 1 时，由于串长不一定是结点大小的整数倍，则链表中的最后一个结点不一定全被串值占满，此时通常补上“#”或其他的非串值字符。

为了便于进行串的操作，当以链表存储串值时，除头指针外，还可附设一个尾指针表示链表中的最后一个结点，并给出当前串的长度。称如此定义的串存储结构为块链结构，说明如下：

```C{.line-numbers}
//-----串的链式存储结构-----
#define CHUNKSIZE 80 // 可由用户定义的块大小

typedef struct Chunk
{
    char ch[CHUNKSIZE];
    struct Chunk *next;
} Chunk;

typedef struct
{
    Chunk *head; // 头指针
    Chunk *tail; // 尾指针
    int length; // 串的当前长度
} LString;
```

在链式存储方式中，结点大小的选择直接影响着串处理的效率。存储密度小（如结点大小为 1 时），运算处理方便，但存储占用量大。

串的字符集大小也是一个重要因素。一般来说，字符集小，则字符的机内编码就短，这也影响串值存储方式的选取。

串的链式存储结构对某些串操作（如连接操作等）有一定方便之处，但不如顺序存储结构灵活，占用存储量大且操作复杂。

### 4.1.4 串的模式匹配算法

子串的定位运算通常称为串的**模式匹配**或**串匹配**。

设有两个字符串 S 和 T。设 S 为主串，也称正文串；设 T 为子串，也称为模式。在主串 S 中查找与模式 T 相匹配的子串，如果匹配成功，确定相匹配的子串中的第一个字符在主串 S 中出现的位置。

#### 4.1.4.1 BF（Brute-Force）算法

> **算法 4.1**&nbsp;&nbsp;&nbsp;&nbsp;BF 算法
>
> 从主串`S`的第`pos`个字符开始查找子串`T`。
>
> 1. 分别用计数指针`i`和`j`指示主串`S`和模式`T`中当前正待比较的字符位置，`i`初值为`pos`，`j`初值为 1。
> 2. 如果两个串均未比较到末尾，则对`S.ch[i]`与`T.ch[j]`进行比较：
>    - 若相等，则`i`和`j`分别指示串中下一个位置，继续比较后续字符。
>    - 若不等，指针后退重新开始匹配。`i`后退到主串的下一个字符（`i = i - j + 2`），`j`后退到模式的第一个字符（`j = 1`）。
> 3. 如果`j > T.length`，说明模式`T`中的每个字符依次和主串`S`中的一个连续的字符序列相等，则匹配成功，返回和模式`T`中第一个字符相等的字符在主串`S`中的序号（`i - T.length`）；否则匹配不成功，返回 0。

```C{.line-numbers}
// 返回模式 T 在主串 S 中第 pos 个字符开始第一次出现的位置。若不存在，则返回 0
// 其中，T 非空，1 <= pos <= S.length
int Index_BF(SString S, SString T, int pos)
{
    // 初始化
    int i = pos;
    int j = 1;
    
    while (i <= S.length && j <= T.length) // 两个串均未比较到串尾
    {
        if (S.ch[i] == T.ch[j]) // 当前位置匹配成功，继续比较后续字符
        {
            i++;
            j++;
        }
        else // 当前位置匹配失败，指针后退重新开始匹配
        {
            i = i - j + 2; // i 后退到上次起始字符的下一个位置
            j = 1;
        }
    }
    
    if (j > T.length) // 匹配成功
        return i - T.length;
    else // 匹配失败
        return 0;
}
```

最好情况下，每趟不成功的匹配都发生在模式串的第一个字符与主串中相应字符的比较。设主串的长度为 $n$，子串的长度为 $m$。假设从主串的第 $i$ 个位置开始与模式串匹配成功，则在前 $i-1$ 趟匹配中字符总共比较了 $i-1$ 次。若第 $i$ 趟成功的字符比较次数为 $m$，则总比较次数为 $i-1+m$。对于成功匹配的主串，其起始位置由 1 到 $n-m+1$，假定这 $n-m+1$ 个起始位置上的匹配成功概率相等，则最好情况下匹配成功的平均比较次数为

$$
\sum_{i=1}^{n-m+1} p_i(i-1+m)=\dfrac{1}{n-m+1}\sum_{i=1}^{n-m+1}(i-1+m)=\dfrac{1}{2}(n+m)
$$

即最好情况下的平均时间复杂度是 $O(n+m)$。

最坏情况下，每趟不成功的匹配都发生在模式串的最后一个字符与主串中相应字符的比较。假设从主串的第 $i$ 个位置开始与模式串匹配成功，则在前 $i-1$ 趟匹配中字符总共比较了 $(i-1)m$ 次。若第 $i$ 趟成功的字符比较次数为 $m$，则总比较次数为 $im$。因此最坏情况下匹配成功的平均比较次数为

$$
\sum_{i=1}^{n-m+1} p_i im=\dfrac{1}{n-m+1}\sum_{i=1}^{n-m+1} im=\dfrac{m}{2}(n-m+2)
$$

即最坏情况下的平均时间复杂度是 $O(nm)$。

BF 算法思路直观简明。但当匹配失败时，主串的指针`i`总是回溯到`i - j + 2`位置，模式串的指针总是恢复到首字符位置，因此算法时间复杂度高。

#### 4.1.4.2 KMP算法

KMP（Knuth-Morris-Pratt）算法是对 BF 算法的改进。其改进在于：每当一趟匹配中出现字符比较不等时，不需回溯`i`指针，而是利用已经得到的部分匹配的结果将模式串向右滑动尽可能远的距离后，继续进行比较。

假设主串为 $“s_1s_2\cdots s_n”$，模式串为 $“t_1t_2\cdots t_m”$。当匹配过程中产生“失配”（即 $s_i\not=t_j$）时，前 $j-1$ 个字符匹配成功，即满足下列等式：

$$
\tag{4-1} “t_1 t_2\cdots t_{j-1}”=“s_{i-j+1} s_{i-j+2}\cdots s_{i-1}”
$$

假设此时应从模式串中第 $k(k<j)$ 个字符开始继续比较，而 $i$ 指针不回溯，即主串中第 $i$ 个字符与模式中第 $k$ 个字符再比较，则模式中前 $k-1$ 个字符的子串必须满足下列关系式 $(4\text{-}2)$，且不可能存在 $k'>k$ 满足下列关系式 $(4\text{-}2)$。

$$
\tag{4-2} “t_1 t_2\cdots t_{k-1}”=“s_{i-k+1} s_{i-k+2}\cdots s_{i-1}”
$$

根据式 $(4\text{-}1)$ 可得

$$
\tag{4-3} “t_{j-k+1} t_{j-k+2}\cdots t_{j-1}”=“s_{i-k+1} s_{i-k+2}\cdots s_{i-1}”
$$

由式 $(4\text{-}2)$ 和式 $(4\text{-}3)$ 推得下列等式

$$
\tag{4-4} “t_1 t_2\cdots t_{k-1}”=“t_{j-k+1} t_{j-k+2}\cdots t_{j-1}”
$$

反之，若模式串中存在满足式 $(4\text{-}4)$ 的两个子串，则当匹配过程中主串第 $i$ 个字符与模式串第 $j$ 个字符比较不等时，仅需将模式向右滑动至模式中第 $k$ 个字符和主串中第 $i$ 个字符对齐。此时，模式中前 $k-1$ 个字符的子串 $“t_1t_2\cdots t_{k-1}”$ 必定与主串中第 $i$ 个字符之前长度为 $k-1$ 的子串 $“s_{i-k+1}s_{i-k+2}\cdots s_{i-1}”$ 相等。由此，匹配仅需从模式中第 $k$ 个字符与主串中第 $i$ 个字符开始，依次向后进行比较。

若令 $\text{next}[j]=k$，则 $\text{next}[j]$ 表明当模式中第 $j$ 个字符与主串中相应字符“失配”时，在模式中需重新和主串中该字符进行比较的字符的位置。由此可引出模式串的 $\text{next}$ 函数的定义：

$$
\text{next}[j]=\begin{cases}
    0 & j=1\\
    \max\{k\,|\,1<k<j\,且\,“t_1 t_2\cdots t_{k-1}”=“t_{j-k+1} t_{j-k+2}\cdots t_{j-1}”\} & 其他
\end{cases}
$$

在求得模式的 $\text{next}$ 函数之后，匹配可如下进行：假设以指针`i`和`j`分别指示主串和模式中正待比较的字符，令`i`的初值为`pos`，`j`的初值为 1。若在匹配过程中 $s_i=t_j$，则`i`和`j`分别增 1；否则，`i`不变，而`j`退到`next[j]`的位置再比较，若相等，则指针各自增 1，否则`j`再退到下一个`next`值的位置，以此类推，直至下列两种可能：一种是`j`退到某个`next`值时字符比较相等，则指针各自增 1，继续进行匹配；另一种是`j`退到值为零（即模式的第一个字符 “失配”），则此时需将模式继续向右滑动一个位置，即从主串的下一个字符 $s_{i+1}$ 起和模式重新开始匹配。

> **算法 4.2**&nbsp;&nbsp;&nbsp;&nbsp;KMP 算法

```C{.line-numbers}
// 利用模式串 T 的 next 函数求 T 在主串 S 中第 pos 个字符之后的位置
// 其中，T 非空，1 <= pos <= S.length
int Index_KMP(SString S, SString T, int pos)
{
    int i = pos;
    int j = 1;
    while (i <= S.length && j <= T.length) // 两个串均未比较到串尾
    {
        if (j == 0 || S.ch[i] == T.ch[j])
        {
            i++;
            j++;
        }
        else
        {
            j = next[j];
        }
    }
    
    if (j > T.length) // 匹配成功
        return i - T.length;
    else // 匹配失败
        return 0;
}
```

$\text{next}$ 函数值仅取决于模式串本身，而和主串无关，可从分析其定义出发用递推的方法求得 $\text{next}$ 函数值。

由定义得知：

$$
\tag{4-5} \text{next}[1]=0
$$

设 $\text{next}[j]=k$，这表明在模式串中存在下列关系：

$$
\tag{4-6} “t_1 t_2\cdots t_{k-1}”=“t_{j-k+1} t_{j-k+2}\cdots t_{j-1}”
$$

其中 $k$ 为满足 $1<k<j$ 的某个值，并且不可能存在 $k'>k$ 满足等式 $(4\text{-}6)$。根据 $\text{next}[j]$ 的值递推求取 $\text{next}[j+1]$，可能有以下两种情况。

1. 若 $t_k=t_j$，则表明在模式串中有

$$
\tag{4-7} “t_1t_2\cdots t_{k}”=“t_{j-k+1}t_{j-k+2}\cdots t_{j}”
$$

并且不可能存在 $k'>k$ 满足等式 $(4\text{-}7)$，因此 $\text{next}[j+1]=k+1$，即

$$
\tag{4-8} \text{next}[j+1]=\text{next}[j]+1
$$

2. 若 $t_k\not=t_j$，则表明在模式串中

$$
“t_1t_2\cdots t_{k}”\not=“t_{j-k+1}t_{j-k+2}\cdots t_{j}”
$$

此时可把求 $\text{next}$ 函数值的问题看成是一个模式匹配的问题，整个模式串既是主串又是模式串。当前在匹配的过程中，已有 $t_{j-k+1}=t_1,t_{j-k+2}=t_2,\cdots,t_{j-1}=t_{k-1}$，则当 $t_j\not=t_k$ 时应将模式向右滑动至以模式中的第 $\text{next}[k]$ 个字符和主串中的第 $j$ 个字符相比较。若 $\text{next}[k]=k'$，且 $t_j=t_{k'}$，则有

$$
\tag{4-9} “t_1t_2\cdots t_{k'}”=“t_{j-k'+1}t_{j-k'+2}\cdots t_{j}” \quad(1<k'<k<j)
$$

这就是说 $\text{next}[j+1]=k'+1$，即

$$
\tag{4-10} \text{next}[j+1]=\text{next}[k]+1
$$

若 $t_j\not=t_{k'}$，则将模式继续向右滑动直至将模式中第 $\text{next}[k']$ 个字符和 $t_j$ 对齐，$\cdots$，以此类推，直至 $t_j$ 和模式中某个字符匹配成功或者不存在任何 $k'(1<k'<j)$ 满足等式 $(4\text{-}9)$，则

$$
\tag{4-11} \text{next}[j+1]=1
$$

根据式 $(4\text{-}5)$、式 $(4\text{-}8)$、式 $(4\text{-}10)$ 和式 $(4\text{-}11)$，仿照 KMP 算法，可得到求 $\text{next}$ 函数值的算法，如算法 4.3 所示。

> **算法 4.3**&nbsp;&nbsp;&nbsp;&nbsp;计算 next 函数值

```C{.line-numbers}
// 求模式串 T 的 next 函数值并存入数组 next
void get_next(SString T, int next[])
{
    int i = 1; // 主串指针
    int j = 0; // 模式串指针
    next[1] = 0;
    while (i < T.length)
    {
        if (j == 0 || T.ch[i] == T.ch[j])
        {
            i++;
            j++;
            next[i] = j;
        }
        else
        {
            j = next[j];
        }
    }
}
```

算法 4.3 的时间复杂度为 $O(m)$。

虽然 BF 算法的时间复杂度是 $O(nm)$，但在一般情况下，其实际的执行时间近似于 $O(n+m)$。KMP 算法仅当模式与主串之间存在许多“部分匹配”的情况下才显得比 BF 算法快得多。但 KMP 算法的最大特点是指示主串的指针不需回溯，整个匹配过程中，对主串仅需从头至尾扫描一遍，这对处理从外设输入的庞大文件很有效，可以边读入边匹配，而无需回头重读。

前面定义的 $\text{next}$ 函数还可以优化。若按上述定义得到 $\text{next}[j]=k$，而模式中 $t_j=t_k$，则当匹配过程中 $s_i\not=t_j$ 时，不需要再和 $t_k$ 进行比较，而直接和 $t_{\text{next}[k]}$ 进行比较，此时应有 $\text{next}[j]=\text{next}[k]$。由此可得计算 $\text{next}$ 函数修正值的算法，如算法 4.4 所示。

> **算法 4.4**&nbsp;&nbsp;&nbsp;&nbsp;计算 next 函数修正值

```C{.line-numbers}
// 求模式串 T 的 next 函数修正值并存入数组 nextval
void get_nextval(SString T, int nextval[])
{
    int i = 1;
    int j = 0;
    nextval[1] = 0;
    while (i < T.length)
    {
        if (j == 0 || T.ch[i] == T.ch[j])
        {
            i++;
            j++;
            
            if (T.ch[i] != T.ch[j])
                nextval[i] = j;
            else
                nextval[i] = nextval[j];
        }
        else
        {
            j = nextval[j];
        }
    }
}
```

## 4.2 数组

### 4.2.1 数组的类型定义

**数组**是由类型相同的数据元素构成的有序集合，每个元素称为**数组元素**，每个元素受 $n\,(n\geqslant 1)$ 个线性关系的约束，每个元素在 $n$ 个线性关系中的序号 $i_1,i_2,\cdots,i_n$ 称为该元素的**下标**，可以通过下标访问该数据元素。因为数组中每个元素处于 $n$ 个关系中，故称该数组为 $n$ 维数组。

例如，一维数组可以看成是一个线性表，二维数组可以看成数据元素是线性表的线性表，$n$ 维数组可以看成数据元素是 $n-1$ 维数组的一维数组。

抽象数据类型数组可形式地定义为：

$$
\begin{aligned}
    & \texttt{ADT Array \{}\\
    & \quad\texttt{数据对象：$D=\{a_{j_1j_2\cdots j_n}|\,a_{j_1j_2\cdots j_n}\in \texttt{ElemSet},\,j_i=0,\cdots,b_i-1,\,i=1,2,\cdots,n\}$}\\
    & \quad\texttt{\qquad\qquad$n$\,称为数组的维度，$b_i$\,是数组第\,$i$\,维的长度，$j_i$\,是数组元素的第\,$j$\,维下标}\\
    & \quad\texttt{数据关系：}R=\{R_1,R_2,\cdots,R_n\}\\
    & \quad\texttt{基本操作：}\\
    & \qquad\texttt{InitArray(\&A, n, boundi, ..., boundn)}\\
    & \qquad\quad\texttt{操作结果：若维数\,n\,和各维长度合法，则构造相应的数组\,A，并返回\,OK}\\
    & \qquad\texttt{DestroyArray(\&A)}\\
    & \qquad\quad\texttt{操作结果：销毁数组\,A}\\
    & \qquad\texttt{Value(A, \&e,index1,..., indexn)}\\
    & \qquad\quad\texttt{初始条件：A\,是\,$n$\,维数组，e\,为元素变量，随后是\,$n$\,个下标值}\\
    & \qquad\quad\texttt{操作结果：若各下标不越界，则\,e\,赋值为所指定的\,A\,的元素值，并返回\,OK}\\
    & \qquad\texttt{Assign(\&A, e, index1,..., indexn)}\\
    & \qquad\quad\texttt{初始条件：A\,是\,$n$\,维数组，e\,为元素变量，随后是\,$n$\,个下标值}\\
    & \qquad\quad\texttt{操作结果：若各下标不越界，则将\,e\,的值赋给所指定的\,A\,的元素，并返回\,OK}\\
    & \texttt{\} ADT Array}
\end{aligned}
$$

### 4.2.2 数组的顺序存储

数组一般不做插入或删除操作，一旦建立了数组，则结构中的数据元素个数和元素之间的关系就不再发生变动。因此，采用顺序存储结构表示数组比较合适。

由于存储单元是一维的结构，而数组可能是多维的结构，则用一组连续存储单元存放数组的数据元素就有次序约定问题。对二维数组有两种存储方式：一种是以列序为主序的存储方式，一种是以行序为主序的存储方式。

对于数组，一旦规定了其维数和各维的长度，便可为它分配存储空间。反之，只要给出一组下标便可求得相应数组元素的存储位置。下面仅用以行序为主序的存储结构为例予以说明。

假设每个数据元素占 $L$ 个存储单元，则二维数组 $A[0\dots m-1,0\dots n-1]$（即下标从 0 开始，共有 $m$ 行 $n$ 列）中任一元素 $a_{ij}$ 的存储位置可由下式确定

$$
\tag{4-12} \text{LOC}(i,j)=\text{LOC}(0,0)+(ni+j)L
$$

式中，$\text{LOC}(i,j)$ 是 $a_{ij}$ 的存储位置；$\text{LOC}(0,0)$ 是 $a_{00}$ 的存储位置，即二维数组 $A$ 的起始存储位置，也称为基地址或基址。

将式 $(4\text{-}12)$ 推广到一般情况，可得到 $n$ 维数组 $A[0\dots b_1-1,0\dots b_2-1,\cdots,0\dots b_n-1]$ 的数据元素存储位置的计算公式：

$$
\begin{aligned}
    \text{LOC}(j_1,j_2,\cdots,j_n)&=\text{LOC}(0,0,\cdots,0)+(b_2b_3\cdots b_nj_1+b_3b_4\cdots b_nj_2
    +\cdots+b_nj_{n-1}+j_n)L\\
    &=\text{LOC}(0,0,\cdots,0)+\Bigg(\sum_{i=1}^{n-1}\bigg(j_i\prod_{k=i+1}^n b_k\bigg)+j_n\Bigg)L
\end{aligned}
$$

可缩写成

$$
\tag{4-13} \text{LOC}(j_1,j_2,\cdots,j_n)=\text{LOC}(0,0,\cdots,0)+\sum_{i=1}^n c_ij_i
$$

其中，$c_n=L,\,c_{i-1}=b_ic_i,\,1<i\leqslant n$。

式 $(4\text{-}13)$ 称为 $n$ 维数组的映像函数。数组元素的存储位置是其下标的线性函数，一旦确定了数组各维的长度，$c_i$ 就是常数。由于计算各个元素存储位置的时间相等，所以存取数组中任一元素的时间也相等，即数组是一种随机存取结构。

### 4.2.3 矩阵的数组表示

可以用二维数组存放矩阵，也可以用一维矩阵以行优先次序存放矩阵元素。

若用大小为 $m\times n$ 的一维数组`A`存放 $m\times n$ 矩阵 $\boldsymbol{A}$，则 $\boldsymbol{A}$ 中元素 $a_{ij}(1\leqslant i\leqslant m,\,1\leqslant j\leqslant n)$ 应存放在`A[(i - 1) * n + j - 1]`处。

> **算法 4.5**&nbsp;&nbsp;&nbsp;&nbsp;矩阵乘法
>
> 用一维数组`a`存放矩阵 $\boldsymbol{A}_{m\times p}$，用一维数组`b`存放矩阵 $\boldsymbol{B}_{p\times n}$，将 $\boldsymbol{A}$ 与 $\boldsymbol{B}$ 的乘积 $\boldsymbol{C}_{m\times n}$ 存放在一维数组`c`中。

```C{.line-numbers}
void MatrixMulti(float a[], float b[], int m, int p, int n, float &c[])
{
    int cc = 0; // 初始时 cc 是 C[1][1] 在一维数组 c 中的下标
    for (int i = 1; i <= m; i++)
    {
        for (int j = 1; j <= n; j++)
        {
            int ca = (i - 1) * p; // ca 为 A[i][1] 在一维数组 a 中的下标
            int cb = j - 1; // cb 为 B[1][j] 在 b 中的下标

            // 计算 C[i][j] 的值，保存在 c[cc] 中
            c[cc] = 0;
            for (int k = 0; k <= p; k++)
            {
                c[cc] = c[cc] + a[ca] * b[cb];
                ca++; // ca 指向 A 中本行下一列元素
                cb += n; // cb 指向 B 中本列下一行元素
            }

            cc++;
        }
    }
}
```

### 4.2.4 特殊矩阵的压缩存储

所谓**压缩存储**，是指为多个值相同的元只分配一个存储空间，对零元不分配空间。

#### 4.2.4.1 对称矩阵

若 $n$ 阶矩阵 $\boldsymbol{A}$ 中的元满足下列性质

$$
a_{ij}=a_{ji}\quad 1\leqslant i,j\leqslant n
$$

则称为 $n$ 阶对称矩阵。

对于对称矩阵，可以为每一对对称元分配一个存储空间，则可将 $n^2$ 个元压缩存储到 $\dfrac{n(n+1)}{2}$ 个元的空间中。不失一般性，可以以行序为主序存储其下三角（包括对角线）中的元。

假设以一维数组`sa[n * (n + 1) / 2]`作为 $n$ 阶对称矩阵 $\boldsymbol{A}$ 的存储结构，则`sa[k]`和矩阵元 $a_{ij}$ 之间存在着一一对应的关系：

$$
k=\begin{cases}
    \dfrac{i(i-1)}{2}+j-1 & i\geqslant j\\
    \dfrac{j(j-1)}{2}+i-1 & i<j
\end{cases}
$$

对于任意给定的一组下标 $(i,j)$，均可在`sa`中找到矩阵元 $a_{ij}$；反之，对所有的 $k=0,1,2,\cdots,\dfrac{n(n+1)}{2}-1$，都能确定`sa[k]`中的元在矩阵中的位置 $(i,j)$。由此，称`sa[n * (n + 1) / 2]`为 $n$ 阶对称矩阵 $\boldsymbol{A}$ 的压缩存储。

#### 4.2.4.2 三角矩阵

以主对角线划分，三角矩阵有上三角矩阵和下三角矩阵两种。上三角矩阵是指矩阵下三角（不包括对角线）中的元均为常数或零的 $n$ 阶矩阵，下三角矩阵与之相反。

对三角矩阵进行压缩存储，除了和对称矩阵一样，只存储其上（下）三角中的元素之外，再加一个存储常数的存储空间即可。

对于上三角矩阵，`sa[k]`和矩阵元 $a_{ij}$ 之间的对应关系为

$$
k=\begin{cases}
    \dfrac{(i-1)(2n-i+2)}{2}+j-i & i\leqslant j\\
    \dfrac{n(n+1)}{2} & i>j
\end{cases}
$$

对于下三角矩阵，`sa[k]`和矩阵元 $a_{ij}$ 之间的对应关系为

$$
k=\begin{cases}
    \dfrac{i(i-1)}{2}+j-1 & i\geqslant j\\
    \dfrac{n(n+1)}{2} & i<j
\end{cases}
$$

#### 4.2.4.3 对角矩阵

若 $n$ 阶方阵 $\boldsymbol{A}$ 中非对角线上的元素均为 0，即对于任意的 $i\not=j\,(1\leqslant i,j\leqslant n)$，都有 $a_{ij}=0$，则称矩阵 $\boldsymbol{A}$ 为对角矩阵。

对于一个 $n$ 阶对角矩阵，至多只有 $n$ 个非零元素，可以用一维数组`d[n]`来存储其 $n$ 个对角元素，其中`d[i-1]`（$1\leqslant i\leqslant n$）存储 $a_{ii}$ 的值。

#### 4.2.4.4 稀疏矩阵

若 $m\times n$ 矩阵 $\boldsymbol{A}$ 中非零元素的个数远小于零元素的个数，且非零元素的分布没有规律，则矩阵 $\boldsymbol{A}$ 称为**稀疏矩阵**。

由于稀疏矩阵中大多数元素为零元素，而非零元素的分布没有规律，因此无法简单地利用一维数组和映射公式来实现稀疏矩阵的压缩存储。

对于 $m\times n$ 矩阵 $\boldsymbol{A}$ 的每个元素 $a_{pq}$，知道其行号 $p$ 和列号 $q$，就可以确定该元素在矩阵中的位置。因此，如果用一个结点来存储矩阵 $\boldsymbol{A}$ 的一个非零元 $a_{pq}$，则结点结构如图 4.1 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.1-%E4%B8%89%E5%85%83%E7%BB%84%E7%BB%93%E7%82%B9.jpg">
    <br>
    图 4.1&nbsp;&nbsp;&nbsp;&nbsp;三元组结点
</div>

由`row`、`col`、`value`三个域组成的结点称为三元组结点，其中`row`为行号，`col`为列号，`value`为元素值。矩阵 $\boldsymbol{A}$ 的任一非零元素 $a_{pq}$ 可由一个三元组结点唯一确定。

```C{.line-numbers}
// 三元组结点的存储结构
typedef struct
{
    int row; // 行号
    int col; // 列号
    ElemType value; // 元素值
} TripleNode;
```

合理组织三元组结点，就可以得到稀疏矩阵的压缩存储。

1. **三元组表**

将表示稀疏矩阵 $\boldsymbol{A}$ 的所有非零元素的三元组结点按行优先的顺序排列，可以得到一个线性表 LL，用顺序存储方式存储的线性表 LL 称为**三元组表**。

```C{.line-numners}
#define MAXSIZE 100

// 三元组表的存储结构
typedef struct
{
    TripleNode data[MAXSIZE + 1];
    int rowCount; // 行数
    int colCount; // 列数
    int elemCount; // 元素个数
} TSMatrix;
```

三元组表便于实现矩阵转置。

> **算法 4.6**&nbsp;&nbsp;&nbsp;&nbsp;三元组表矩阵转置

```C{.line-numers}
// 矩阵 A 存放在三元组表 a 中，求 A 的转置并将其存放在三元组表 b 中
void Transpose(TSMatrix a, TSMatrix &b)
{
    b.rowCount = a.colCount;
    b.colCount = a.rowCount;
    b.elemCount = a.elemCount;

    // 若 a 非空，则进行转置
    if (a.elemCount > 0)
    {
        int j = 0; // 三元组表 b 的下标

        // 对 b 按行优先次序依次确认非零元素
        for (int k = 1; k <= b.rowCount; k++)
        {
            // 扫描 a
            for (int i = 0; i < a.elemCount; i++)
            {
                // 在 a 中找到列号为 k 的元素，即为 b 中行号为 k 的元素
                if (a.data[i].col == k)
                {
                    b.data[j].row = k;
                    b.data[j].col = a.data[i].row; // 该元素在 b 中的列号为其在 a 中的行号
                    b.data[j].value = a.data[i].value;
                    j++;
                }
            }
        }
    }
}
```

对于用三元组表存储的稀疏矩阵 $\boldsymbol{A}_{m\times n}$，若非零元素个数为 $t$，则矩阵转置算法的时间复杂度为 $O(nt)$。

用三元组表存储稀疏矩阵，无论是添加或删除矩阵的非零元素，还是对矩阵实施某些操作（如矩阵加法），都可能引起矩阵中非零元素的个数和位置的变化，这些变化将引起三元组表中大量结点的移动，效率较低。用链式存储方式实现稀疏矩阵可以避免这些问题。

2. **十字链表**

在稀疏矩阵的十字链表中，矩阵的每一行都设置为由一个头结点引导的循环链表（简称为行链表），矩阵的每一列也都设置为由一个头结点引导的循环链表（简称为列链表）。

十字链表的结点结构如图 4.2 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.2-%E5%8D%81%E5%AD%97%E9%93%BE%E8%A1%A8%E7%9A%84%E7%BB%93%E7%82%B9%E7%BB%93%E6%9E%84.jpg">
    <br>
    图 4.2&nbsp;&nbsp;&nbsp;&nbsp;十字链表的结点结构
</div>

其中 LEFT 和 UP 是指针，分别存放该结点的左邻非零元素和上邻非零元素的地址信息。

例如，设稀疏矩阵为

$$
\begin{bmatrix}
    0 & 0 & 6 & 0\\
    4 & 0 & 0 & 0\\
    0 & 9 & 0 & 7\\
    0 & 0 & 0 & 8
\end{bmatrix}
$$

它的十字链表如图 4.3 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.3-%E5%8D%81%E5%AD%97%E9%93%BE%E8%A1%A8%E7%A4%BA%E4%BE%8B.jpg">
    <br>
    图 4.3&nbsp;&nbsp;&nbsp;&nbsp;十字链表示例
</div>

## 4.3 广义表

### 4.3.1 广义表的定义

广义表是线性表的推广，也称为列表。广义表一般记作

$$
LS=(a_1,a_2,\cdots,a_n)
$$

其中，$LS$ 是广义表的名称，$n$ 是其长度。

在线性表的定义中，$a_i(1\leqslant i \leqslant n)$ 只限于单个元素。而在广义表的定义中，$a_i$ 可以是单个元素，也可以是广义表，分别称为广义表 $LS$ 的原子和子表。习惯上，用大写字母表示广义表的名称，用小写字母表示原子。

广义表的定义是一个递归的定义，因为在描述广义表时又用到了广义表的概念。

广义表的例子：

1. $A=()$——$A$ 是一个空表，其长度为零。
2. $B=(e)$——$B$ 只有一个原子 $e$，其长度为 1。
3. $C=(a,(b,c,d))$——$C$ 的长度为 2，两个元素分别为原子 $a$ 和子表 $(b,c,d)$。
4. $D=(A,B,C)$——$D$ 的长度为 3，3 个元素都是广义表。将子表的值代入后，则有 $D=((),(e),(a,(b,c,d)))$。
5. $E=(a,E)$——这是一个递归的表，其长度为 2。$E$ 相当于一个无限的广义表 $E=(a,(a,(a,\cdots)))$。

广义表的 3 个重要结论：

1. 广义表的元素可以是子表，而子表的元素还可以是子表，由此，广义表是一个多层次的结构，可以用图形象地表示。例如，图 4.4 表示的是广义表 $D$，图中以圆圈表示广义表，以方块表示原子。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.4-%E5%B9%BF%E4%B9%89%E8%A1%A8%E7%9A%84%E5%9B%BE%E5%BD%A2%E8%A1%A8%E7%A4%BA.png">
    <br>
    图 4.4&nbsp;&nbsp;&nbsp;&nbsp;广义表的图形表示
</div>

2. 广义表可为其他广义表所共享。在广义表中可以不必列出子表的值，而是通过子表的名称来引用。
3. 广义表可以是一个递归的表，即广义表也可以是其本身的一个子表。例如，$E$ 就是一个递归的表。

广义表最重要的两个运算如下：

1. 取表头`GetHead(LS)`：取出的表头为非空广义表的第一个元素，它可以是一个单原子，也可以是一个子表。
2. 取表尾`GetTail(LS)`：取出的表尾为除去表头之外，由其余元素构成的表。即表尾一定是一个广义表。

### 4.3.2 广义表的存储结构

由于广义表中的数据元素可以有不同的结构，因此难以用顺序存储结构表示，通常采用链式存储结构。常用的链式存储结构有两种：头尾链表的存储结构、扩展线性链表的存储结构。

#### 4.3.2.1 头尾链表的存储结构

由于广义表中的数据元素可能为原子或广义表，由此需要两种结构的结点：一种是表结点，用以表示广义表；一种是原子结点，用以表示原子。一个表结点可由 3 个域组成：标志域、指示表头的指针域和指示表尾的指针域。原子结点只需 2 个域：标志域和值域。如图 4.3 所示，其中 tag 是标志域，值为 1 时表明结点是子表，值为 0 时表明结点是原子。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.5-%E5%A4%B4%E5%B0%BE%E9%93%BE%E8%A1%A8%E8%A1%A8%E7%A4%BA%E7%9A%84%E7%BB%93%E7%82%B9%E7%BB%93%E6%9E%84.png">
    <br>
    图 4.5&nbsp;&nbsp;&nbsp;&nbsp;头尾链表表示的结点结构
</div>

若广义表不空，则可分解成表头和表尾，因此，一对确定的表头和表尾可唯一确定广义表。

广义表的头尾链表存储表示的形式定义说明如下：

```C{.line-numbers}
typedef enum
{
    ATOM, // 原子
    LIST // 子表
} ElemTag;

typedef struct GLNode
{
    ElemTag tag; // 标志域，用于区分原子结点和表结点
    union
    {
        AtomType atom; // 原子结点的值域，AtomType 由用户定义
        struct
        {
            struct GLNode *hp; // 表头指针
            struct GLNode *tp; // 表尾指针
        } ptr; // 表结点的指针域
    };
} *GList;
```

上面列举了 5 个广义表的例子，它们的存储结构如图 4.6 所示。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.6-%E5%A4%B4%E5%B0%BE%E9%93%BE%E8%A1%A8%E8%A1%A8%E7%A4%BA%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B.png">
    <br>
    图 4.6&nbsp;&nbsp;&nbsp;&nbsp;头尾链表表示的存储结构示例
</div>

头尾链表存储结构的特点：

1. 除空表的表头指针为空外，对任何非空广义表，其表头指针均指向一个表结点，且该表结点中的`hp`域指示广义表表头（或为原子结点，或为表结点），`tp`域指向广义表表尾（当表尾为空时指针为空，否则必为表结点）。
2. 容易分清列表中原子和子表所在层次。例如在广义表 $D$ 中，原子 $a$ 和 $e$ 在同一层次上，而 $b$、$c$ 和 $d$ 在同一层次且比 $a$ 和 $e$ 低一层，$B$ 和 $C$ 是同一层的子表。
3. 最高层的表结点个数即为广义表的长度。

#### 4.3.2.2 扩展线性链表的存储结构

在扩展线性链表的存储结构中，无论是原子结点还是表结点均由三个域组成，其结点结构如图 4.7 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.7-%E6%89%A9%E5%B1%95%E7%BA%BF%E6%80%A7%E9%93%BE%E8%A1%A8%E8%A1%A8%E7%A4%BA%E7%9A%84%E7%BB%93%E7%82%B9%E7%BB%93%E6%9E%84.png">
    <br>
    图 4.7&nbsp;&nbsp;&nbsp;&nbsp;扩展线性链表表示的结点结构
</div>

4.3.1 小节中广义表例子所对应的扩展线性链表表示的存储结构，如图 4.8 所示。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE4.8-%E6%89%A9%E5%B1%95%E7%BA%BF%E6%80%A7%E9%93%BE%E8%A1%A8%E8%A1%A8%E7%A4%BA%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84%E7%A4%BA%E4%BE%8B.png">
    <br>
    图 4.8&nbsp;&nbsp;&nbsp;&nbsp;扩展线性链表表示的存储结构示例
</div>

## 4.4 环状模式串的模式匹配

在模式匹配中，如果模式串是环状的，就需要对 BF 算法或 KMP 算法进行改进。

假设模式串的长度是 $m$。因为模式串是环状的，为了线性取到每个可行的长度为 $m$ 的模式串，可将存储模式串的字符串长度扩大为 $2m$，将模式串连续存储两次。然后循环 $m$ 次，依次取得每个长度为 $m$ 的环状字符串，将此字符串作为模式串，调用 BF 算法或 KMP 算法进行匹配。只要匹配成功，即可中止循环；否则，若 $m$ 次循环中没有一次匹配成功，说明匹配失败。

> **算法 4.7**&nbsp;&nbsp;&nbsp; 环状模式串的模式匹配
>
> 1. 设置一个标志性变量`flag`，用来标识是否匹配成功。初值为 0，表示未匹配。
> 2. 模式串的长度是 $m$，将存储模式串的字符串长度扩大为 $2m$，将模式串连续存储两次。
> 3. 循环 $m$ 次，重复执行以下操作：
>    （1）依次取得每个长度为 $m$ 的字符串。
>    （2）将此字符串作为模式串，调用 BF 算法或 KMP 算法进行模式匹配，将匹配结果赋给`flag`。若`flag`非 0，表示匹配成功，返回`flag`。
> 4. 若 $m$ 次循环执行完毕后未返回，说明匹配失败，返回 0。

```C{.line-numbers}
int Index_circular(SString S, SString T, int pos)
{
    int flag = 0; // 用来标识是否匹配成功
    
    SString T_doubled;
    Concat(T_doubled, T, T); // 将存储模式串的字符串长度扩大 2 倍
    
    SString temp;
    for (int i = 1; i <= T.length; i++)
    {
        SubString(temp, T_doubled, i, T.length); // 取得长度为 m 的字符串作为模式串
        flag = Index_KMP(S, temp, pos); // 模式匹配
        if (flag != 0) // 若匹配成功则直接返回
            return flag;
    }
    
    return 0;
}
```

# 第5章 树和二叉树

## 5.1 树的基本概念

### 5.1.1 树的定义

**树**（tree）是 $n\,(n\geqslant 0)$ 个结点的有限集，它或为空树（$n=0$），或为非空树。对于非空树 $T$：

1. 有且仅有一个称之为根的结点；
2. 除根结点以外的其余结点可分为 $m\,(m>0)$ 个互不相交的有限集 $T_1,T_2,\cdots,T_m$，其中每个集合本身又是一棵树，称为根的**子树**（subtree）。

树的结构定义是一个递归的定义，即在树的定义中又用到树的定义。

例如，图 5.1 是一棵有 13 个结点的树。其中 A 是根，其余结点分成 3 个互不相交的子集：$T_1=\{B,E,F,K,L\}$，$T_2=\{C,G\}$，$T_3=\{D,H,I,J,M\}$。$T_1$、$T_2$ 和 $T_3$ 都是根 A 的子树，且本身也是一棵树。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.1-树的示例.6m71s194bgc0.png">
    <br>
    图 5.1&nbsp;&nbsp;&nbsp;&nbsp;树的示例
</div>

树还可以有其他的表示形式，如图 5.2 所示为图 5.1 中树的各种表示。其中（a）是以嵌套集合的形式表示的，对于图中的任何两个集合，或者不相交，或者一个包含另一个；（b）是以广义表的形式表示的，根作为由子树森林组成的表的名字写在表的左边；（c）是凹入表示法。

<div align="center">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.2-树的其他表示法.2jvma9yyero0.png">
    <br>
    图 5.2&nbsp;&nbsp;&nbsp;&nbsp;树的其他表示法
</div>

### 5.1.2 树的基本术语

1. **结点**：树中的一个独立单元，包含一个数据元素及若干指向其子树的分支。
2. 结点的度：结点拥有的子树数称为结点的度。
3. 树的度：树的度是树内各结点度的最大值。
4. 叶子结点：度为 0 的结点称为**叶子结点**或**终端结点**。
5. 非终端结点：度不为 0 的结点称为**非终端结点**或**分支结点**。除根结点之外，非终端结点也称为**内部结点**。
6. 双亲和孩子：结点的子树的根称为该结点的**孩子**，该结点称为孩子的**双亲**。
7. 兄弟：同一个双亲的孩子之间互称**兄弟**。
8. **祖先**：从根到该结点所经分支上的所有结点。
9. 子孙：以某结点为根的子树中的任一结点都称为该结点的**子孙**。
10. 层次：结点的层次从根开始定义起，根为第一层，根的孩子为第二层。树中任一结点的层次等于其双亲结点的层次加 1。
11. 堂兄弟：双亲在同一层的结点互为**堂兄弟**。
12. 树的深度：树中结点的最大层次称为树的**深度**或**高度**。图 5.1 所示的树的深度为 4。
13. 有序树和无序树：如果将树中结点的各子树看成从左到右是有次序的（即不能互换），则称该树为**有序树**，否则称为**无序树**。在有序树中最左边的子树的根称为第一个孩子，最右边的称为最后一个孩子。
14. **森林**：是 $m\,(m\geqslant 0)$ 棵互不相交的树的集合。对树中每个结点而言，其子树的集合即为森林。

就逻辑结构而言，任何一棵树都是一个二元组 $T=(r,F)$，其中 $r$ 是数据元素，称作树的根结点；$F$ 是 $m\,(m\geqslant 0)$ 棵树的森林，$F=(T_1,T_2,\cdots,T_m)$，其中 $T_i=(r_i,F_i)$ 称作根 $r$ 的第 $i$ 棵子树。当 $m\not=0$ 时，在树根和其子树森林之间存在下列关系：

$$
RF=\{\text{<}r,r_i\text{>}|\,i=1,2,\cdots,m,\,m>0\}
$$

## 5.2 二叉树

### 5.2.1 二叉树的定义

**二叉树**（binary tree）是 $n\,(n\geqslant 0)$ 个结点所构成的集合，它或为空树（$n=0$），或为非空树。对于非空树 $T$：

1. 有且仅有一个称之为根的结点；
2. 除根节点以外的其余结点分为两个互不相交的子集 $T_1$ 和 $T_2$，分别称为 $T$ 的**左子树**和**右子树**，且 $T_1$ 和 $T_2$ 本身又都是二叉树。

二叉树与树一样具有递归性质。二叉树与树的区别主要有以下两点：

1. 二叉树每个结点至多只有两棵子树（即二叉树中不存在度大于 2 的结点）。
2. 二叉树的子树有左右之分，其次序不能任意颠倒。

二叉树有 5 种基本形态，如图 5.3 所示。

<div align="center">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.3-二叉树的5种基本形态.7m51ftd89gg.png">
    <br>
    图 5.3&nbsp;&nbsp;&nbsp;&nbsp;二叉树的 5 种基本形态
</div>

### 5.2.2 二叉树的抽象数据类型定义

$$
\begin{aligned}
    & \texttt{ADT BinaryTree \{}\\
    & \quad\texttt{数据对象\,$D$：$D$\,是具有相同特性的数据元素的集合}\\
    & \quad\texttt{数据关系\,$R$：若\,$D=\text{\O}$，则\,$R=\text{\O}$，称\,BinaryTree\,为空二叉树；}\\
    & \qquad\qquad\qquad\quad\texttt{若\,$D\not=\text{\O}$，则\,$R=\{H\}$，$H$\,是如下二元关系：}\\
    & \qquad\qquad\qquad\quad\texttt{（1）在\,$D$\,中存在唯一的称为根的数据元素\,root，它在关系\,$H$\,下无前驱;}\\
    & \qquad\qquad\qquad\quad\texttt{（2）若$D-\{\text{root}\}\not=\text{\O}$，则存在$D-\{\text{root}\}=\{D_\text{l},D_\text{r}\}$，且}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$D_\text{l}\cap D_\text{r}=\text{\O}$；}\\
    & \qquad\qquad\qquad\quad\texttt{（3）若\,$D_\text{l}\not=\text{\O}$，则\,$D_\text{l}$\,中存在唯一的元素\,$x_\text{l}$，$\textrm{<}\text{root},x_\text{l}\textrm{>}\in H$，且存在}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$D_\text{l}$\,上的关系\,$H_\text{l}\subset H$；若\,$D_\text{r}\not=\text{\O}$，则\,$D_\text{r}$\,中存在唯一的元素\,$x_\text{r}$，}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$\textrm{<}\text{root},x_\text{r}\textrm{>}\in H$，且存在\,$D_\text{r}$\,上的关系\,$H_\text{r}\subset H$；}\\
    & \qquad\qquad\qquad\qquad\quad\ \ H=\{\text{<}\text{root},x_\text{l}\text{>},\text{<}\text{root},x_\text{r}\text{>},H_\text{l},H_\text{r}\}\texttt{；}\\
    & \qquad\qquad\qquad\quad\texttt{（4）$(D_\text{l},\{H_\text{l}\})$\,是一棵符合本定义的二叉树，称为根的左子树；}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$(D_\text{r},\{H_\text{r}\})$\,是一棵符合本定义的二叉树，称为根的右子树。}\\
    & \quad\texttt{基本操作\,$P$：}\\
    & \qquad\texttt{InitBiTree(\&T)}\\
    & \qquad\quad\texttt{操作结果：构造空二叉树\,T}\\
    & \qquad\texttt{DestroyBiTree(\&T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：销毁二叉树\,T}\\
    & \qquad\texttt{CreateBiTree(\&T, definition)}\\
    & \qquad\quad\texttt{初始条件：definition\,给出二叉树\,T\,的定义}\\
    & \qquad\quad\texttt{操作结果：按\,definition\,构造二叉树\,T}\\
    & \qquad\texttt{ClearBiTree(\&T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：将二叉树\,T\,清为空树}\\
    & \qquad\texttt{BiTreeEmpty(T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：若T为空二叉树，则返回\,true，否则返回\,false}\\
    & \qquad\texttt{BiTreeDepth(T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：返回\,T\,的深度}\\
    & \qquad\texttt{Root(T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：返回\,T\,的根}\\
    & \qquad\texttt{Value(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：返回\,cur\_e\,的值}\\
    & \qquad\texttt{Assign(T, cur\_e, value)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：结点\,cur\_e\,赋值为\,value}\\
    & \qquad\texttt{Parent(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：若\,cur\_e\,是\,T\,的非根结点，则返回它的双亲，否则返回“空”}\\
    & \qquad\texttt{LeftChild(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：返回\,cur\_e\,的左孩子。若\,cur\_e\,无左孩子，则返回“空”}\\
    & \qquad\texttt{RightChild(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：返回\,cur\_e\,的右孩子。若\,cur\_e\,无右孩子，则返回“空”}\\
    & \qquad\texttt{LeftSibling(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：若\,cur\_e\,有左兄弟，则返回它的左兄弟，否则返回“空”}\\
    & \qquad\texttt{RightSibling(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：若\,cur\_e\,有右兄弟，则返回它的右兄弟，否则返回“空”}\\
    & \qquad\texttt{InsertChild(\&T, p, LR, c)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，p\,指向\,T\,中某个结点，LR\,为\,0\,或\,1，非空树\,c\,与\,T\,不相交且右子树为空}\\
    & \qquad\quad\texttt{操作结果：根据\,LR\,为\,0\,或\,1，插入\,c\,为\,T\,中\,p\,所指结点的左或右子树，}\\
    & \qquad\qquad\qquad\qquad\ \texttt{p\,所指结点的原有左或右子树成为\,c\,的右子树}\\
    & \qquad\texttt{DeleteChild(\&T, p, LR)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在，p\,指向\,T\,中某个结点，LR\,为\,0\,或\,1}\\
    & \qquad\quad\texttt{操作结果：根据\,LR\,为\,0\,或\,1，删除\,T\,中\,p\,所指结点的左或右子树}\\
    & \qquad\texttt{PreOrderTraverse(T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：先序遍历\,T，对每个结点访问一次}\\
    & \qquad\texttt{InOrderTraverse(T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：中序遍历\,T，对每个结点访问一次}\\
    & \qquad\texttt{PostOrderTraverse(T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：后序遍历\,T，对每个结点访问一次}\\
    & \qquad\texttt{LevelOrderTraverse(T)}\\
    & \qquad\quad\texttt{初始条件：二叉树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：层序遍历\,T，对每个结点访问一次}\\
    & \texttt{\} ADT BinaryTree}
\end{aligned}
$$

### 5.2.3 二叉树的性质

**性质 1**&nbsp;&nbsp;&nbsp;&nbsp;在二叉树的第 $i$ 层上至多有 $2^{i-1}$ 个结点（$i\geqslant 1$）。

> **证明：** 利用归纳法，$i=1$ 时，只有一个根结点，$2^{i-1}=2^0=1$ 成立。
>
> 假设对所有的 $j\,(1\leqslant j<i)$ 命题成立，即第 $j$ 层上至多有 $2^{j-1}$ 个结点。下面证明 $j=i$ 时命题也成立。
>
> 由归纳假设可得，第 $i-1$ 层上至多有 $2^{i-2}$ 个结点。由于二叉树每个结点的度至多为 2，故在第 $i$ 层上的最大结点数为第 $i-1$ 层上的最大结点数的 2 倍，即 $2\times 2^{i-2}=2^{i-1}$，定理成立。

**性质 2**&nbsp;&nbsp;&nbsp;&nbsp;深度为 $k$ 的二叉树至多有 $2^k-1$ 个结点（$k\geqslant 1$）。

> **证明：** 由性质 1 可得，深度为 $k$ 的二叉树的最大结点数为
>
> $$
> \sum_{i=1}^k 2^{i-1}=2^k-1
> $$

**性质 3**&nbsp;&nbsp;&nbsp;&nbsp;对任何一棵二叉树，如果其终端结点数为 $n_0$，度为 2 的结点数为 $n_2$，则 $n_0=n_2+1$。

> **证明：** 设 $n_1$ 为二叉树中度为 1 的结点数。因为二叉树中所有结点的度均小于或等于 2，所以其结点总数为
>
> $$
> \tag{5-1} n=n_0+n_1+n_2
> $$
>
> 除了根结点外，其余结点都有一个分支进入。设 $B$ 为分支总数，则
>
> $$
> n=B+1
> $$
>
> 由于这些分支是由度为 1 或 2 的结点射出的，所以有
>
> $$
> B=n_1+2n_2
> $$
>
> 于是得
>
> $$
> \tag{5-2} n=n_1+2n_2+1
> $$
>
> 由式 $(5\text{-}1)$ 和式 $(5\text{-}2)$ 得
>
> $$
> n_0=n_2+1
> $$

**满二叉树**：深度为 $k$ 且含有 $2^k-1$ 个结点的二叉树。图 5.4 所示是一棵深度为 4 的满二叉树。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.4-满二叉树.71bgg4ncxic0.png">
    <br>
    图 5.4&nbsp;&nbsp;&nbsp;&nbsp;满二叉树
</div>

满二叉树的特点：

1. 每一层上的结点数都是最大结点数，即第 $i$ 层的结点数具有最大值 $2^{i-1}$。
2. 叶子结点都在第 $k$ 层上。
3. 每个分支结点都有两个孩子。
4. 叶子结点个数等于非终端结点个数加 1。

可以对满二叉树的结点进行连续编号，约定编号从根结点起，自上而下，自左至右。

**完全二叉树**：深度为 $k$、有 $n$ 个结点的二叉树，当且仅当其每一个结点都与深度为 $k$ 的满二叉树中编号从 1 至 $n$ 的结点一一对应时，称之为完全二叉树。图 5.5 所示为一棵深度为 4 的完全二叉树。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.5-完全二叉树.5a8z451ulsk0.png">
    <br>
    图 5.5&nbsp;&nbsp;&nbsp;&nbsp;完全二叉树
</div>

具有 $n$ 个结点、高度为 $k$ 的完全二叉树的特点是：

1. 叶子结点只可能在层次最大的两层上出现。
2. 对任一结点，若其右分支下的子孙的最大层次为 $l$，则其左分支下的子孙的最大层次必为 $l$ 或 $l+1$。
3. 树中只有最下面两层结点的度可以小于 2。
4. 树中最下面一层的结点都集中在该层最左边的若干位置上。
5. 只有编号最大的非终端结点可以没有右孩子，其余非终端结点都有两个孩子结点。

**性质 4**&nbsp;&nbsp;&nbsp;&nbsp;具有 $n$ 个结点的完全二叉树的深度为 $\lfloor \log_2 n\rfloor+1$。

> **证明：** 假设深度为 $k$，则根据完全二叉树的定义，其结点个数介于高度为 $k$ 和高度为 $k-1$ 的满二叉树的结点数之间，由性质 2 可得
>
> $$
> 2^{k-1}-1<n\leqslant 2^k-1\quad或\quad 2^{k-1}\leqslant n<2^k
> $$
>
> 于是
>
> $$
> k-1 \leqslant \log_2 n < k
> $$
>
> 即
>
> $$
> \log_2 n<k\leqslant\log_2 n+1
> $$
>
> 因为 $k$ 是整数，所以
>
> $$
> k=\lfloor\log_2 n\rfloor+1
> $$

**性质 5**&nbsp;&nbsp;&nbsp;&nbsp;如果对一棵有 $n$ 个结点的完全二叉树的结点按层次顺序编号，则对任一结点 $i\,(1\leqslant i\leqslant n)$，有

1. 如果 $i=1$，则结点 $i$ 是二叉树的根，无双亲；如果 $i>1$，则其双亲是结点 $\Big\lfloor\dfrac{i}{2}\Big\rfloor$。
2. 如果 $2i>n$，则结点 $i$ 无左孩子，结点 $i$ 为叶子结点；否则其左孩子是结点 $2i$。
3. 如果 $2i+1>n$，则结点 $i$ 无右孩子；否则其右孩子是结点 $2i+1$。

> **证明：** 用归纳法可证明 2。
>
> 若 $i=1$，如果 $n\geqslant 2$，则左孩子编号为 2。
>
> 假设对所有 $j\,(1\leqslant j\leqslant i,\,2i\leqslant n)$，$j$ 的左孩子编号为 $2j$，往证结点 $j=i+1$ 的左孩子的编号为 $2(i+1)$。
>
> 如果 $2(i+1)\leqslant n$，则由层次顺序知，$i+1$ 的左孩子之前的两个结点就是 $i$ 的左孩子和右孩子。由归纳假设可知，$i$ 的左孩子编号为 $2i$，故 $i$ 的右孩子编号为 $2i+1$，从而 $i+1$ 的左孩子编号为 $2i+2=2(i+1)$。至此，2 得证。
>
> 由 2 可直接推出 3，由 2 和 3 又可得到 1，证毕。

### 5.2.4 二叉树的存储结构

#### 5.2.4.1 顺序存储结构

```C{.line-numbers}
//-----二叉树的顺序存储表示-----
#define MAXTSIZE 100 // 二叉树的最大结点数

typedef TElemType SqBiTree[MAXTSIZE];
```

顺序存储结构使用一组地址连续的存储单元来存储数据元素，为了能够在存储结构中反映出结点之间的逻辑关系，必须将二叉树中的结点依照一定的规律安排在这组单元中。

对于完全二叉树，只要从根起按层序存储即可，依次自上而下、自左至右存储结点元素，即将完全二叉树上编号为 $i$ 的结点元素存储在如上定义的一维数组中下标为 $i-1$ 的分量中。

对于一般二叉树，应将其每个结点与完全二叉树上的结点相对照，存储在一维数组的相应分量中。

顺序存储结构仅适用于完全二叉树或近似完全二叉树，而一般二叉树不适合。在最坏的情况下，一个深度为 $k$ 且只有 $k$ 个结点的单支树却需要长度为 $2^k-1$ 的一维数组，这造成了存储空间的极大浪费。

#### 5.2.4.2 链式存储结构

由二叉树的定义得知，二叉树的结点由一个数据元素和分别指向其左、右子树的两个分支构成，如图 5.6(a) 所示。则表示二叉树的链表中的结点至少包含 3 个域：数据域和左、右指针域，如图 5.6(b) 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.6-二叉树的结点及其存储结构.l8aks5na5sg.png">
    <br>
    图 5.6&nbsp;&nbsp;&nbsp;&nbsp;二叉树的结点及其存储结构
</div>

为了便于找到结点的双亲，还可以在结点结构中增加一个指向其双亲结点的指针域，如图 5.6(c) 所示。

利用这两种结点结构所得二叉树的存储结构分别称为二叉链表和三叉链表，如图 5.7 所示。链表的头指针指向二叉树的根结点。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.7-二叉树的链表存储结构.15phrzbxcpls.png">
    <br>
    图 5.7&nbsp;&nbsp;&nbsp;&nbsp;二叉树的链表存储结构
</div>

```C{.line-numbers}
//-----二叉树的二叉链表存储表示-----
typedef struct BiTNode
{
    TElemType data; // 数据域
    struct BiTNode *lchild; // 左孩子指针
    struct BiTNode *rchild; // 右孩子指针
} BiTNode, *BiTree;
```

**性质 6**&nbsp;&nbsp;&nbsp;&nbsp;在含有 $n$ 个结点的二叉链表中有 $n+1$ 个空指针域。

> **证明：** 设二叉链表中叶子结点的个数为 $n_0$，度为 1 的结点个数为 $n_1$，度为 2 的结点个数为 $n_2$，则
>
> $$
> n=n_0+n_1+n_2
> $$
>
> 设二叉链表中非空指针域的数量为 $B$，则
>
> $$
> B=n_1+2n_2
> $$
>
> 二叉链表中指针域的个数为 $2n$，则空指针域的个数为
>
> $$
> \begin{aligned}
>     n_{\text{NULL}}&=2n-B\\
>     &=2(n_0+n_1+n_2)-(n_1+2n_2)\\
>     &=2n_0+n_1\\
>     &=n_0+n_1+n_2+1\\
>     &=n+1
> \end{aligned}
> $$

### 5.2.5 二叉树的遍历

#### 5.2.5.1 遍历二叉树算法描述

遍历二叉树是指按某条搜索路径巡访树中每个结点，使得每个结点均被访问一次，而且仅被访问一次。遍历二叉树是二叉树最基本的操作，也是二叉树其他各种操作的基础。遍历的实质是对二叉树进行线性化的过程，即遍历的结果是将非线性结构的树中结点排成一个线性序列。

先序遍历二叉树的操作定义如下：若二叉树为空，则空操作；否则

1. 访问根节点；
2. 先序遍历左子树；
3. 先序遍历右子树。

中序遍历二叉树的操作定义如下：若二叉树为空，则空操作；否则

1. 中序遍历左子树；
2. 访问根节点；
3. 中序遍历右子树。

后序遍历二叉树的操作定义如下：若二叉树为空，则空操作；否则

1. 后序遍历左子树；
2. 后序遍历右子树；
3. 访问根节点。

> **算法 5.1**&nbsp;&nbsp;&nbsp;&nbsp;中序遍历二叉树的递归算法

```C++{.line-numbers}
void InOrderTraverse(BiTree T)
{
    if (T) // 若二叉树非空
    {
        InOrderTraverse(T->lchild); // 中序遍历左子树
        cout << T->data; // 访问根节点
        InOrderTraverse(T->rchild); // 中序遍历右子树
    }
}
```

从算法来看，3 种遍历算法的不同之处仅在于访问根结点和遍历左、右子树的先后关系，算法中的输出语句与两条递归语句的相对位置不同。如果在算法中暂且去掉和递归无关的`cout`语句，则 3 个遍历算法完全相同。因此，从递归执行过程的角度来看，先序、中序和后序遍历是完全相同的。

从遍历序列来看，3 种不同遍历序列中叶子结点间的相对次序是相同的，都是按照从左到右的次序排列，3 种遍历序列间的区别仅在于非终端结点间的次序以及非终端结点和叶子结点间的次序有所不同。

可以利用栈将递归算法改写成非递归算法。例如，从中序遍历递归算法执行过程中递归工作栈的状态可见：

1. 工作记录中包含两项，其一是递归调用的语句编号，其二是指向根结点的指针。
2. 当栈顶记录中的指针非空时，应遍历左子树，即指向左子树根的指针进栈。
3. 若栈顶记录中的指针为空，则应退至上一层。若是从左子树返回，则应访问当前层中指针所指的根结点；若是从右子树返回，则表明当前层的遍历结束，应继续退栈。从另一个角度看，遍历右子树时不再需要保存当前层的根指针，直接修改栈顶记录中的指针即可。

> **算法 5.2**&nbsp;&nbsp;&nbsp;&nbsp;中序遍历的非递归算法
>
> 1. 初始化一个空栈`S`，指针`p`指向根结点。
> 2. 申请一个结点空间`q`，用来存放栈顶弹出的元素。
> 3. 当`p`非空或者栈`S`非空时，循环执行以下操作：
>    - 如果`p`非空，则将`p`进栈，`p`指向该结点的左孩子；
>    - 如果`p`为空，则弹出栈顶元素并访问，将`p`指向该结点的右孩子。

```C++{.line-numbers}
void InOrderTraverse(BiTree T)
{
    InitStack(S);
    BiTNode *p = T;
    BiTNode *q = new BiTNode;
    
    while (p || !StackEmpty(S)) // p 非空或栈 S 非空时，继续循环
    {
        if (p) // p 非空
        {
            Push(S, p); // 根指针进栈
            p = p->lchild; // 遍历左子树
        }
        else // p 为空
        {
            Pop(S, q); // 退栈
            cout << q->data; // 访问根结点
            p = q->rchild;
        }
    }
}
```

无论是递归还是非递归遍历二叉树，无论按哪一种次序进行遍历，对含 $n$ 个结点的二叉树，其时间复杂度均为 $O(n)$。所需辅助空间为遍历过程中栈的最大容量，即树的深度，最坏情况下为 $n$，则空间复杂度也为 $O(n)$。

#### 5.2.5.2 根据遍历序列确定二叉树

若二叉树中各结点的值均不相同，任意一棵二叉树结点的先序序列、中序序列和后序序列都是唯一的。

仅根据先序序列或中序序列或后序序列，不能确定相应二叉树的结构。

由二叉树的先序序列和中序序列，或由其后序序列和中序序列均能唯一地确定一棵二叉树。但是，由一棵二叉树的先序序列和后序序列不能唯一确定一棵二叉树，因为无法确定左右子树两部分。

#### 5.2.5.3 二叉树遍历算法的应用

> **算法 5.3**&nbsp;&nbsp;&nbsp;&nbsp;先序遍历的顺序建立二叉链表
>
> 为简化问题，设二叉树中结点的元素均为一个单字符。则算法步骤如下：
>
> 1. 扫描字符序列，读入字符`ch`。
> 2. 如果`ch`是结束字符（`'#'`），则表明该二叉树为空树，即`T`为`NULL`；否则执行以下操作：
>    （1）申请一个结点空间`T`；
>    （2）将`ch`赋给`T->data`；
>    （3）递归创建`T`的左子树；
>    （4）递归创建`T`的右子树。

```C++{.line-numbers}
// 按先序次序输入二叉树结点中的值，创建二叉链表表示的二叉树 T
void CreateBiTree(BiTree &T)
{
    char ch;
    cin >> ch;
    if (ch == '#')
        T = NULL;
    else
    {
        T = new BiTNode; // 生成根结点
        T->data = ch;
        CreateBiTree(T->lchild); // 递归创建左子树
        CreateBiTree(T->rchild); // 递归创建右子树
    }
}
```

> **算法 5.4**&nbsp;&nbsp;&nbsp;&nbsp;复制二叉树
>
> 如果是空树，递归结束，否则执行以下操作：
>
> 1. 申请一个新的结点空间，复制根结点；
> 2. 递归复制左子树；
> 3. 递归复制右子树。

```C++{.line-numbers}
// 复制一棵与 T 完全相同的二叉树
void Copy(BiTree T, BiTree &NewT)
{
    if (T == NULL) // 如果是空树，递归结束
    {
        NewT = NULL;
    }
    else
    {
        NewT = new BiTNode;
        NewT->data = T->data; // 复制根结点
        Copy(T->lchild, NewT->lchild); // 递归复制左子树
        Copy(T->rchild, NewT->rchild); // 递归复制右子树
    }
}
```

> **算法 5.5**&nbsp;&nbsp;&nbsp;&nbsp;计算二叉树的深度
>
> 如果是空树，递归结束，深度为 0，否则执行以下操作：
>
> 1. 递归计算左子树的深度，记为 $m$；
> 2. 递归计算右子树的深度，记为 $n$；
> 3. 如果 $m>n$，则二叉树的深度为 $m+1$，否则为 $n+1$。

```C{.line-numbers}
int Depth(BiTree T)
{
    if (T == NULL) // 如果是空树，递归结束，深度为 0
        return 0;
    else
    {
        int m = Depth(T->lchild); // 递归计算左子树的深度
        int n = Depth(T->rchild); // 递归计算右子树的深度
        return m > n ? m + 1 : n + 1;
    }
}
```

> **算法 5.6**&nbsp;&nbsp;&nbsp;&nbsp;统计二叉树中结点的个数

```C{.line-numbers}
int NodeCount(BiTree T)
{
    if (T == NULL) // 如果是空树，则结点个数为 0
        return 0;
    else // 否则，结点个数 = 左子树的结点个数 + 右子树的结点个数 + 1
        return NodeCount(T->lchild) + NodeCount(T->rchild) + 1;
}
```

## 5.3 线索二叉树

### 5.3.1 线索二叉树的基本概念

遍历二叉树是以一定规则将二叉树中的结点排列成一个线性序列，这实质上是对一个非线性结构进行线性化操作，使每个结点（除第一个和最后一个外）有且仅有一个直接前驱和直接后继。但是，当以二叉链表作为存储结构时，只能找到结点的左、右孩子信息，而不能直接得到结点在任一序列中的前驱和后继信息，这种信息只有在遍历的动态过程中才能得到。为此，引入线索二叉树来保存这些在动态过程中得到的有关前驱和后继的信息。

由于有 $n$ 个结点的二叉链表中必定存在 $n+1$ 个空指针域，因此可以充分利用这些空指针域来存放结点的前驱和后继信息。

规定：若结点有左子树，则其`lchild`域指示其左孩子，否则令`lchild`域指示其前驱；若结点有右子树，则其`rchild`域指示其右孩子，否则令`rchild`域指示其后继。为了避免混淆，需要改变结点结构，增加两个标志域，其结点形式如图 5.8 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.8-线索二叉树的结点形式.2fl4n7wy3izo.png">
    <br>
    图 5.8&nbsp;&nbsp;&nbsp;&nbsp;线索二叉树的结点形式
</div>

其中，`LTag`为 0 时，`lchild`域指示结点的左孩子；`LTag`为 1 时，`lchild`域指示结点的前驱。`RTag`为 0 时，`rchild`域指示结点的右孩子；`RTag`为 1 时，`rchild`域指示结点的后继。

二叉树的二叉线索类型定义如下：

```C{.line-numbers}
//-----二叉树的二叉线索存储表示-----
typedef struct BiThrNode
{
    TElemType data;
    struct BiThrNode *lchild;
    struct BiThrNode *rchild;
    int LTag;
    int RTag;
} BiThrNode, *BiThrTree;
```

以这种结点结构构成的二叉链表作为二叉树的存储结构叫做**线索链表**，其中指向结点前驱和后继的指针叫做**线索**。加上线索的二叉树叫做**线索二叉树**（Threaded Binary Tree）。对二叉树以某种次序遍历使其变为线索二叉树的过程叫做**线索化**。

例如，图 5.9(a) 所示为中序线索二叉树，与其对应的中序线索链表如图 5.9(b) 所示，其中实线为指针，虚线为线索。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.9-线索二叉树及其存储结构.k3tpcm4499c.png">
    <br>
    图 5.9&nbsp;&nbsp;&nbsp;&nbsp;线索二叉树及其存储结构
</div>

为了方便起见，在二叉树的线索链表上也添加一个头结点，并令其`lchild`域的指针指向二叉树的根结点，其`rchild`域的指针指向遍历序列的最后一个结点。同时，令遍历序列中第一个结点的`lchild`域指针和最后一个结点`rchild`域的指针均指向头结点。这好比为二叉树建立了一个双向线索链表，既可以从第一个结点起沿后继进行遍历，也可以从最后一个结点起沿前驱进行遍历。

### 5.3.2 构造线索二叉树

由于线索二叉树构造的实质是将二叉链表中的空指针改为指向前驱或后继的线索，而前驱或后继的信息只有在遍历时才能得到，因此线索化的过程即为在遍历的过程中修改空指针的过程。对二叉树按照不同的遍历次序进行线索化，可以得到不同的线索二叉树，包括先序线索二叉树、中序线索二叉树和后序线索二叉树。

为了记下遍历过程中访问结点的先后关系，附设一个指针`pre`始终指向刚刚访问过的结点，而指针`p`指向当前访问的结点，由此记录下遍历过程中访问结点的先后关系。

> **算法 5.7**&nbsp;&nbsp;&nbsp;&nbsp;以结点`p`为根的子树中序线索化
>
> 1. 如果`p`非空，左子树递归线索化。
> 2. 如果`p`的左孩子为空，则给`p`加上左线索，将`p->LTag`置为 1，让`p->lchild`指向`pre`；否则将`p->LTag`置为 0。
> 3. 如果`pre`的右孩子为空，则给`pre`加上右线索，将`pre->RTag`置为 1，让`pre->rchild`指向`p`；否则将`pre->RTag`置为 0。
> 4. 将`pre`指向`p`。
> 5. 右子树递归线索化。

```C{.line-numbers}
// pre 是全局变量，初始化时其右孩子指针为空，便于在树的最左点开始建线索
void InThreading(BiThrTree p)
{
    if (p)
    {
        InThreading(p->lchild); // 左子树递归线索化
        if (!p->lchild) // p 的左孩子为空
        {
            p->LTag = 1; // 给 p 加上左线索
            p->lchild = pre;
        }
        else
        {
            p->LTag = 0;
        }
        
        if (!pre->rchild) // pre 的右孩子为空
        {
            pre->RTag = 1; // 给 pre 加上右线索
            pre->rchild = p;
        }
        else
        {
            pre->RTag = 0;
        }
        
        pre = p;
        InThreading(p->rchild); // 右子树递归线索化
    }
}
```

> **算法 5.8**&nbsp;&nbsp;&nbsp;&nbsp;带头结点的二叉树中序线索化

```C++{.line-numbers}
// 中序遍历二叉树 T，并将其中序线索化，Thrt 指向头结点
void InOrderThreading(BiThrTree &Thrt, BiThrTree T)
{
    Thrt = new BiThrNode; // 建头结点
    Thrt->LTag = 0; // 头结点的左指针指向根结点
    Thrt->RTag = 1; // 头结点的右指针为右线索
    Thrt->rchild = Thrt; // 初始化时右指针指向自己
    if (!T)
        Thrt->lchild = Thrt; // 若树为空，则左指针也指向自己
    else
    {
        Thrt->lchild = T; // 头结点的左指针指向根结点
        pre = Thrt; // pre 初值指向头结点
        InThreading(T); // 调用算法5.7，对以 T 为根的二叉树进行中序线索化
        pre->rchild = Thrt; // 算法5.7结束后，pre为最右结点，pre的右线索指向头结点
        pre->RTag = 1;
        Thrt->rchild = pre; // 头结点的右线索指向最后一个结点
    }
}
```

### 5.3.3 遍历线索二叉树

由于有了结点的前驱和后继信息，线索二叉树的遍历和在指定次序下查找结点的前驱和后继算法都变得简单。因此，若需经常查找结点在遍历序列中的前驱和后继，则采用线索链表作为存储结构。

下面分 3 种情况讨论在线索二叉树中如何查找结点的前驱和后继。

1. 在中序线索二叉树中查找
   （1）查找`p`指针所指结点的前驱
   - 若`p->LTag`为 1，则`p`的左链指示其前驱。
   - 若`p->LTag`为 0，说明`p`有左子树，结点的前驱是遍历左子树时最后访问的结点（左子树中最右下的结点）。

   （2）查找`p`指针所指结点的后继
   - 若`p->RTag`为 1，则`p`的右链指示其后继。
   - 若`p->RTag`为 0，说明`p`有右子树，结点的后继是遍历右子树时访问的第一个结点（右子树中最左下的结点）。
2. 在先序线索二叉树中查找
   （1）查找`p`指针所指结点的前驱
   - 若`p->LTag`为 1，则`p`的左链指示其前驱。
   - 若`p->LTag`为 0，说明`p`有左子树，此时`p`的前驱有两种情况：若`*p`是其双亲的左孩子，则其前驱为其双亲结点；否则应是其双亲的左子树上先序遍历最后访问到的结点。

   （2）查找`p`指针所指结点的后继
   - 若`p->RTag`为 1，则`p`的右链指示其后继。
   - 若`p->RTag`为 0，说明`p`有右子树，结点的后继是其左子树根（若存在）或右子树根。
3. 在后序线索二叉树中查找
   （1）查找`p`指针所指结点的前驱
   - 若`p->LTag`为 1，则`p`的左链指示其前驱。
   - 若`p->LTag`为 0，当`p->RTag`也为 0 时，则`p`的右链指示其前驱；若`p->LTag`为 0，而`p->RTag`为 1 时，则`p`的左链指示其前驱。

   （2）查找`p`指针所指结点的后继
   - 若`*p`是二叉树的根，则其后继为空。
   - 若`*p`是其双亲的右孩子，则其后继为双亲结点。
   - 若`*p`是其双亲的左孩子，且`*p`没有右兄弟，则其后继为双亲结点。
   - 若`*p`是其双亲的左孩子，且`*p`有右兄弟，则其后继为双亲的右子树上按后序遍历列出的第一个结点（即右子树中最左下的叶结点）。

从以上分析可以看出，在后序线索二叉树中查找后继和在先序线索二叉树中查找前驱并不总是有效的。

由于有了结点的前驱和后继的信息，线索二叉树的遍历操作无需设栈，避免了频繁的进栈、出栈，因此在时间上和空间上都比遍历二叉树节省。如果遍历某种次序的线索二叉树，只要从该次序下的根结点出发，反复查找其在该次序下的后继，直到叶子结点。

> **算法 5.9**&nbsp;&nbsp;&nbsp;&nbsp;遍历中序线索二叉树
>
> 1. 指针`p`指向根结点。
> 2. `p`为非空树或遍历未结束时，循环执行以下操作：
>    （1）沿左孩子向下，到达最左下结点`*p`，它是中序的第一个结点。
>    （2）访问`*p`。
>    （3）沿右线索反复查找当前结点`*p`的后继结点并访问后继结点，直至右线索为 0 或者遍历结束。
>    （4）转向`p`的右子树。

```C{.line-numbers}
// T 指向头结点，头结点的左链 lchild 指向根结点
// 中序遍历线索二叉树 T 的非递归算法，对每个元素直接输出
void InOrderTraverse_Thr(BiThrTree T)
{
    BiThrNode *p = T->lchild; // p 指向根结点
    while (p != T)
    {
        while (p->LTag == 0) // 沿左孩子向下
            p = p->lchild;
        cout << p->data; // 访问其左子树为空的结点
        while (p->RTag == 1 && p->rchild != T) // 沿右线索访问后继结点
        {
            p = p->rchild;
            cout << p->data;
        }
        p = p->rchild; // 转向 p 的右子树
    }
}
```

遍历中序线索二叉树的时间复杂度为 $O(n)$，空间复杂度为 $O(1)$。

## 5.4 树和森林

### 5.4.1 树的抽象数据类型定义

$$
\begin{aligned}
    & \texttt{ADT Tree \{}\\
    & \quad\texttt{数据对象\,$D$：$D$\,是具有相同特性的数据元素的集合}\\
    & \quad\texttt{数据关系\,$R$：若\,$D$\,为空集，则称为空树；若\,$D$\,仅含一个数据元素，则\,$R$\,为空集；}\\
    & \qquad\qquad\qquad\quad\texttt{否则\,$R=\{H\}$，$H$\,是如下二元关系：}\\
    & \qquad\qquad\qquad\quad\texttt{（1）在\,$D$\,中存在唯一的称为根的数据元素\,root，它在关系\,$H$\,下无前驱;}\\
    & \qquad\qquad\qquad\quad\texttt{（2）若\,$D-\{\text{root}\}\not=\text{\O}$，则存在\,$D-\{\text{root}\}$\,的一个划分}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$D_1,D_2,\cdots,D_m(m>0)$，对任意\,$j\not=k(1\leqslant j,k\leqslant m)$\,有}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$D_j\cap D_k=\text{\O}$，且对任意的\,$i(1\leqslant i\leqslant m)$，唯一存在数据元素}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$x_i\in D_i$，有\,$\textrm{<}\text{root},x_i\textrm{>}\in H$；}\\
    & \qquad\qquad\qquad\quad\texttt{（3）对应于\,$D-\{\text{root}$\}\,的划分，$H-\{\textrm{<}\text{root},x_1\textrm{>},\cdots,\textrm{<}\text{root},x_m\textrm{>}\}$}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{有唯一的一个划分\,$H_1,H_2,\cdots,H_m(m>0)$，对任意\,$j\not=k(1\leqslant j,k\leqslant m)$有}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$H_j\cap H_k=\text{\O}$，且对任意\,$i(1\leqslant i\leqslant m)$，$H_i$\,是\,$D_i$\,上的二元关系，}\\
    & \qquad\qquad\qquad\qquad\quad\ \ \texttt{$(D_i,\{H_i\})$\,是一棵符合本定义的树，称为根\,root\,的子树。}\\
    & \quad\texttt{基本操作\,$P$：}\\
    & \qquad\texttt{InitTree(\&T)}\\
    & \qquad\quad\texttt{操作结果：构造空树\,T}\\
    & \qquad\texttt{DestroyTree(\&T)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：销毁树\,T}\\
    & \qquad\texttt{CreateTree(\&T, definition)}\\
    & \qquad\quad\texttt{初始条件：definition\,给出树\,T\,的定义}\\
    & \qquad\quad\texttt{操作结果：按\,definition\,构造树\,T}\\
    & \qquad\texttt{ClearTree(\&T)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：将树\,T\,清为空树}\\
    & \qquad\texttt{TreeEmpty(T)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：若\,T\,为空树，则返回\,true，否则返回\,false}\\
    & \qquad\texttt{TreeDepth(T)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：返回\,T\,的深度}\\
    & \qquad\texttt{Root(T)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：返回\,T\,的根}\\
    & \qquad\texttt{Value(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：返回\,cur\_e\,的值}\\
    & \qquad\texttt{Assign(T, cur\_e, value)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：结点\,cur\_e\,赋值为\,value}\\
    & \qquad\texttt{Parent(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：若\,cur\_e\,是\,T\,的非根结点，则返回它的双亲，否则返回“空”}\\
    & \qquad\texttt{LeftChild(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：若\,cur\_e\,是\,T\,的非叶子结点，则返回它的最左孩子，否则返回“空”}\\
    & \qquad\texttt{RightSibling(T, cur\_e)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在，cur\_e\,是\,T\,中某个结点}\\
    & \qquad\quad\texttt{操作结果：若\,cur\_e\,有右兄弟，则返回它的右兄弟，否则返回“空”}\\
    & \qquad\texttt{InsertChild(\&T, p, i, c)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在，p\,指向\,T\,中某个结点，$1\leqslant i\leqslant \text{p\,所指结点的度}+1$，}\\
    & \qquad\qquad\qquad\qquad\texttt{非空树\,c\,与\,T\,不相交}\\
    & \qquad\quad\texttt{操作结果：插入\,c\,为\,T\,中\,p\,所指结点的第\,i\,棵子树}\\
    & \qquad\texttt{DeleteChild(\&T, p, i)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在，p\,指向\,T\,中某个结点，$1\leqslant i\leqslant \text{p\,所指结点的度}$}\\
    & \qquad\quad\texttt{操作结果：删除\,T\,中\,p\,所指结点的第\,i\,棵子树}\\
    & \qquad\texttt{TraverseTree(T)}\\
    & \qquad\quad\texttt{初始条件：树\,T\,存在}\\
    & \qquad\quad\texttt{操作结果：按某种次序对\,T\,的每个结点访问一次}\\
    & \texttt{\} ADT Tree}
\end{aligned}
$$

### 5.4.2 树的存储结构

#### 5.4.2.1 双亲表示法

这种表示法中，以一组连续的存储单元存储树的结点，每个结点除了数据域`data`外，还附设一个`parent`域用以指示其双亲结点的位置。

例如，图 5.10 为一棵树及其双亲表示的存储结构。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.10-树的双亲表示法示例.6f2ga4vc5yo0.png">
    <br>
    图 5.10&nbsp;&nbsp;&nbsp;&nbsp;树的双亲表示法示例
</div>

这种存储结构利用了每个结点只有唯一双亲的性质。在这种存储结构下，求结点的双亲十分方便，也容易求树的根，但求结点的孩子时需要遍历整个结构。

#### 5.4.2.2 孩子表示法

由于树中每个结点可能有多棵子树，则可用多重链表，即每个结点有多个指针域，每个指针指向一棵子树的根结点。此时链表中的结点可以有如图 5.11 所示的两种结点格式。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.11-孩子表示法的两种结点.4vfsjkrug7w0.png">
    <br>
    图 5.11&nbsp;&nbsp;&nbsp;&nbsp;孩子表示法的两种结点
</div>

若采用第一种结点格式，则多重链表中的结点是同构的，其中 $d$ 为树的度。由于树中很多结点的度小于 $d$，所以链表中有很多空链域，空间较浪费。在一棵有 $n$ 个结点、度为 $k$ 的树中，共有 $nk$ 个指针域，而树中只有 $n-1$ 条边，故树中的空指针数目为 $nk-(n-1)=n(k-1)+1$。

若采用第二种结点格式，则多重链表中的结点是不同构的，其中 $d$ 为结点的度，`degree`域的值与 $d$ 相同。此时，虽能节约存储空间，但操作和管理不方便。

另一种办法是，把每个结点的孩子结点排列起来，看成是一个线性表，且以单链表做存储结构，则 $n$ 个结点有 $n$ 个孩子链表。$n$ 个头指针又组成一个线性表，为了便于查找，可采用顺序存储结构。这种方法称为孩子链表表示法。图 5.12 所示为图 5.10 中的树的孩子链表表示法。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.12-孩子链表.6vzg9ymdtgg0.png">
    <br>
    图 5.12&nbsp;&nbsp;&nbsp;&nbsp;孩子链表
</div>

与双亲表示法相反，孩子表示法便于那些涉及孩子的操作的实现。可以把双亲表示法和孩子表示法结合起来，将双亲表示与孩子链表合在一起，形成双亲孩子链表表示法，如图 5.13 所示。

<div align="center">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.13-带双亲的孩子链表.7b51hd7owds0.png">
    <br>
    图 5.13&nbsp;&nbsp;&nbsp;&nbsp;带双亲的孩子链表
</div>

#### 5.4.2.3 孩子兄弟法

又称二叉树表示法，或二叉链表表示法，即以二叉链表做树的存储结构。链表中结点的两个链域分别指向该结点的第一个孩子结点和下一个兄弟结点，分别命名为`firstchild`域和`nextsibling`域，其结点形式如图 5.14 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.14-孩子兄弟表示法的结点.5ub3z68gir40.png">
    <br>
    图 5.14&nbsp;&nbsp;&nbsp;&nbsp;孩子兄弟表示法的结点
</div>

```C{.line-numbers}
// 树的二叉链表（孩子兄弟）存储表示
typedef struct CSNode
{
    ElemType data;
    struct CSNode *firstchild;
    struct CSNode *nextsibling;
} CSNode, *CSTree;
```

图 5.15 所示为图 5.10 中的树的孩子兄弟链表。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.15-孩子兄弟表示法示例.1x88lbixdrmo.png">
    <br>
    图 5.15&nbsp;&nbsp;&nbsp;&nbsp;孩子兄弟表示法示例
</div>

利用这种存储结构便于实现各种树的操作。首先易于实现找结点孩子等的操作。例如，若要访问结点`x`的第 $i$ 个孩子，则只要先从`firstchild`域找到第 1 个孩子结点，然后沿着孩子结点的`nextsibling`域连续走 $i-1$ 步，便可找到`x`的第 $i$ 个孩子。如果为每个结点增设一个`parent`域，则同样能方便地实现查找双亲的操作。

这种存储结构的优点是它和二叉树的二叉链表表示完全一样，便于将一般的树结构转换为二叉树进行处理，利用二叉树的算法来实现对树的操作。因此孩子兄弟表示法是应用较为普遍的一种树的存储表示方法。

### 5.4.3 树与二叉树的转换

从树的二叉链表表示的定义可知，任何一棵与树对应的二叉树，其根结点的右子树必为空。若把森林中第二棵树的根结点看成是第一棵树的根结点的兄弟，则同样可导出森林和二叉树的对应关系，这个一一对应的关系说明森林或树与二叉树可以相互转换。

任何一个森林都对应一棵二叉树，反之，任何一棵二叉树对应一个唯一的森林，称这个变换为森林与二叉树之间的自然对应。

#### 5.4.3.1 树转换成二叉树

将树转换成二叉树的方法为：

1. 在所有兄弟结点之间加一条连线。
2. 对每个结点，除保留与其大儿子和其大兄弟结点的连线之外，去掉该结点与其他孩子结点的连线。
3. 调整部分连线方向、长短，使之成为规范图形。

#### 5.4.3.2 二叉树转换成树

如果二叉树根结点的右子树为空，则能将该二叉树转换成树，方法为：

1. 对每个结点，找其大兄弟结点的双亲，并在两者间加一条连线。
2. 去掉所有结点和右孩子之间的连线。
3. 调整部分连线方向、长短，使之成为规范图形。

#### 5.4.3.3 森林转换成二叉树

如果 $F=\{T_1,T_2,\cdots,T_m\}$ 是森林，则可按如下规则转换成一棵二叉树 $B=(root,LB,RB)$：

1. 若 $F$ 为空，即 $m=0$，则 $B$ 为空树。
2. 若 $F$ 非空，则 $m\not=0$，则 $B$ 的根 $root$ 即为森林中第一棵树的根 $\operatorname{ROOT}(T_1)$，$B$ 的左子树 $LB$ 是从 $T_1$ 中根结点的子树森林 $F_1=\{T_{11},T_{12},\cdots,T_{1n}\}$ 转换而成的二叉树，其右子树 $RB$ 是从森林 $F'=\{T_2,T_3,\cdots,T_m\}$ 转换而成的二叉树。

实际操作时，可以将森林中每一棵树转换成二叉树，将第一棵二叉树的根结点作为总根，将其他二叉树的根结点视为兄弟，依次从左至右连接在一起。

#### 5.4.3.4 二叉树转换成森林

如果二叉树根结点的右子树非空，则能将该二叉树转换成森林。

如果 $B=(root,LB,RB)$ 是一棵二叉树，则可按如下规则转换成森林 $F=\{T_1,T_2,\cdots,T_m\}$：

1. 若 $B$ 为空，则 $F$ 为空。
2. 若 $B$ 非空，则 $F$ 中第一棵树 $T_1$ 的根 $\operatorname{ROOT}(T_1)$ 即为二叉树 $B$ 的根 $root$，$T_1$ 中根结点的子树森林 $F_1$ 是由 $B$ 的左子树 $LB$ 转换而成的森林，$F$ 中除 $T_1$ 之外其余树组成的森林 $F'=\{T_2,T_3,\cdots,T_m\}$ 是由 $B$ 的右子树 $RB$ 转换而成的森林。

实际操作时，可以从根结点出发，断开每个结点与其右孩子的连线，直至某个结点没有右孩子为止，得到若干棵二叉树，再将每棵二叉树转换成树，就可以得到对应的森林。

### 5.4.4 树和森林的遍历

#### 5.4.4.1 树的遍历

先根遍历树：先访问树的根结点，然后依次先根遍历根结点的每棵子树。

后根遍历树：先依次后根遍历每棵子树，然后访问根结点。

树的先根遍历序列等于其对应的二叉树的先序序列，树的后根遍历序列等于其对应的二叉树的中序序列。当以二叉链表做树的存储结构时，树的先根遍历和后根遍历可借用二叉树的先序遍历和中序遍历的算法实现。

#### 5.4.4.2 森林的遍历

先序遍历森林：

1. 访问森林中第一棵树的根结点。
2. 先序遍历第一棵树的根结点的子树森林。
3. 先序遍历除去第一棵树之后剩余的树构成的森林。

中序遍历森林：

1. 中序遍历森林中第一棵树的根结点的子树森林。
2. 访问第一棵树的根结点。
3. 中序遍历除去第一棵树之后剩余的树构成的森林。

当森林转换成二叉树时，其第一棵树的子树森林转换成左子树，剩余树的森林转换成右子树，则森林的先序和中序遍历即为其对应的二叉树的先序和中序遍历。

### 5.4.5 树的顺序表示

仅用先序序列无法确定树的结构。

**定理 5.1**&nbsp;&nbsp;&nbsp;&nbsp;如果已知一棵树的先序序列和每个结点的度，则能唯一确定该树的结构。

> **证明：** 用数学归纳法。若树只有一个结点，定理成立。
>
> 假设树结点个数小于 $n\,(n\geqslant 2)$ 时，定理成立。
>
> 当树有 $n$ 个结点时，由树的先序序列的定义可知，序列中的第一个结点为根结点（设为 A）。设 A 的度为 $k$，由 $n\geqslant 2$ 可知 $k\geqslant 1$，因此 A 有 $k$ 棵子树，且第一棵子树排在最前面，第 $k$ 棵子树排在最后面，并且每棵子树的结点个数小于 $n$。由归纳假设知，每棵子树都能唯一确定，从而以 A 为根的树也能唯一确定，证毕。

因此可以采用先序序列和结点的度来存储一棵树。

同理，如果已知一棵树的后序序列和每个结点的度，也能唯一确定树的结构。因此，也可以用后序序列和结点的度来存储一棵树。

确定树结构的另一种思路是指明一个结点的孩子链表何时结束。具体方法为：

1. 在遍历序列中使用“)”指明孩子链表的结束。
2. 叶子结点没有孩子，所有叶子结点后都有一个“)”。
3. 如果一个叶子结点同时是其双亲结点的最后一个孩子，那么该叶子结点后就会有连续两个或多个“)”。

该方法称为使用孩子链表结束符的顺序表示法，其特点如下：

1. 若树的结点数为 $n$，则需要保存 $n$ 个孩子链表结束符。与保存结点度的方法相比，此方法需要的空间可望更少。
2. 该方法与树的括号表示法类似。
3. 利用该方法创建树的算法与使用先序序列创建二叉树的算法类似。

树的顺序表示不保存指针，优点是节省空间；缺点是访问任何结点都需要顺序地处理该结点之前的所有结点，相比于树的其他存储方法，顺序表示丧失了结点访问的有效性。因此，树的顺序表示更适合作为树的输入输出，为树的创建、存储到硬盘、序列化等应用提供支持，并在需要的时候重构树。

## 5.5 哈夫曼树及其应用

### 5.5.1 哈夫曼树的基本概念

**哈夫曼树**又称**最优树**，是一类带权路径长度最短的树。

基本概念：

1. 路径：从树中一个结点到另一个结点之间的分支构成这两个结点之间的路径。
2. 路径长度：路径上的分支数目称作路径长度。
3. 树的路径长度：从树根到每一结点的路径长度之和。
4. 权：赋予某个实体的一个量，是对实体的某个或某些属性的数值化描述。
5. 结点的带权路径长度：从该结点到树根之间的路径长度与结点上权的乘积。
6. 树的带权路径长度：树中所有叶子结点的带权路径长度之和，通常记作 $WPL=\displaystyle\sum_{k=1}^n w_k l_k$。其中 $n$ 表示叶子结点的个数，$w_k$ 表示叶子结点的权值，$l_k$ 表示叶子结点到根结点的路径长度。
7. 哈夫曼树：假设有 $m$ 个权值 $\{w_1,w_2,\cdots,w_m\}$，可以构造一棵含 $m$ 个叶子结点的二叉树，每个叶子结点的权为 $w_i$，则其中带权路径长度 $WPL$ 最小的二叉树称作**最优二叉树**或**哈夫曼树**。

### 5.5.2 哈夫曼树的构造算法

哈夫曼树的构造过程：

1. 根据给定的 $n$ 个权值 $\{w_1,w_2,\cdots,w_m\}$，构造 $n$ 棵只有根结点的二叉树，这 $n$ 棵二叉树构成一个森林 $F$。
2. 在森林 $F$ 中选取两棵根结点的权值最小的树作为左右子树构造一棵新的二叉树，且置新的二叉树的根结点的权值为其左、右子树上根结点的权值之和。
3. 在森林 $F$ 中删除这两棵树，同时将新得到的二叉树加入 $F$ 中。
4. 重复 2 和 3，直到 $F$ 只含一棵树为止，这棵树便是哈夫曼树。

哈夫曼树是一种二叉树，而由于哈夫曼树中没有度为 1 的结点，则一棵有 $n$ 个叶子结点的哈夫曼树共有 $2n-1$ 个结点，可以存储在一个大小为 $2n-1$ 的一维数组中。每个结点的存储结构设计如图 5.16 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://cdn.jsdelivr.net/gh/zzx-JLU/images_for_markdown@main/数据结构/图5.16-哈夫曼树的结点结构.7718vqpugrk0.png">
    <br>
    图 5.16&nbsp;&nbsp;&nbsp;&nbsp;哈夫曼树的结点结构
</div>

```C{.line-numbers}
// 哈夫曼树的存储表示
typedef struct
{
    int weight; // 结点的权值
    int parent; // 结点的双亲的下标
    int lchild; // 结点的左孩子的下标
    int rchild; // 结点的右孩子的下标
} HTNode, *HuffmanTree;
```

哈夫曼树的各结点存储在由`HuffmanTree`定义的动态分配的数组中，为了实现方便，数组的 0 号单元不使用，从 1 号单元开始使用，所以数组的大小为 $2n$。将叶子结点集中存储在前面 1~n 号位置，而后面的 $n-1$ 个位置存储其余非叶子结点。

> **算法 5.10**&nbsp;&nbsp;&nbsp;&nbsp;构造哈夫曼树
>
> 1. 初始化：首先动态申请 $2n$ 个单元；然后循环 $2n-1$ 次，从 1 号单元开始，依次将 1 至 $2n-1$ 所有单元中的双亲、左孩子、右孩子的下标都初始化为 0；最后再循环 $n$ 次，输入前 $n$ 个单元中叶子结点的权值。
> 2. 创建树：循环 $n-1$ 次，通过 $n-1$ 次的选择、删除与合并来创建哈夫曼树。选择是从当前森林中选择双亲为 0 且权值最小的两个树根结点`s1`和`s2`；删除是指将结点`s1`和`s2`的双亲改为非 0；合并就是将`s1`和`s2`的权值之和作为一个新结点的权值依次存入到数组的第 $n+1$ 之后的单元中，同时记录这个新结点左孩子的下标为`s1`，右孩子的下标为`s2`。

```C++{.line-numbers}
void CreateHuffmanTree(HuffmanTree &HT, int n)
{
    if (n <= 1) return;
    
    // 初始化
    int m = 2 * n - 1;
    HT = new HTNode[m + 1]; // 申请 2n 个单元
    for (int i = 1; i <= m; i++)
    {
        HT[i].parent = 0;
        HT[i].lchild = 0;
        HT[i].rchild = 0;
    }
    for (int i = 1; i <= n; i++) // 输入前 n 个单元中叶子结点的权值
    {
        cin >> HT[i].weight;
    }
    
    // 创建树
    for (int i = n + 1; i <= m; i++)
    {
        // 在 HT 的前 i-1 个元素中选择双亲为 0 且权值最小的两个结点
        // 返回它们的序号 s1 和 s2
        Select(HT, i - 1, s1, s2);
        HT[i].lchild = s1;
        HT[i].rchild = s2;
        HT[i].weight = HT[s1].weight + HT[s2].weight;
    }
}
```

### 5.5.3 哈夫曼编码

在数据通信、数据压缩问题中，需要将数据文件转换成由二进制字符 0、1 组成的二进制串，称之为编码。

等长编码比较简单，但并不是最优的编码方案，因为每个字符出现的频率不同。如果在编码时考虑字符出现的频率，使频率高的字符采用尽可能短的编码，频率低的字符采用稍长的编码，来构造一种不等长编码，则会获得更好的空间效率。

但对于不等长编码，如果设计得不合理，就会给解码带来困难。例如，如果字母 a、b、c、d 的编码分别为 0、01、010、111，则对于二进制串 “0010” 会有不同的译法，或是 “aba”，或是 “ac”。因此，若要设计不等长编码，必须满足一个条件：任何一个字符的编码都不是另一个字符的编码的前缀。

**定义**&nbsp;&nbsp;&nbsp;&nbsp;如果在一个编码方案中，任何一个编码都不是其他任何编码的前缀，则称编码是**前缀编码**。

前缀编码可以保证对压缩文件进行解码时不产生二义性，确保正确解码。

**定义**&nbsp;&nbsp;&nbsp;&nbsp;对一棵具有 $n$ 个叶子的哈夫曼树，若对树中的每个左分支赋予 0，右分支赋予 1，则从根到每个叶子的路径上，各分支的赋值分别构成一个二进制串，该二进制串称为**哈夫曼编码**。

哈夫曼编码满足下面的两个性质。

**性质 1**&nbsp;&nbsp;&nbsp;&nbsp;哈夫曼编码是前缀编码。

> **证明：** 哈夫曼编码是根到叶子路径上的编码序列，由树的特点可知，若路径 A 是另一条路径 B 的最左部分，则 A 的终点一定不是叶子。而哈夫曼编码对应路径的终点一定为叶子，因此，任一哈夫曼编码都不会与任意其他哈夫曼编码的前缀部分完全重叠，因此哈夫曼编码是前缀编码。

**性质 2**&nbsp;&nbsp;&nbsp;&nbsp;哈夫曼编码是最优前缀编码。

对于包括 $n$ 个字符的数据文件，分别以它们的出现次数为权值构造哈夫曼树，则利用该树对应的哈夫曼编码对文件进行编码，能使该文件压缩后对应的二进制文件的长度最短。

由于每个哈夫曼编码是变长编码，因此使用一个指针数组来存放每个字符编码串的首地址。

```C
// 哈夫曼编码表的存储表示
typedef char **HuffmanCode;
```

各字符的哈夫曼编码存储在由`HuffmanCode`定义的动态分配的数组`HC`中。为了实现方便，数组的 0 号单元不使用，从 1 号单元开始使用，所以数组`HC`的大小为 $n+1$，即编码表`HC`包括 $n+1$ 行。但因为每个字符编码的长度事先不能确定，所以不能预先为每个字符分配大小合适的存储空间。为了不浪费存储空间，动态分配一个长度为 $n$ 的一维数组`cd`，用来临时存放正在求解的第 $i(1\leqslant i\leqslant n)$ 个字符的编码，当第 $i$ 个字符的编码求解完毕后，根据数组`cd`的字符串长度分配`HC[i]`的空间，然后将数组`cd`中的编码复制到`HC[i]`中。

根据哈夫曼树求哈夫曼编码的主要思想是：依次以叶子为出发点，向上回溯至根结点为止，回溯时走左分支则生成代码 0，走右分支则生成代码 1。所以对于每个字符，得到的编码顺序是从右向左的，故将编码向数组`cd`存放的顺序也是从后向前的，即每个字符的第 1 个编码存放在`cd[n - 2]`中，第 2 个编码存放在`cd[n - 3]`中，以此类推，直到全部编码存放完毕。

> **算法 5.11**&nbsp;&nbsp;&nbsp;&nbsp;根据哈夫曼树求哈夫曼编码
>
> 1. 分配存储 $n$ 个字符编码的编码表空间`HC`，长度为 $n+1$；分配临时存储每个字符编码的动态数组空间`cd`，`cd[n - 1]`置为`'\0'`。
> 2. 逐个求解 $n$ 个字符的编码，循环 $n$ 次，执行以下操作：
>    （1）设置变量`start`用于记录编码在`cd`中存放的位置，`start`初始时指向编码结束符位置`n-1`。
>    （2）设置变量`c`用于记录从叶子结点向上回溯至根结点所经过的结点下标，`c`初始时为当前待编码字符的下标`i`。`f`用于记录`c`的双亲结点的下标。
>    （3）从叶子结点向上回溯至根结点，求得字符`i`的编码，当`f`没有到达根结点时，循环执行以下操作：
>    - `start`向前移动一个位置。
>    - 若结点`c`是`f`的左孩子，则生成代码 0，否则生成代码 1，生成的代码保存在`cd[start]`中。
>    - 继续向上回溯，改变`c`和`f`的值。
>
>    （4）根据数组`cd`的字符串长度，为第 $i$ 个字符编码分配空间`HC[i]`，然后将数组`cd`中的编码复制到`HC[i]`中。
> 3. 释放临时空间`cd`。

```C++{.line-numbers}
void CreateHuffmanCode(HuffmanTree HT, HuffmanCode &HC, int n)
{
    HC = new char*[n + 1]; // 分配存储 n 个字符编码的编码表空间
    char *cd = new char[n]; // 分配临时存放每个字符编码的动态数组空间
    cd[n - 1] = '\0'; // 编码结束符
    
    for (int i = 1; i <= n; i++)
    {
        int start = n - 1;
        int c = i; // c 指向当前待求编码的叶子结点
        int f = HT[i].parent; // f 指向 c 的双亲结点
        
        while (f != 0) // 从叶子结点开始向上回溯，直到根结点
        {
            start--;
            if (HT[f].lchild == c)
                cd[start] = '0'; // c 是 f 的左孩子，生成代码 0
            else
                cd[start] = '1'; // c 是 f 的右孩子，生成代码 1
            // 继续向上回溯
            c = f;
            f = HT[f].parent;
        }
        
        HC[i] = new char[n - start]; // 为第 i 个字符编码分配空间
        strcpy(HC[i], &cd[start]); // 将求得的编码从临时空间 cd 复制到 HC[i] 中
    }
    
    delete cd; // 释放临时空间
}
```

## 5.6 树和二叉树的应用

### 5.6.1 表达式求值

一般情况下，一个表达式由一个运算符和两个操作数构成，两个操作数之间有次序之分，并且操作数本身也可以是表达式。这个结构类似于二叉树，因此可以利用二叉树来表示表达式。

以二叉树表示表达式的递归定义如下：

1. 若表达式为数或简单变量，则相应二叉树中仅有一个根结点，其数据域存放该表达式信息。
2. 若表达式为“第一操作数 运算符 第二操作数”的形式，则相应的二叉树中以左子树表示第一操作数，右子树表示第二操作数，根结点的数据域存放运算符（若为一元运算符，则左子树为空），其中，操作数本身又为表达式。

假设运算符均为双目运算符，则表达式对应的表达式树中叶子结点均为操作数，分支结点均为运算符。由于创建的表达式树需要准确地表达运算次序，因此在扫描表达式的过程中，当遇到运算符时不能直接创建结点，而应将其与前面的运算符进行优先级比较，根据比较结果再进行处理。

根据表达式树与表达式对应关系的递归定义，每两个操作数和一个运算符就可以建立一棵表达式二叉树，而该二叉树又可以作为另一个运算符结点的一棵子树。可以另外借助一个表达式树栈，来暂存已建立好的表达式树的根结点，以便其作为另一个运算符结点的子树而被引用。

为实现表达式树的创建算法，可以使用两个工作栈，一个称做`OPTR`，用以暂存运算符；另一个称做`EXPT`，用以暂存已建立好的表达式树的根结点。为了便于实现，假设每个表达式均以“#”开始，以“#”结束。

> **算法 5.12**&nbsp;&nbsp;&nbsp;&nbsp;表达式树的创建
>
> 1. 初始化`OPTR`栈和`EXPT`栈，将表达式起始符 “#” 压入`OPTR`栈。
> 2. 扫描表达式，读入第一个字符`ch`，如果表达式没有扫描完毕至 “#” 或`OPTR`的栈顶元素不为 “#” 时，则循环执行以下操作：
>    - 若`ch`不是运算符，则以`ch`为根创建一棵只有根结点的二叉树，且将该树根结点压入`EXPT`栈，读入下一个字符`ch`。
>    - 若`ch`是运算符，则根据`OPTR`的栈顶元素和`ch`的优先级比较结果，做不同的处理：
>      - 若是`ch`优先级更高，则`ch`压入`OPTR`栈，读入下一字符`ch`。
>      - 若是栈顶元素优先级更高，则弹出`OPTR`栈顶的运算符，从`EXPT`栈弹出两个表达式子树的根结点。以该运算符为根结点，以`EXPT`栈中弹出的第二个子树作为左子树，以`EXPT`栈中弹出的第一个子树作为右子树，创建一棵新二叉树，并将该树根结点压入`EXPT`栈。
>      - 若是等于，则`OPTR`的栈顶元素是 “(” 且`ch`是 “)”，这时弹出`OPTR`栈顶的 “(”，相当于括号匹配成功，然后读入下一字符`ch`。

```C++{.line-numbers}
void InitExpTree()
{
    InitStack(EXPT); // 初始化 EXPT 栈
    InitStack(OPTR); // 初始化 OPTR 栈
    Push(OPTR, '#'); // 将表达式起始符 '#' 压入 OPTR 栈
    
    char ch;
    cin >> ch;
    while (ch != '#' || GetTop(OPTR) != '#')
    {
        if (!In(ch)) // ch 不是运算符
        {
            CreateExpTree(T, NULL, NULL, ch); // 以 ch 为根创建一棵只有根结点的二叉树
            Push(EXPT, T); // 将二叉树根结点 T 压入 EXPT 栈
            cin >> ch; // 读入下一字符
        }
        else // ch 是运算符
        {
            switch (Precede(GetTop(OPTR), ch)) // 比较 OPTR 的栈顶元素和 ch 的优先级
            {
                case '<':
                    Push(OPTR, ch); // 当前字符压入 OPTR 栈
                    cin >> ch; // 读入下一字符
                    break;
                case '>':
                    Pop(OPTR, theta); // 弹出 OPTR 栈顶的运算符
                    Pop(EXPT, b); // 弹出第二个运算数
                    Pop(EXPT, a); // 弹出第一个运算数
                    // 以 theta 为根，a 为左子树，b 为右子树，创建一棵二叉树
                    CreateExpTree(T, a, b, theta);
                    Push(EXPT, T); // 将二叉树根结点 T 压入 EXPT 栈
                    break;
                case '=':
                    Pop(OPTR, x);
                    cin >> ch; // 读入下一字符
                    break;
            }
        }
    }
}
```

此算法从头到尾扫描表达式中每个字符，若表达式的字符串长度为 $n$，则此算法的时间复杂度为 $O(n)$。算法在运行时所占用的辅助空间主要取决于`OPTR`栈和`EXPT`栈的大小，显然，它们的空间大小之和不会超过 $n$，所以此算法的空间复杂度也同样为 $O(n)$。

> **算法 5.13**&nbsp;&nbsp;&nbsp;&nbsp;表达式树的求值
>
> 1. 设变量`lvalue`和`rvalue`分别用以记录表达式树中左子树和右子树的值，初值均为 0。
> 2. 如果当前结点为叶子（结点为操作数），则返回该结点的数值，否则（结点为运算符）执行如下操作：
>    （1）递归计算左子树的值，保存到`lvalue`中。
>    （2）递归计算右子树的值，保存到`rvalue`中。
>    （3）根据当前结点运算符的类型， 将`lvalue`和`rvalue`进行相应运算并返回。

```C{.line-numbers}
int EvaluateExpTree(BiTree T)
{
    int lvalue = 0;
    int rvalue = 0;
    
    if (T->lchild == NULL && T->rchild == NULL) // 结点为操作数
    {
        return T->data - '0'; // 返回结点的数值
    }
    else // 结点为运算符
    {
        lvalue = EvaluateExpTree(T->lchild); // 递归计算左子树的值
        rvalue = EvaluateExpTree(T->rchild); // 递归计算右子树的值
        return GetValue(T->data, lvalue, rvalue);
    }
}
```

对表达式树进行求值的过程实际上是一个后序遍历二叉树的过程，因此时间和空间复杂度均为 $O(n)$。

### 5.6.2 并查集

#### 5.6.2.1 并查集的定义

并查集是一种树型数据结构，用于处理不相交集合（disjoint set）的维护和相关操作。

并查集维护了一组不相交集合，为查找元素所在的集合，要标识每个集合。可以选择集合中的某个元素代表整个集合，这个元素称为集合的代表元。

设`x`、`y`表示集合中的元素，并查集支持 3 种操作：

1. `MAKE_SET(x)`：建立一个新的集合，它的唯一元素是`x`。
2. `UNION(x, y)`：合并，将包含`x`和`y`的两个集合合并成一个新的集合。
3. `FIND(x)`：查找，返回`x`所在集合的代表元。

#### 5.6.2.2 并查集的实现

用树表示集合，每棵树代表一个集合，由树组成的森林代表并查集。树中的每个结点表示集合的一个元素，根结点为集合的代表元。

在每个结点中加入指向双亲结点的`parent`指针，则并查集的 3 种操作可以实现如下：

1. `MAKE_SET(x)`：为元素`x`生成一棵单结点树。
2. `UNION(x, y)`：将`x`所在树的根结点连接到`y`所在树的根结点上，或者将`y`所在树的根结点连接到`x`所在树的根结点上。
3. `FIND(x)`：从结点`x`开始，沿`parent`链向上访问，直到根结点为止。

为了实现简便，用数组实现`parent`链接结构，数组下标为结点编号，数组元素为该结点的双亲结点的编号。由此，并查集实现如下。

> **算法 5.14**&nbsp;&nbsp;&nbsp;&nbsp;并查集

```C{.line-numbers}
#define MAXSIZE 100

int Parent[MAXSIZE];

void MakeSet(int x)
{
    Parent[x] = x; // x 的双亲是其自身
}

int Find(int x)
{
    if (Parent[x] == x)
    {
        return x;
    }
    else
    {
        return Find(Parent[x]);
    }
}

void Union(int x, int y)
{
    Parent[Find(y)] = Find(x); // 将 y 所在树的根结点连接到 x 所在树的根结点上
}
```

设 $n$ 表示 MAKE_SET 操作的次数，即并查集的元素总数，$u$ 表示 UNION 操作的次数，$f$ 表示 FIND 操作的次数，$m$ 表示 MAKE_SET、UNION 和 FIND 操作的总次数，则 $m=n+u+f$。

因为各个集合是不相交的，每个有效的 UNION 操作减少一个集合，因此经过 $n-1$ 次 UNION 操作后，并查集中只剩下 1 个集合，则 $u\leqslant n-1$。反之，经过 $u$ 次 UNION 操作，可能得到的最大集合包含 $u+1$ 个元素。

由于 UNION 操作是对集合的代表元进行的，每次 UNION 操作之前至少有一个 FIND 操作，因此 $f\geqslant u$。

反复进行 UNION 操作可能会产生退化树，使得树结构退化为单链表。退化树的出现可能会增加 FIND 操作的时间，导致 FIND 操作和 UNION 操作的最坏时间复杂度均为 $O(n)$。

#### 5.6.2.3 并查集的优化

1. **按秩合并**

对每个结点维护一个秩（rank），表示以该结点为根的子树高度的一个上界。按秩合并策略让具有较小秩的根指向具有较大秩的根，从而使合并后树的高度不会增加。

秩的具体操作规则如下：

- MAKE_SET 操作：每个结点的秩初始化为 0。
- UNION 操作：设`x`和`y`所在树的根分别为`fx`和`fy`。
  - 如果`fx.rank == fy.rank`，则让`fy`指向`fx`，`fx.rank`增 1。
  - 如果`fx.rank != fy.rank`，则让秩较小的根指向秩较大的根，秩不变。

**定理 5.2**&nbsp;&nbsp;&nbsp;&nbsp;设 $F$ 是从初始并查集经过 $u$ 次 UNION 操作形成的森林，UNION 操作使用了按秩合并规则，则 $F$ 中任一结点的秩最多为 $\lfloor\log_2(u+1)\rfloor$。

> **证明：** 对 $u$ 使用数学归纳法。
>
> $u=1$ 时，$F$ 最多生成一棵新树，新树的根的秩为 1，其他结点的秩都为 0，定理成立。
>
> 假设定理对于所有的 $u<k\,(k>1)$ 都成立。
>
> 当 $u=k$ 时，考虑最后一次调用 UNION 操作的情况。设最后一次调用为`UNION(x, y)`，`x`所在树由 $p$ 次 UNION 操作形成，根为`fx`；`y`所在树由 $q$ 次 UNION 操作形成，根为`fy`。显然，$p+q\leqslant k-1$。
>
> 如果`fx.rank != fy.rank`，则`fx`和`fy`的秩都不变，根据假设，`fx`和`fy`的秩最多为 $\lfloor\log_2(k-1+1)\rfloor$，即 $\lfloor\log_2 k\rfloor<\lfloor\log_2(k+1)\rfloor$。
>
> 如果`fx.rank == fy.rank`，由于 $p$ 和 $q$ 至少有一个不超过 $\Big\lfloor\dfrac{k-1}{2}\Big\rfloor$，不妨设 $p\leqslant q$，则 $p\leqslant\Big\lfloor\dfrac{k-1}{2}\Big\rfloor$，根据假设，$\operatorname{rank}(f_x)=\operatorname{rank}(f_y)\leqslant\Big\lfloor\log_2\Big(\Big\lfloor\dfrac{k-1}{2}\Big\rfloor+1\Big)\Big\rfloor$，因此
>
> $$
> \begin{aligned}
>     \operatorname{rank}(f_x)+1 &\leqslant\Big\lfloor\log_2\Big(\Big\lfloor\dfrac{k-1}{2}\Big\rfloor+1\Big)\Big\rfloor+1\\
>     &=\Big\lfloor\log_2\Big(\Big\lfloor\dfrac{k-1}{2}\Big\rfloor+1\Big)+1\Big\rfloor\\
>     &=\Big\lfloor\log_2\Big(\Big\lfloor\dfrac{k-1}{2}\Big\rfloor\times 2+2\Big)\Big\rfloor\\
>     &\leqslant\lfloor\log_2(k-1+2)\rfloor\\
>     &=\lfloor\log_2(k+1)\rfloor
> \end{aligned}
> $$

由于 $u\leqslant n-1$，可得如下定理。

**定理 5.3**&nbsp;&nbsp;&nbsp;&nbsp;设 $F$ 是从初始并查集经过若干次 UNION 操作形成的森林，UNION 操作使用了按秩合并规则，则 $F$ 中任一结点的秩最多为 $\lfloor\log_2 n\rfloor$。

由定理 5.3 可知，使用按秩合并规则，并查集森林中的树的最大高度为 $\lfloor\log_2 n\rfloor$。因此，改进后的并查集的 UNION 和 FIND 操作的最坏时间复杂度均为 $O(\log_2 n)$。

2. **路径压缩**

在 FIND 操作中，找到元素`x`所在树的根`fx`后，将`x`到根`fx`路径上的所有结点的双亲都改成`fx`，这种策略称为路径压缩。

路径压缩不改变任何结点的秩。

路径压缩虽然增加了一次 FIND 操作的时间，但是它可能导致树的高度变小，提高后续的 UNION/FIND 操作的效率，从而提高整个 UNION/FIND 操作序列的效率。

结论：对于一个具有 $n$ 次 MAKE_SET 操作、$u$ 次 UNION 操作和 $f$ 次 FIND 操作的操作序列，单独使用路径压缩的最坏时间复杂度为 $O(n+f(1+\log_{2+\frac{f}{n}}n))$。

因此，使用路径压缩策略，虽然一次 UNION/FIND 操作的最坏时间复杂度仍为 $O(n)$，但是均摊到整个操作序列上，每个操作的最坏时间复杂度相当于 $O(\log n)$。

3. **算法优化**

同时使用按秩合并和路径压缩两种优化策略。并查集继续使用树的双亲数组表示，集合中的每个元素使用 1~n 的编号表示。

由于只有根结点的秩在合并时起作用，因此每个结点没有真正包含`rank`域，而是巧妙地利用了`parent`域保存结点的秩，规则如下：

- 如果`x`是根结点，`Parent[x]`保存结点`x`的秩的相反数。
- 如果`x`不是根结点，`Parent[x]`保存结点`x`的双亲结点的编号。

优化后的算法实现如下。

> **算法 5.15**&nbsp;&nbsp;&nbsp;&nbsp;优化后的并查集

```C{.line-numbers}
#define MAXSIZE 100

int Parent[MAXSIZE];

void MakeSet(int x)
{
    Parent[x] = 0; // 初始时，每棵树都是只有一个根结点的树，保存秩即可
}

int Find(int x)
{
    if (Parent[x] <= 0) // 是根结点，直接返回
    {
        return x;
    }
    
    int fx = Find(Parent[x]); // 查找根结点
    Parent[x] = fx; // 路径压缩
    return fx;
}

void Union(int x, int y)
{
    // 分别取 x 和 y 所在树的根
    int fx = Find(x);
    int fy = Find(y);

    // x 和 y 在同一棵树上，直接返回
    if (fx == fy)
        return;

    // 按秩合并
    if (Parent[fx] < Parent[fy]) // fx 更高，将 fy 接在 fx 上
    {
        Parent[fy] = fx;
    }
    else
    {
        if (Parent[fx] == Parent[fy]) // 两棵树一样高，fy 的秩加 1
        {
            Parent[fy]--; // 根结点保存的是秩的相反数，所以要减 1
        }
        Parent[fx] = fy; // 将 fx 接在 fy 上
    }
}
```

**定理 5.4**&nbsp;&nbsp;&nbsp;&nbsp;一组 $m$ 个 MAKE_SET、UNION 和 FIND 操作的序列，其中 $n$ 个是 MAKE_SET 操作，在并查集上使用按秩合并和路径压缩，最坏时间复杂度为 $O(m\alpha(n))$。其中 $\alpha(x)$ 是 Ackerman 函数的反函数。

$\alpha(x)$ 增长得非常缓慢，对所有在实际问题中有意义的 $x$，$\alpha(x)\leqslant 4$，因此可以把它看成常数。定理 5.4 表明，同时使用按秩合并和路径压缩两种优化策略，均摊到整个操作序列上，每个操作的最坏时间复杂度相当于 $\alpha(n)$，近似为常数。

#### 5.6.2.4 等价类

集合 $S$ 上的一个关系 $\sim$ 称为等价关系，当且仅当对于 $S$ 中的任何元素 $x,y,z$ 满足下列三个性质：

1. 反身性：$x\sim x$。
2. 对称性：若 $x\sim y$，则 $y\sim x$。
3. 传递性：若 $x\sim y$，且 $y\sim z$，则 $x\sim z$。

等价性问题：给定集合 $S$ 及其上的若干等价元素对，询问 $S$ 上的两个元素是否等价。

元素 $x$ 的等价类定义为 $S$ 中等价于 $x$ 的所有元素的集合，即 $\{y\,|\,x\sim y,\,x\in S,\,y\in S\}$。

$S$ 上的任一等价关系都可将 $S$ 划分成若干个等价类。设集合 $S$ 划分成 $k\,(k\geqslant 1)$ 个等价类 $S_1,S_2,\cdots,S_k$，则

1. $S_1\cup S_2\cup\cdots\cup S_k=S$
2. $S_i\cap S_j=\text{\O}\,(1\leqslant i,j\leqslant k,\,i\not=j)$
3. $S_i$ 中的任意两个元素都有等价关系，$S_i$ 中的任意元素和 $S_j$ 中的任意元素没有等价关系（$1\leqslant i,j\leqslant k,\,i\not=j$）。

等价性问题的关键在于等价类的维护。等价类的维护是并查集的一个简单应用。初始时，每个元素生成一个集合，形成若干不相交的集合；如果输入一对等价元素，就合并两个元素所在的集合；如果询问两个元素是否等价，就查找两个元素所在的集合是否相同。

设集合 $S$ 的元素个数为 $n$，$S$ 中的元素用编号 1~n 表示。算法首先输入元素个数 $n$、等价对数 $m$、询问数 $q$，然后输入 $m$ 个具体等价对和 $q$ 个具体询问。算法的输出是 $q$ 个询问的结果，如果等价，则输出 "yes."，否则输出 "no."。

> **算法 5.16**&nbsp;&nbsp;&nbsp;&nbsp;用并查集解决等价性问题

```C++{.line-numbers}
void EP()
{
    // 初始化
    cin >> n >> m >> p;
    for (int i = 1; i <= n; i++)
    {
        MakeSet(i);
    }

    // 处理等价关系
    for (int i = 0; i < m; i++)
    {
        cin >> x >> y; // 输入一个等价对
        Union(x, y); // 合并 x、y 所在的集合
    }

    // 处理查询
    for (int i = 0; i < q; i++)
    {
        cin >> x >> y; // 输入一个查询
        if (Find(x) == Find(y))
        {
            cout << "yes." << endl;
        }
        else
        {
            cout << "no." << endl;
        }
    }
}
```

# 第6章 图

## 6.1 图的定义和基本术语

### 6.1.1 图的定义

**图**（Graph）由两个集合 $V$ 和 $E$ 组成，记为 $G=(V,E)$，其中 $V$ 是顶点的有穷非空集合，$E$ 是 $V$ 中顶点偶对的有穷集合，这些顶点偶对称为**边**。$V(G)$ 和 $E(G)$ 通常分别表示图 $G$ 的顶点集合和边集合。$E(G)$ 可以为空集，若 $E(G)$ 为空，则图 $G$ 只有顶点而没有边。

对于图 $G$，若边集 $E(G)$ 为有向边的集合，则称该图为有向图；若边集 $E(G)$ 为无向边的集合，则称该图为无向图。

在有向图中，顶点对 $\text{<}x,y\text{>}$ 是有序的，顶点对用一对尖括号括起来，它称为从顶点 $x$ 到顶点 $y$ 的一条**有向边**，$x$ 是有向边的始点，$y$ 是有向边的终点。因此，$\text{<}x,y\text{>}$ 与 $\text{<}y,x\text{>}$ 是不同的两条边。$\text{<}x,y\text{>}$ 也称作一条**弧**，则 $x$ 为弧尾，$y$ 为弧头。

在无向图中，顶点对 $(x,y)$ 是无序的，它称为与顶点 $x$ 和顶点 $y$ 相关联的一条边。这条边没有特定的方向，$(x,y)$ 与 $(y,x)$ 是同一条边。为了有别于有向边，无向边的顶点用一对圆括号括起来。

### 6.1.2 图的基本术语

用 $n$ 表示图中顶点数目，用 $e$ 表示边的数目。

假设有两个图 $G=(V,E)$ 和 $G'=(V',E')$，如果 $V'\subseteq V$ 且 $E'\subseteq E$，则称 $G'$ 为 $G$ 的**子图**。

对于无向图，若具有 $\dfrac{n(n-1)}{2}$ 条边，则称为**无向完全图**。

对于有向图，若具有 $n(n-1)$ 条弧，则称为**有向完全图**。

有很少条边或弧（如 $e<n\log_2n$）的图称为**稀疏图**，反之称为**稠密图**。

在实际应用中，每条边可以标上具有某种含义的数值，该数值称为该边上的**权**。带权的图通常称为**网**。

对于无向图 $G$，如果图的边 $(v,v')\in E$，则称顶点 $v$ 和 $v'$ 互为**邻接点**，即 $v$ 和 $v'$ **相邻接**。边 $(v,v')$ **依附于**顶点 $v$ 和 $v'$，或者说边 $(v,v')$ 与顶点 $v$ 和 $v'$ **相关联**。

顶点 $v$ 的**度**是指和 $v$ 相关联的边的数目，记为 $\operatorname{TD}(v)$。对于有向图，顶点 $v$ 的度分为入度和出度。**入度**是以顶点 $v$ 为头的弧的数目，记为 $\operatorname{ID}(v)$；**出度**是以顶点 $v$ 为尾的弧的数目，记为 $\operatorname{OD}(v)$。顶点 $v$ 的度为 $\operatorname{TD}(v)=\operatorname{ID}(v)+\operatorname{OD}(v)$。

一般地，如果顶点 $v_i$ 的度记为 $\operatorname{TD}(v_i)$，那么一个有 $n$ 个顶点、$e$ 条边的图，满足如下关系：

$$
e=\dfrac{1}{2}\sum_{i=1}^n \operatorname{TD}(v_i)
$$

在无向图 $G$ 中，从顶点 $v$ 到顶点 $v'$ 的**路径**是一个顶点序列 $(v=v_{i,0},v_{i,1},\cdots,v_{i,m}=v')$，其中 $(v_{i,j-1},v_{i,j})\in E,1\leqslant j\leqslant m$。如果 $G$ 是有向图，则路径也是有向的，顶点序列应满足 $\text{<}v_{i,j-1},v_{i,j}\text{>}\in E,1\leqslant j\leqslant m$。

**路径长度**是一条路径上经过的边或弧的数目。

第一个顶点和最后一个顶点相同的路径称为**回路**或**环**。

序列中顶点不重复出现的路径称为**简单路径**。除了第一个顶点和最后一个顶点之外，其余顶点不重复出现的回路，称为**简单回路**或**简单环**。

在无向图 $G$ 中，如果从顶点 $v$ 到顶点 $v'$ 有路径，则称 $v$ 和 $v'$ 是**连通**的。如果对于图中任意两个顶点 $v_i,v_j\in V$，$v_i$ 和 $v_j$ 都是连通的，则称 $G$ 是**连通图**。**连通分量**是指无向图中的极大连通子图。

在有向图 $G$ 中，如果对于每一对顶点 $v_i,v_j\in V$，从 $v_i$ 到 $v_j$ 和从 $v_j$ 到 $v_i$ 都存在路径，则称 $G$ 是**强连通图**。有向图中的极大强连通子图称作有向图的**强连通分量**。

一个极小连通子图，它含有图中全部顶点，但只有足以构成一棵树的 $n-1$ 条边，这样的连通子图称为连通图的**生成树**。

一棵有 $n$ 个顶点的生成树有且仅有 $n-1$ 条边。如果一个图有 $n$ 个顶点和小于 $n-1$ 条边，则是非连通图；如果它多于 $n-1$ 条边，则一定有环。但是，有 $n-1$ 条边的图不一定是生成树。

有一个顶点的入度为 0，其余顶点的读入均为 1 的有向图称为**有向树**。一个有向图的**生成森林**是由若干棵有向树组成，含有图中全部顶点，但只有足以构成若干棵不相交的有向树的弧。

## 6.2 图的类型定义

$$
\begin{aligned}
    & \texttt{ADT Graph \{}\\
    & \quad\texttt{数据对象：}V\,\texttt{是具有相同特性的数据元素的集合，称为顶点集}\\
    & \quad\texttt{数据关系：}\\
    & \qquad R=\{VR\}\\
    & \qquad VR=\{\text{<}v,w\text{>}|\,v,w\in V\,且\,P(v,w)\}\\
    & \qquad\texttt{其中\,$\textrm{<}v,w\textrm{>}$\,表示从\,$v$\,到\,$w$\,的弧，谓词\,$P(v,w)\,$定义了弧\,$\textrm{<}v,w\textrm{>}$\,的意义或信息}\\
    & \quad\texttt{基本操作：}\\
    & \qquad\texttt{CreateGraph(\&G,V,VR)}\\
    & \qquad\quad\texttt{初始条件：V\,是图的顶点集，VR\,是图中弧的集合}\\
    & \qquad\quad\texttt{操作结果：按\,V\,和\,VR\,的定义构造图\,G}\\
    & \qquad \texttt{DestroyGraph(\&G)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在}\\
    & \qquad\quad\texttt{操作结果：销毁图\,G}\\
    & \qquad \texttt{LocateVex(G,u)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，u\,和\,G\,中顶点有相同特征}\\
    & \qquad\quad\texttt{操作结果：若\,G\,中存在顶点\,u，则返回该顶点在图中的位置，否则返回其他信息}\\
    & \qquad\texttt{GetVex(G,v)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,是\,G\,中某个顶点}\\
    & \qquad\quad\texttt{操作结果：返回\,v\,的值}\\
    & \qquad\texttt{PutVex(\&G,v,value)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,是\,G\,中某个顶点}\\
    & \qquad\quad\texttt{操作结果：对\,v\,赋值\,value}\\
    & \qquad\texttt{FirstAdjVex(G,v)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,是\,G\,中某个顶点}\\
    & \qquad\quad\texttt{操作结果：返回\,v\,的第一个邻接顶点。}\\
    & \qquad\qquad\qquad\qquad\texttt{若\,v\,在\,G\,中没有邻接顶点，则返回\,null}\\
    & \qquad\texttt{NextAdjVex(G,v,w)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,是\,G\,中某个顶点，w\,是\,v\,的邻接顶点}\\
    & \qquad\quad\texttt{操作结果：返回\,v\,的相对于\,w\,的下一个邻接顶点。}\\
    & \qquad\qquad\qquad\qquad\texttt{若\,w\,是\,v\,的最后一个邻接顶点，则返回\,null}\\
    & \qquad\texttt{InsertVex(\&G,v)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,和\,G\,中顶点有相同特征}\\
    & \qquad\quad\texttt{操作结果：在图\,G\,中添加新顶点\,v}\\
    & \qquad\texttt{DeleteVex(\&G,v)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,是\,G\,中某个顶点}\\
    & \qquad\quad\texttt{操作结果：删除\,G\,中顶点\,v\,及其相关的弧}\\
    & \qquad\texttt{InsertArc(\&G,v,w)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,和\,w\,是\,G\,中两个顶点}\\
    & \qquad\quad\texttt{操作结果：在\,G\,中添加弧\,<v,w>。若\,G\,是无向图，则还添加对称弧\,<w,v>}\\
    & \qquad\texttt{DeleteArc(\&G,v,w)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在，v\,和\,w\,是\,G\,中两个顶点}\\
    & \qquad\quad\texttt{操作结果：在\,G\,中删除弧\,<v,w>。若\,G\,是无向图，则还删除对称弧\,<w,v>}\\
    & \qquad\texttt{DFSTraverse(G)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在}\\
    & \qquad\quad\texttt{操作结果：对图进行深度优先遍历，在遍历过程中对每个顶点访问一次}\\
    & \qquad\texttt{BFSTraverse(G)}\\
    & \qquad\quad\texttt{初始条件：图\,G\,存在}\\
    & \qquad\quad\texttt{操作结果：对图进行广度优先遍历，在遍历过程中对每个顶点访问一次}\\
    & \texttt{\} ADT Graph}
\end{aligned}
$$

## 6.3 图的存储结构

### 6.3.1 邻接矩阵

**邻接矩阵**（Adjacency Matrix）是表示顶点之间相邻关系的矩阵。设 $G(V,E)$ 是具有 $n$ 个顶点的图，则 $G$ 的邻接矩阵是具有如下性质的 $n$ 阶方阵。

$$
a_{ij}=\begin{cases}
    1 & 若\text{<}v_i,v_j\text{>}\in E\,或\,(v_i,v_j)\in E\\
    0 & 反之
\end{cases}
$$

若 $G$ 是网，则邻接矩阵可以定义为

$$
a_{ij}=\begin{cases}
    w_{i,j} & 若\text{<}v_i,v_j\text{>}\in E\,或\,(v_i,v_j)\in E\\
    \infty & 反之
\end{cases}
$$

其中，$w_{i,j}$ 表示边上的权值，$\infty$ 表示计算机允许的、大于所有边上权值的数。

用邻接矩阵表示法表示图，除了一个用于存储邻接矩阵的二维数组外，还需要用一个一维数组来存储顶点信息。其形式说明如下：

```C{.line-numbers}
// 图的邻接矩阵存储表示
#define MaxInt 32767 // 表示极大值
#define MVNum 100 // 最大顶点数

typedef char VerTexType; // 假设顶点的数据类型为字符型
typedef int ArcType; // 假设边的权值类型为整型

typedef struct
{
    VerTexType vexs[MVNum]; // 顶点表
    ArcType arcs[MVNum][MVNum]; // 邻接矩阵
    int vexnum; // 顶点数
    int arcnum; // 边数
} AMGraph;
```

> **算法 6.1**&nbsp;&nbsp;&nbsp;&nbsp;采用邻接矩阵表示法创建无向网
>
> 1. 输入总顶点数和总边数。
> 2. 依次输入点的信息存入顶点表中。
> 3. 初始化邻接矩阵，使每个权值初始化为极大值。
> 4. 构造邻接矩阵。依次输入每条边依附的顶点及其权值，确定两个顶点在图中的位置之后，为相应边赋予相应的权值，同时为其对称边赋予相同的权值。

```C++{.line-numbers}
Status CreateUDN(AMGraph &G)
{
    cin >> G.vexnum >> G.arcnum; // 输入总顶点数和总边数
    for (int i = 0; i < G.vexnum; i++)
    {
        cin >> G.vexs[i]; // 依次输入点的信息
    }
    
    for (int i = 0; i < G.vexnum; i++)
    {
        for (int j = 0; j < G.vexnum; j++)
        {
            G.arcs[i][j] = MaxInt; // 初始化邻接矩阵
        }
    }
    
    for (int k = 0; k < G.arcnum; k++) // 构造邻接矩阵
    {
        // 输入一条边依附的顶点及权值
        cin >> v1 >> v2 >> w;
        // 确定 v1 和 v2 在 G 中的位置
        int i = LocateVex(G, v1);
        int j = LocateVex(G, v2);
        // 设置边的权值
        G.arcs[i][j] = w;
        // 设置对称边的权值
        G.arcs[j][i] = G.arcs[i][j];
    }
    return OK;
}
```

该算法的时间复杂度是 $O(n^2)$。

若要建立无向图，只需对上述算法做两处小的改动：一是初始化邻接矩阵时，将边的权值均初始化为 0；二是构造邻接矩阵时，将权值 $w$ 改为常量值 1 即可。

邻接矩阵表示法的优点：

1. 便于判断两个顶点之间是否有边。
2. 便于计算各个顶点的度。对于无向图，邻接矩阵第 $i$ 行元素之和就是顶点 $i$ 的度；对于有向图，第 $i$ 行元素之和就是顶点 $i$ 的出度，第 $i$ 列元素之和就是顶点 $i$ 的入度。

缺点：

1. 不便于增加和删除顶点。
2. 不便于统计边的数目，需要扫描邻接矩阵所有元素才能统计完毕，时间复杂度为 $O(n^2)$。
3. 空间复杂度高。如果是有向图，$n$ 个顶点需要 $n^2$ 个单元存储边。如果是无向图，因其邻接矩阵是对称的，所以对规模较大的邻接矩阵可以采用压缩存储的方法，仅存储下三角（或上三角）的元素，这样需要 $\dfrac{n(n-1)}{2}$ 个单元即可。但无论以何种方式存储，邻接矩阵表示法的空间复杂度均为 $O(n^2)$，这对于稀疏图而言尤其浪费空间。

### 6.3.2 邻接表

**邻接表**（Adjacency List）是图的一种链式存储结构。在邻接表中，对图中每个顶点 $v_i$ 建立一个单链表，把与 $v_i$ 相邻接的顶点放在这个链表中。邻接表中每个单链表的第一个结点存放有关顶点的信息，把这一结点看成链表的表头，其余结点存放有关边的信息，这样邻接表便由两部分组成：表头结点表和边表。

表头结点表：由所有表头结点以顺序结构的形式存储，以便可以随机访问任一顶点的链表。表头结点包括数据域和链域两部分，其中，数据域用于存储顶点 $v_i$ 的名称或其他有关信息，链域用于指向链表中第一个结点（即与顶点 $v_i$ 邻接的第一个顶点）。

边表：由表示图中顶点间关系的 $2n$ 个边链表组成。边链表中边结点包括邻接点域、数据域和链域三部分。其中，邻接点域指示与顶点 $v_i$ 邻接的点在图中的位置；数据域存储和边相关的信息，如权值等；链域指示与顶点 $v_i$ 邻接的下一条边的结点。

在无向图的邻接表中，第 $i$ 个链表中的结点数恰为顶点 $v_i$ 的度；而在有向图中，第 $i$ 个链表中的结点个数指示顶点 $v_i$ 的出度，为求入度必须遍历整个邻接表，在所有链表中，其邻接点域的值为 $i$ 的结点的个数是顶点 $v_i$ 的入度。

为了便于确定顶点的入度，可以建立一个有向图的逆邻接表，即对每个顶点 $v_i$ 建立一个链接所有进入 $v_i$ 的边的表。

```C{.line-numbers}
// 图的邻接表存储表示
#define MVNum 100 // 最大顶点数

// 边结点
typedef struct ArcNode
{
    int adjvex; // 该边所指向的顶点的位置
    OtherInfo info; // 和边相关的信息
    struct ArcNode *nextarc; // 指向下一条边的指针
} ArcNode;

// 顶点信息
typedef struct VNode
{
    VerTexType data;
    ArcNode *firstarc; // 指向第一条依附该顶点的边的指针
} VNode, AdjList[MVNum];

// 邻接表
typedef struct
{
    AdjList vertices;
    int vexnum; // 顶点数
    int arcnum; // 边数
} ALGraph;
```

> **算法 6.2**&nbsp;&nbsp;&nbsp;&nbsp;采用邻接表表示法创建无向图
>
> 1. 输入总顶点数和总边数。
> 2. 依次输入点的信息存入顶点表中，使每个表头结点的指针域初始化为`NULL`。
> 3. 创建邻接表。依次输入每条边依附的两个顶点，确定这两个顶点的序号 $i$ 和 $j$ 后，将此边结点分别插入 $v_i$ 和 $v_j$ 对应的两个边链表的头部。

```C++{.line-numbers}
Status CreateUDG(ALGraph &G)
{
    cin >> G.vexnum >> G.arcnum; // 输入总顶点数和总边数
    
    for (int i = 0; i < G.vexnum; i++) // 输入各点，构造表头结点表
    {
        cin >> G.vertices[i].data; // 输入顶点值
        G.vertices[i].firstarc = NULL; // 初始化表头结点的指针域为 NULL
    }
    
    for (int k = 0; k < G.arcnum; k++) // 输入各边，构造邻接表
    {
        // 输入一条边依附的两个顶点
        cin >> v1 >> v2;
        // 确定 v1 和 v2 在 G 中的位置
        int i = LocateVex(G, v1);
        int j = LocateVex(G, v2);
        // 生成一个新的边结点
        ArcNode *p1 = new ArcNode;
        p1->adjvex = j;
        // 将新结点插入顶点 vi 的边表头部
        p1->nextarc = G.vertices[i].firstarc;
        G.vertices[i].firstarc = p1;
        // 生成对称的边结点
        ArcNode *p2 = new ArcNode;
        p2->adjvex = i;
        // 将对称结点插入顶点 vj 的边表头部
        p2->nextarc = G.vertices[j].firstarc;
        G.vertices[j].firstarc = p2;
    }
    return OK;
}
```

该算法的时间复杂度是 $O(n+e)$。

建立有向图的邻接表于此类似，只是更加简单，每读入一个顶点对序号 $\text{<}i,j\text{>}$，仅需生成一个邻接点序号为 $j$ 的边表结点，并将其插入到 $v_i$ 的边链表头部即可。若要创建网的邻接表，可以将边的权值存储在`info`域中。

注意：一个图的邻接矩阵表示是唯一的，但其邻接表表示不唯一。这是因为邻接表表示中，各边表结点的链接次序取决于建立邻接表的算法，以及边的输入次序。

邻接表表示法的优点：

1. 便于增加和删除顶点。
2. 便于统计边的数目。按顶点表顺序扫描所有边表可得到边的数目，时间复杂度为 $O(n+e)$。
3. 空间效率高。对于一个具有 $n$ 个顶点 $e$ 条边的图 $G$，若 $G$ 是无向图，则在其邻接表表示中有 $n$ 个顶点表结点和 $2e$ 个边表结点；若 $G$ 是有向图，则在其邻接表表示或逆邻接表表示中均有 $n$ 个顶点表结点和 $e$ 个边表结点。因此，邻接表或逆邻接表表示的空间复杂度为 $O(n+e)$，适合表示稀疏图。对于稠密图，考虑到邻接表中要附加链域，因此常采用邻接矩阵表示法。

缺点：

1. 不便于判断顶点之间是否有边。要判定 $v_i$ 和 $v_j$ 之间是否有边，就需要扫描第 $i$ 个边表，最坏情况下要耗费 $O(n)$ 时间。
2. 不便于计算有向图各个顶点的度。对于无向图，在邻接表表示中顶点 $v_i$ 的度是第 $i$ 个边表中的结点个数。在有向图的邻接表中，第 $i$ 个边表上的结点个数是顶点 $v_i$ 的出度，但求 $v_i$ 的入度较困难，需遍历各顶点的边表。若有向图采用逆邻接表表示，则与邻接表表示相反，求顶点的入度容易，而求顶点的出度较难。

邻接矩阵和邻接表的比较如下表所示。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5%E5%92%8C%E9%82%BB%E6%8E%A5%E8%A1%A8%E7%9A%84%E6%AF%94%E8%BE%83.png">
</div>

### 6.3.3 十字链表

**十字链表**（Orthogonal List）是有向图的另一种链式存储结构，可以看成是将有向图的邻接表和逆邻接表结合起来得到的一种链表。在十字链表中，对应于有向图中每一条弧有一个结点，对应于每个顶点也有一个结点，结点结构如图 6.1 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/数据结构/图6.1-十字链表的结点结构.png">
    <br>
    图 6.1&nbsp;&nbsp;&nbsp;&nbsp;十字链表的结点结构
</div>

在弧结点中有 5 个域：尾域（`tailvax`）指示弧尾顶点，头域（`headvex`）指示弧头顶点，`hlink`指向弧头相同的下一条弧，`tlink`指向弧尾相同的下一条弧，`info`域指向该弧的相关信息。弧头相同的弧在同一链表上，弧尾相同的弧也在同一链表上，它们的头结点即为顶点结点。

顶点结点由 3 个域组成：`data`域存储与顶点相关的信息，如顶点的名称等；`firstin`和`firstout`为两个指针域，分别指向以该顶点为弧头或弧尾的第一个弧结点。

十字链表示例如图 6.2 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/数据结构/图6.2-有向图的十字链表.png">
    <br>
    图 6.2&nbsp;&nbsp;&nbsp;&nbsp;有向图的十字链表
</div>

有向图的十字链表存储表示的形式说明如下所示：

```C{.line-numbers}
#define MAX_VERTEX_NUM 20

// 弧结点
typedef struct ArcBox
{
    int tailvex; // 弧尾顶点
    int headvex; // 弧头顶点
    struct ArcBox *hlink; // 弧头相同的弧的链域
    struct ArcBox *tlink; // 弧尾相同的弧的链域
    InfoType *info; // 弧的相关信息
} ArcBox;

// 顶点结点
typedef struct VexNode
{
    VertexType data; // 顶点信息
    ArcBox *firstin; // 第一条入弧
    ArcBox *firstout; // 第一条出弧
} VexNode;

// 十字链表
typedef struct
{
    VexNode xlist[MAX_VERTEX_NUM]; // 顶点数组
    int vexnum; // 顶点数
    int arcnum; // 弧数
} OLGraph;
```

只要输入 $n$ 个顶点和 $e$ 条弧的信息，便可建立该有向图的十字链表，建立十字链表的时间复杂度与建立邻接链表相同，为 $O(n+e)$。

在十字链表中既容易找到以 $v_i$ 为尾的弧，也容易找到以 $v_i$ 为头的弧，因而容易求得顶点的入度和出度。

### 6.3.4 邻接多重表

**邻接多重表**（Adjacency Multilist）是无向图的另一种链式存储结构。邻接多重表的结构与十字链表类似，如图 6.3 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/数据结构/图6.3-邻接多重表的结点结构.png">
    <br>
    图 6.3&nbsp;&nbsp;&nbsp;&nbsp;邻接多重表的结点结构
</div>

在邻接多重表中，每条边用一个结点表示，边结点由如图 6.3(a) 所示的 6 个域组成。其中，`mark`为标志域，可以用来标记该条边是否被搜索过；`ivex`和`jvex`为该边依附的两个顶点；`ilink`指向下一条依附于顶点`ivex`的边；`jlink`指向下一条依附于顶点`jvex`的边；`info`为指向和边相关的各种信息的指针域。

每个顶点也用一个结点表示，它由如图 6.3(b) 所示的 2 个域组成。其中，`data`域存储顶点信息，`firstedge`域指向第一条依附于该顶点的边。

在邻接多重表中，所有依附于同一顶点的边串联在同一链表中，由于每条边依附于两个顶点，则每个边结点同时链接在两个链表中。

对无向图而言，其邻接多重表和邻接表的差别，仅仅在于同一条边在邻接表中用两个结点表示，而在邻接多重表中只有一个结点。

邻接多重表的类型说明如下：

```C{.line-numbers}
#define MAX_VERTEX_NUM 20

typedef enum
{
    unvisited,
    visited
} VisitIf;

// 边结点
typedef struct EBox
{
    VisitIf mark; // 访问标记
    int ivex;
    int jvex;
    struct EBox *ilink;
    struct EBox *jlink;
    InfoType *info; // 边信息指针
} EBox;

// 顶点结点
typedef struct VexBox
{
    VertexType data; // 顶点信息
    EBox *firstedge; // 指向第一条依附该顶点的边
} VexBox;

// 邻接多重表
typedef struct
{
    VexBox adjmulist[MAX_VERTEX_NUM]; // 顶点数组
    int vaxnum; // 顶点数
    int edgenum; // 边数
} AMLGraph;
```

## 6.4 图的遍历

### 6.4.1 深度优先搜索

深度优先搜索（Depth First Search，DFS）类似于树的先序遍历，是树的先序遍历的推广。

对于一个连通图，深度优先搜索的过程如下：

1. 从图中某个顶点 $v$ 出发，访问 $v$。
2. 找出刚访问过的顶点的第一个未被访问的邻接点，访问该顶点。以该顶点为新顶点，重复此步骤，直至刚访问过的顶点没有未被访问的邻接点为止。
3. 返回前一个访问过的且仍有为被访问的邻接点的顶点，找出该顶点的下一个未被访问的邻接点，访问该顶点。
4. 重复步骤 2 和 3，直至图中所有顶点都被访问过，搜索结束。

将深度优先搜索的访问和回溯过程表示成一棵树，称为**深度优先生成树**。

为了在遍历过程中便于区分顶点是否已被访问，需附设访问标志数组`visited`，其初值为`false`，一旦某个顶点被访问，则其相应的分量置为`true`。

> **算法 6.3**&nbsp;&nbsp;&nbsp;&nbsp;深度优先搜索遍历连通图
>
> 1. 从图中某个顶点`v`出发，访问`v`，并置`visited[v]`为`true`。
> 2. 依次检查`v`的所有邻接点`w`，如果`visited[w]`为`false`，再从`w`出发进行递归遍历，直到图中所有顶点都被访问过。

```C++{.line-numbers}
bool visited[MVNum]; // 访问标志数组，其初值为 false

void DFS(Graph G, int v)
{
    cout << v; // 访问结点 v
    visited[v] = true;
    
    // 依次检查 v 的所有邻接点 w，FirstAdjVex(G, v) 表示 v 的第一个邻接点
    // NextAdjVex(G, v, w) 表示 v 相对于 w 的下一个邻接点
    for (int w = FirstAdjVex(G, v), w >= 0; w = NextAdjVex(G, v, w))
    {
        if (!visited[w])
            DFS(G, w);
    }
}
```

若是非连通图，上述遍历过程执行之后，图中一定还有顶点未被访问，需要从图中另选一个未被访问的顶点作为起始点，重复上述深度优先搜索过程，直到图中所有顶点均被访问过为止。

> **算法 6.4**&nbsp;&nbsp;&nbsp;&nbsp;深度优先搜索遍历非连通图

```C++{.line-numbers}
void DFSTraverse(Graph G)
{
    // 访问标志数组初始化
    for (int v = 0; v < G.vexnum; v++)
        visited[v] = false;
    
    // 循环调用算法 6.3
    for (int v = 0; v < G.vexnum; v++)
    {
        if (!visited[v]) // 对尚未访问的顶点调用 DFS
            DFS(G, v);
    }
}
```

对于算法 6.4，每调用一次算法 6.3 将遍历一个连通分量，有多少次调用，就说明图中有多少个连通分量。

在算法 6.3 中，对于查找邻接点的操作`FirstAdjVex(G, v)`及`NextAdjVex(G, v, w)`并没有具体展开。如果图的存储结构不同，这两个操作的实现方法不同，时间耗费也不同。下面的算法 6.5、算法 6.6 分别用邻接矩阵和邻接表具体实现了算法 6.3 的功能。

> **算法 6.5**&nbsp;&nbsp;&nbsp;&nbsp;采用邻接矩阵表示图的深度优先搜索

```C++{.line-numbers}
void DFS_AM(AMGrapg G, int v)
{
    cout << v;
    visited[v] = true;
    
    for (int w = 0; w < G.vexnum; w++) // 依次检查邻接矩阵中 v 所在的行
    {
        // G.arcs[v][w] != 0 表示 w 是 v 的邻接点，如果 w 未访问，则递归调用 DFS
        if (G.arcs[v][w] != 0 && !visited[w])
            DFS_AM(G, w);
    }
}
```

> **算法 6.6**&nbsp;&nbsp;&nbsp;&nbsp;采用邻接表表示图的深度优先搜索

```C++{.line-numbers}
void DFS_AL(ALGraph G, int v)
{
    cout << v;
    visited[v] = true;

    ArcNode *p = G.vertices[v].firstarc; // p 指向 v 的边链表的第一个边结点
    while(p != NULL)
    {
        ArcNode *w = p->adjvex; // w 是 v 的邻接点
        if (!visited[w]) // 如果 w 未访问，则递归调用 DFS
            DFS_AL(G, w);
        p = p->nextarc;
    }
}
```

在遍历图时，对图中每个顶点至多调用一次`DFS`函数，因此，遍历图的过程实质上是对每个顶点查找其邻接点的过程，其耗费的时间取决于所采用的存储结构。当用邻接矩阵表示图时，查找每个顶点的邻接点的时间复杂度为 $O(n^2)$，其中 $n$ 为图中顶点数。而当以邻接表做图的存储结构时，查找邻接点的时间复杂度为 $O(e)$，其中 $e$ 为图中边数，因此深度优先搜索的时间复杂度为 $O(n+e)$。

### 6.4.2 广度优先搜索

广度优先搜索（Breadth First Search，BFS）类似于树的按层次遍历的过程。

广度优先搜索的过程如下：

1. 从图中某个顶点 $v$ 出发，访问 $v$。
2. 依次访问 $v$ 的各个未曾访问过的邻接点。
3. 分别从这些邻接点出发依次访问它们的邻接点，并使“先被访问的顶点的邻接点”先于“后被访问的顶点的邻接点”被访问。重复步骤 3，直至图中所有已被访问的顶点的邻接点都被访问到。

> **算法 6.7**&nbsp;&nbsp;&nbsp;&nbsp;广度优先搜索遍历连通图
>
> 1. 从图中某个顶点`v`出发，访问`v`，并置`visited[v]`为`true`，然后将`v`入队。
> 2. 只要队列不空，则重复下述操作：
>   （1）队头顶点`u`出队。
>   （2）依次检查`u`的所有邻接点`w`，如果`visited[w]`为`false`，则访问`w`，并置`visited[w]`为`true`，然后将`w`入队。

```C++{.line-numbers}
void BFS(Graph G, int v)
{
    cout << v; // 访问顶点 v
    visited[v] = true;
    
    InitQueue(Q); // 队列初始化
    EnQueue(Q, v); // v 入队
    
    while (!QueueEmpty(Q)) // 队列非空
    {
        DeQueue(Q, u); // 队头元素出队并置为 u
        // 依次检查 u 的所有邻接点 w
        for (int w = FirstAdjVex(G, u); w >= 0; w = NextAdjVex(G, u, w))
        {
            if (!visited[w])
            {
                count << w;
                visited[w] = true;
                EnQueue(Q, w);
            }
        }
    }
}
```

若是非连通图，上述遍历过程执行之后，图中一定还有顶点未被访问，需要从图中另选一个未被访问的顶点作为起始点，重复上述广度优先搜索过程，直到图中所有顶点均被访问过为止。

每个顶点至多进一次队列。遍历图的过程实质上是通过边找邻接点的过程，因此广度优先搜索遍历图的时间复杂度和深度优先搜索遍历相同，即当用邻接矩阵存储时，时间复杂度为 $O(n^2)$；用邻接表存储时，时间复杂度为$O(n+e)$。两种遍历方法的不同之处仅仅在于对顶点访问的顺序不同。

## 6.5 图的应用

### 6.5.1 最小生成树

在一个连通网的所有生成树中，各边的代价之和最小的那棵生成树称为该联通网的**最小代价生成树**（Minimum Cost Spanning Tree），简称**最小生成树**（MST）。

**最小生成树的 MST 性质**：假设 $N=(V,E)$ 是一个连通网，$U$ 是顶点集 $V$ 的一个非空子集，若 $(u,v)$ 是一条具有最小权值的边，其中 $u\in U,v\in V-U$，则必存在一棵包含边 $(u,v)$ 的最小生成树。

> **证明：** 使用反证法。假设网 $N$ 的任何一棵最小生成树都不包含 $(u,v)$，设 $T$ 是连通网上的一棵最小生成树，当将边 $(u,v)$ 加入到 $T$ 中时，由生成树的定义，$T$ 中必存在一条包含 $(u,v)$ 的回路。另一方面，由于 $T$ 是生成树，则在 $T$ 上必存在另一条边 $(u',v')$，其中 $u'\in U,v'\in V-U$，且 $u$ 和 $u'$ 之间、$v$ 和 $v'$ 之间均有路径相通。删去边 $(u',v')$，便可消除上述回路，同时得到另一棵生成树 $T'$。因为 $(u,v)$ 的权值不高于 $(u',v')$，则 $T'$ 的权值也不高于 $T$，$T'$ 是包含 $(u,v)$ 的一棵最小生成树，与假设矛盾。

#### 6.5.1.1 普里姆（Prim）算法

假设 $N=(V,E)$ 是连通网，$TE$ 是 $N$ 上最小生成树中边的集合，则普里姆算法的构造过程为：

1. 初始化：$U=\{u_0\}(u_0\in V),TE=\{\}$。
2. 在所有 $u\in U,v\in V-U$ 的边 $(u,v)\in E$ 中找一条权值最小的边 $(u_0,v_0)$ 并入集合 $TE$，同时 $v_0$ 并入 $U$。如果选择权值最小的边时，存在多条同样权值的边可选，此时任选其一即可。
3. 重复步骤 2，直至 $U=V$ 为止。

图 6.4 所示为一个连通网从 $v_1$ 开始构造最小生成树的例子。可以看出，普里姆算法逐步增加 $U$ 中的顶点，可称为“加点法”。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/数据结构/图6.4-普里姆算法构造最小生成树的例子.png">
    <br>
    图 6.4&nbsp;&nbsp;&nbsp;&nbsp;普里姆算法构造最小生成树的例子
</div>

假设一个无向网 $G$ 以邻接矩阵形式存储，从顶点 $u$ 出发构造 $G$ 的最小生成树 $T$，要求输出 $T$ 的各条边。为实现这个算法需附设一个辅助数组`closedge`，以记录从 $U$ 到 $V-U$ 具有最小权值的边。对每个顶点 $v_i\in V-U$，在辅助数组中存在一个相应分量`closedge[i - 1]`，它包括两个域：`lowcost`和`adjvex`，其中`lowcost`存储最小边上的权，`adjvex`存储最小边在 $U$ 中的那个顶点。

> **算法 6.8**&nbsp;&nbsp;&nbsp;&nbsp;普里姆算法
>
> 1. 首先将初始顶点 $u$ 加入 $U$ 中，对其余的每个顶点 $v_j$，将`closedge[j]`均初始化为到 $u$ 的边信息。
> 2. 循环 $n-1$ 次，做如下处理：
>   （1）从各组边`closedge`中选出最小边`closedge[k]`，输出此边。
>   （2）将 $k$ 加入 $U$ 中。
>   （3）更新剩余的每组最小边信息`closedge[j]`。对于 $V-U$ 中的边，新增了一条从 $k$ 到 $j$ 的边，如果新边的权值比`closedge[j].lowcost`小，则将`closedge[j].lowcost`更新为新边的权值。

```C++{.line-numbers}
// 辅助数组的定义，用来记录从顶点集 U 到 V-U 的权值最小的边
struct
{
    VerTexType adjvex; // 最小边在 U 中的那个顶点
    ArcType lowcost; // 最小边上的权值
} closedge[MVNum];

// 无向网 G 以邻接矩阵形式存储，从顶点 u 出发构造 G 的最小生成树 T，输出 T 的各条边
void MiniSpanTree_Prim(AMGrapg G, VerTexType u)
{
    int k = LocateVex(G, u); // k 为顶点 u 的下标
    // 初始化 closedge
    for (int j = 0; j < G.vexnum; j++)
    {
        if (j != k)
        {
            closedge[j].adjvex = u;
            closedge[j].lowcost = G.arcs[k][j];
        }
    }
    closedge[k].lowcost = 0;

    for (int i = 1; i < G.vexnum; i++)
    {
        k = Min(closedge); // 最小边的下标
        u0 = closedge[k].adjvex; // 最小边在 U 中的顶点
        v0 = G.vexs[k]; // 最小边的另一个顶点
        cout << u0 << v0;

        closedge[k].lowcost = 0; // 将 k 并入 U

        // 更新 closedge
        for (int j = 0; j < G.vexnum; j++)
        {
            if (G.arcs[k][j] < closedge[j].lowcost)
            {
                closedge[j].adjvex = G.vexs[k];
                closedge[j].clocost = G.arcs[k][j];
            }
        }
    }
}
```

假设网中有 $n$ 个顶点，则第一个进行初始化的循环语句的频度为 $n$，第二个循环语句的频度为 $n-1$。其中第二个循环中有两个内循环：其一是在`closedge[v].lowcost`中求最小值，其频度为 $n-1$；其二是重新选择具有最小权值的边，其频度为 $n$。由此，普里姆算法的时间复杂度为 $O(n^2)$，与网中的边数无关，因此适用于求稠密网的最小生成树。

#### 6.5.1.2 克鲁斯卡尔（Kruskal）算法

克鲁斯卡尔算法的构造过程：

1. 假设连通网 $N=(V,E)$，将 $N$ 中的边按权值从小到大的顺序排列。
2. 初始状态为只有 $n$ 个顶点而无边的非连通图 $T=(V,\{\})$，图中每个顶点自成一个连通分量。
3. 在 $E$ 中选择权值最小的边，若该边依附的顶点落在 $T$ 中不同的连通分量上（即不形成回路），则将此边加入到 $T$ 中，否则舍去此边而选择下一条权值最小的边。
4. 重复 3，直至 $T$ 中所有顶点都在统一连通分量上为止。

克鲁斯卡尔算法逐步增加生成树的边，与普里姆算法相比，可称为“加边法”。每次选择最小边时，可能有多条同样权值的边可选，可以任选其一。

克鲁斯卡尔算法的实现需要引入以下的辅助数据结构：

1. 结构体数组`Edge`：存储边的信息，包括边的两个顶点和权值。
2. 数组`Vexset`：标识各个顶点所属的连通分量。对每个顶点 $v_i\in V$，在辅助数组中存在一个相应元素`Vexset[i]`表示该顶点所在的连通分量。初始时`Vexset[i] = i`，表示各顶点自成一个连通分量。

> **算法 6.9**&nbsp;&nbsp;&nbsp;&nbsp;克鲁斯卡尔算法
>
> 1. 将数组`Edge`中的元素按权值从小到大排序。
> 2. 依次查看数组`Edge`中的边，循环执行以下操作：
> （1）依次从排好序的数组`Edge`中选出一条边 $(v_1,v_2)$；
> （2）在`Vexset`中分别查找 $v_1$ 和 $v_2$ 所在的连通分量 $vs_1$ 和 $vs_2$，进行判断：
>    - 如果 $vs_1$ 和 $vs_2$ 不等，表明所选的两个顶点分属不同的连通分量，输出此边，并合并 $vs_1$ 和 $vs_2$ 两个连通分量；
>    - 如果 $vs_1$ 和 $vs_2$ 相等，表明所选的两个顶点属于同一个连通分量，舍去此边而选择下一条权值最小的边。

```C++{.line-numbers}
// 辅助数组 Edge 的定义
struct
{
    VerTexType Head; // 边的始点
    VerTexType Tail; // 边的终点
    ArcType lowcost; // 边上的权值
} Edge[arcnum];

// 辅助数组 Vexset 的定义
int Vexset[MVNum];

// 无向网 G 以邻接矩阵形式存储，构造 G 的最小生成树 T，输出 T 的各条边
void MiniSpanTree_Kruskal(AMGraph G)
{
    Sort(Edge); // 将数组 Edge 中的元素按权值从小到大排序

    // 辅助数组 Vexset 初始化，表示各顶点自成一个连通分量
    for (int i = 0; i < G.vexnum; i++)
    {
        Vexset[i] = i;
    }

    // 依次查看数组 Edge 中的边
    for (int i = 0; i < G.arcnum; i++)
    {
        int v1 = LocateVex(G, Edge[i].Head); // v1 为边的始点的下标
        int v2 = LocateVex(G, Edge[i].Tail); // v2 为边的终点的下标
        int vs1 = Vexset[v1]; // 获取边 Edge[i] 的始点所在的连通分量
        int vs2 = Vexset[v2]; // 获取边 Edge[i] 的终点所在的连通分量

        if (vs1 != vs2) // 边的两个顶点分属不同的连通分量
        {
            cout << Edge[i].Head << Edge[i].Tail; // 输出此边
            // 合并 vs1 和 vs2 两个分量
            for (int j = 0; j < G.vexnum; j++)
            {
                if (Vexset[j] == vs2)
                {
                    Vexset[j] = vs1; // 集合编号为 vs2 的都改为 vs1
                }
            }
        }
    }
}
```

假设使用堆排序对辅助数组`Edge`进行排序，对于包含 $e$ 条边的网，排序时间是 $O(e\log_2 e)$。在 for 循环中最耗时的操作是合并两个不同的连通分量，只要采取合适的数据结构，可以证明其执行时间为 $O(\log_2 e)$，因此整个 for 循环的执行时间是 $O(e\log_2 e)$。由此，克鲁斯卡尔算法的时间复杂度为 $O(e\log_2 e)$。与普里姆算法相比，克鲁斯卡尔算法更适合于求稀疏网的最小生成树。

### 6.5.2 最短路径

在带权有向网中，称路径上的第一个顶点为**源点**（source），最后一个顶点为**终点**（destination）。

#### 6.5.2.1 从某个源点到其余各顶点的最短路径

给定带权有向图 $G$ 和源点 $v_0$，求从 $v_0$ 到 $G$ 中其余各顶点的最短路径。

迪杰斯特拉（Dijkstra）算法的求解过程：对于网 $N=(V,E)$，将 $N$ 中的顶点分成两组，$S$ 为已求出最短路径的终点集合（初始时只包含源点 $v_0$），$V-S$ 为尚未求出最短路径的顶点集合（初始时为 $V-\{v_0\}$）。算法将按各顶点与 $v_0$ 间最短路径长度递增的次序，逐个将集合 $V-S$ 中的顶点加入到集合 $S$ 中去。在这个过程中，总保持从 $v_0$ 到集合 $S$ 中各顶点的路径长度始终不大于到集合 $V-S$ 中各顶点的路径长度。

这种求解方法能确保是正确的。因为，假设 $S$ 为已求得最短路径的终点的集合，则下一条最短路径（设其终点为 $x$）或者是边 $(v_0,x)$，或者是中间只经过 $S$ 中的顶点而最后到达顶点 $x$ 的路径。

> **证明：** 使用反证法。假设此路径上有一个顶点不在 $S$ 中，则说明存在一条终点不在 $S$ 而长度比此路径更短的路径。但这是不可能的，因为算法是按路径长度递增的顺序来产生最短路径的，长度比此路径短的所有路径均已产生，它们的终点必定在 $S$ 中，因此假设不成立。所以，最新的最短路径一定只经过 $S$ 中的顶点而最后到达顶点 $x$。

假设用带权的邻接矩阵`arcs`来表示带权有向网 $G$，`G.arcs[i][j]`表示弧 $\text{<}v_i,v_j\text{>}$ 上的权值。若 $\text{<}v_i,v_j\text{>}$ 不存在，则置`G.arcs[i][j]`为 $\infin$。

算法的实现要引入以下的辅助数据结构：

1. 一维数组`S`：元素`S[i]`记录从源点 $v_0$ 到终点 $v_i$ 是否已经确定最短路径长度，`true`表示确定，`false`表示尚未确定。
2. 一维数组`Path`：元素`Path[i]`记录从源点 $v_0$ 到终点 $v_i$ 的当前最短路径上 $v_i$ 的直接前驱顶点序号。其初值为：如果从 $v_0$ 到 $v_i$ 有弧，则`Path[i]`为 $v_0$，否则为 -1。
3. 一维数组`D`：元素`D[i]`记录从源点 $v_0$ 到终点 $v_i$ 的当前最短路径长度。其初值为：如果从 $v_0$ 到 $v_i$ 有弧，则`D[i]`为弧上的权值，否则为 $\infin$。

长度最短的一条最短路径 $(v_0,v_k)$ 满足以下条件：

$$
\operatorname{D}[k]=\min\{\operatorname{D}[i]\,|\,v_i\in V-S\}
$$

求得顶点 $v_k$ 的最短路径后，将其加入到顶点集 $S$ 中。

每当加入一个新的顶点到顶点集 $S$，对 $V-S$ 剩余的各个顶点而言，多了一个中转顶点，从而多了一个中转路径，所以要对 $V-S$ 中剩余的各个顶点的最短路径长度进行更新。原来 $v_0$ 到 $v_i$ 的最短路径长度为`D[i]`，加进 $v_k$ 后，以 $v_k$ 作为中间顶点的中转路径长度为`D[k] + G.arcs[k][i]`，若`D[k] + G.arcs[k][i] < D[i]`，则用`D[k] + G.arcs[k][i]`取代`D[i]`。

更新后，再选择数组`D`中值最小的顶点加入到顶点集 $S$ 中，如此进行下去，直到图中所有顶点都加入到 $S$ 中为止。

> **算法 6.10**&nbsp;&nbsp;&nbsp;&nbsp;迪杰斯特拉算法
>
> 1. 初始化：
>    （1）将源点 $v_0$ 加到 $S$ 中，即`S[v0] = true`；
>    （2）将 $v0$ 到各个终点的最短路径长度初始化为权值，即`D[i] = G.arcs[v0][vi]`（$v_i\in V-S$）；
>    （3）如果 $v_0$ 和 $v_i$ 之间有弧，则将 $v_i$ 的前驱置为 $v_0$，即`Path[i] = v0`，否则`Path[i] = -1`。
> 2. 循环 $n-1$ 次，执行以下操作：
>    （1）选择下一条最短路径的终点 $v_k$，使得 $\operatorname{D}[k]=\min\{\operatorname{D}[i]\,|\,v_i\in V-S\}$；
>    （2）将 $v_k$ 加到 $S$ 中，即`S[vk] = true`；
>    （3）根据条件更新从 $v_0$ 出发到集合 $V-S$ 上任一顶点的最短路径的长度。若`D[k] + G.arcs[k][i] < D[i]`成立，则更新`D[i] = D[k] + G.arcs[k][i]`，同时更改 $v_i$ 的前驱为 $v_k$，即`Path[i] = k`。

```C{.line-numbers}
void Dijkstra(AMGraph G, int v0)
{
    int n = G.vexnum; // n 为 G 中顶点的个数
    // n 个顶点依次初始化
    for (int i = 0; i < n; i++)
    {
        S[i] = false; // S 初始为空集
        D[i] = G.arcs[v0][i]; // 将 v0 到各个终点的最短路径长度初始化为弧上的权值
        if (D[i] < MaxInt)
            Path[i] = v0; // 如果 v0 和 i 之间有弧，则将 i 的前驱置为 v0
        else
            Path[i] = -1; // 如果 v0 和 i 之间没有弧，则将 i 的前驱置为 -1
    }
    S[v0] = true; // 将 v0 加入 S
    D[v0] = 0; // 源点到源点的距离为 0

    // 主循环，每次求得 v0 到某个顶点 v 的最短路径，将 v 加入 S
    for (int i = 1; i < n; i++)
    {
        int min = MaxInt;
        int v;

        // 找到当前路径长度最短的顶点 v
        for (int j = 0; j < n; j++)
        {
            if (!S[j] && D[j] < min)
            {
                v = j;
                min = D[j];
            }
        }

        // 将 v 加入 S
        S[v] = true;

        // 更新从 v0 出发到集合 V-S 上所有顶点的最短路径长度
        for (int j = 0; j < n; j++)
        {
            if (!S[j] && D[v] + G.arcs[v][j] < D[j])
            {
                D[j] = D[v] + G.arcs[v][j];
                Path[j] = v; // 更改 j 的前驱为 v
            }
        }
    }
}
```

算法 6.10 的主循环共执行 $n-1$ 次，每次执行的时间是 $O(n)$，所以算法的时间复杂度为 $O(n^2)$。如果采用带权的邻接表作为有向图的存储结构，则虽然修改`D`的时间可以减少，但由于在`D`向量中选择最小分量的时间不变，所以时间复杂度仍为 $O(n^2)$。

#### 6.5.2.2 每一对顶点之间的最短路径

求解每一对顶点之间的最短路径有两种方法：其一是分别以图中的每个顶点为源点共调用 $n$ 次迪杰斯特拉算法；其二是采用下面介绍的弗洛伊德（Floyd）算法。两种算法的时间复杂度均为 $O(n^3)$，但后者形式上较简单。

弗洛伊德算法使用带权的邻接矩阵`arcs`来表示有向网 $G$。算法的实现要引入以下的辅助数据结构：

1. 二维数组`Path`：`Path[i][j]`表示最短路径上顶点 $v_j$ 的前驱顶点的序号。
2. 二维数组`D`：`D[i][j]`表示顶点 $v_i$ 和 $v_j$ 之间的最短路径长度。

初始时，将 $v_i$ 到 $v_j$ 的最短路径长度初始化，即`D[i][j] = G.arcs[i][j]`，然后进行 $n$ 次比较和更新。

1. 在 $v_i$ 和 $v_j$ 之间加入顶点 $v_0$，比较 $(v_i,v_j)$ 和 $(v_i,v_0,v_j)$ 的路径长度，取其中较短者作为 $v_i$ 到 $v_j$ 的中间顶点序号不大于 0 的最短路径。
2. 在 $v_i$ 和 $v_j$ 之间加入顶点 $v_1$，得到 $(v_i,\cdots,v_1)$ 和 $(v_1,\cdots,v_j)$，其中 $(v_i,\cdots,v_1)$ 是 $v_i$ 到 $v_1$ 的且中间顶点序号不大于 0 的最短路径，$(v_1,\cdots,v_j)$ 是 $v_1$ 到 $v_j$ 的且中间顶点序号不大于 0 的最短路径，这两条路径已在上一步中求出。比较 $(v_i,\cdots,v_1,\cdots,v_j)$ 与上一步求出的 $v_i$ 到 $v_j$ 的中间顶点序号不大于 0 的最短路径，取其中较短者作为 $v_i$ 到 $v_j$ 的中间顶点序号不大于 1 的最短路径。
3. 以此类推，在 $v_i$ 和 $v_j$ 之间加入顶点 $v_k$，若 $(v_i,\cdots,v_k)$ 和 $(v_k,\cdots,v_j)$ 分别是从 $v_i$ 到 $v_k$ 和从 $v_k$ 到 $v_j$ 的中间顶点序号不大于 $k-1$ 的最短路径，则将 $(v_i,\cdots,v_k,\cdots,v_j)$ 和已经得到的从 $v_i$ 到 $v_j$ 且中间顶点序号不大于 $k-1$ 的最短路径相比较，其长度较短者便是从 $v_i$ 到 $v_j$ 的中间顶点序号不大于 $k$ 的最短路径。

这样，经过 $n$ 次比较后，最后求得的必是从 $v_i$ 到 $v_j$ 的最短路径。按此方法，可以同时求得各对顶点之间的最短路径。

根据上述求解过程，图中的所有顶点对 $(v_i,v_j)$ 间的最短路径长度对应一个 $n$ 阶方阵 $\boldsymbol{D}$。在上述 $n+1$ 步中，$\boldsymbol{D}$ 不断变化，对应一个 $n$ 阶方阵序列。$n$ 阶方阵序列定义为：

$$
\boldsymbol{D}^{(-1)},\boldsymbol{D}^{(0)},\boldsymbol{D}^{(1)},\cdots,\boldsymbol{D}^{(k)},\cdots,\boldsymbol{D}^{(n-1)}
$$

其中，

$$
\boldsymbol{D}^{(-1)}[i][j]=G.arcs[i][j]\\
\boldsymbol{D}^{(k)}[i][j]=\min\{\boldsymbol{D}^{(k-1)}[i][j],\boldsymbol{D}^{(k-1)}[i][k]+\boldsymbol{D}^{(k-1)}[k][j]\},0 \leqslant k \leqslant n-1
$$

$\boldsymbol{D}^{(1)}[i][j]$ 是从 $v_i$ 到 $v_j$ 的中间顶点序号不大于 1 的最短路径的长度，$\boldsymbol{D}^{(k)}[i][j]$ 是从 $v_i$ 到 $v_j$ 的中间顶点序号不大于 $k$ 的最短路径的长度，$\boldsymbol{D}^{(n-1)}[i][j]$ 是从 $v_i$ 到 $v_j$ 的最短路径的长度。

> **算法 6.11**&nbsp;&nbsp;&nbsp;&nbsp;弗洛伊德算法

```C{.line-numbers}
void Floyd(AMGaph G)
{
    // 初始化
    for (int i = 0; i < G.vexnum; i++)
    {
        for (int j = 0; j < G.vexnum; j++)
        {
            D[i][j] = G.arcs[i][j];

            if (D[i][j] < MaxInt)
                Path[i][j] = i; // 如果 i 和 j 之间有弧，则将 j 的前驱置为 i
            else
                Path[i][i] = -1; // 如果 i 和 j 之间无弧，则将 j 的前驱置为 -1
        }
    }

    for (int k = 0; k < G.vexnum; k++)
    {
        for (int i = 0; i < G.vexnum; i++)
        {
            for (int j = 0; j < G.vexnum; j++)
            {
                if (D[i][k] + D[k][j] < D[i][j])
                {
                    D[i][j] = D[i][k] + D[k][j]
                    Path[i][j] = Path[k][j]; // j 的前驱更改为 k
                }
            }
        }
    }
}
```

### 6.5.3 拓扑排序

无环的有向图称作**有向无环图**（Directed Acycline Graph），简称 DAG 图。有向无环图是描述一项工程或系统的进行过程的有效工具。

一般可以将工程分为若干个活动（activity），这些活动之间通常受着一定条件的约束，如其中某些活动的开始必须在另一些活动完成之后。这种先后关系可以用有向图表示，用顶点表示活动，用弧表示活动间的优先关系，这样的有向图称为**顶点表示活动的网**（Activity On Vertex Network），简称 **AOV-网**。

在网中，若从顶点 $v_i$ 到顶点 $v_j$ 有一条有向路径，则 $v_i$ 是 $v_j$ 的前驱，$v_j$ 是 $v_i$ 的后继。若 $\text{<}v_i,v_j\text{>}$ 是网中的一条弧，则 $v_i$ 是 $v_j$ 的直接前驱，$v_j$ 是 $v_i$ 的直接后继。

在 AOV-网中不应该出现有向环，因为存在环意味着某项活动以自己为先决条件，这是荒谬的。因此，对给定的 AOV-网应首先判定网中是否存在环。检测的办法是对有向图的顶点进行拓扑排序，若网中所有顶点都在它的拓扑序列中，则该 AOV-网中必定不存在环。

**拓扑排序**就是将 AOV-网中所有顶点排成一个线性序列，该序列满足：若在 AOV-网中由顶点 $v_i$ 到顶点 $v_j$ 有一条路径，则在该线性序列中顶点 $v_i$ 必定在顶点 $v_j$ 之前。

对于任何无回路的 AOV-网，其顶点均可排成拓扑序列，并且其拓扑序列未必唯一。

拓扑排序的过程：

1. 在有向图中选一个无前驱的顶点并输出它。
2. 从图中删除该顶点和所有从它出发的弧。
3. 重复 1 和 2，直至不存在无前驱的顶点。
4. 若此时输出的顶点数小于有向图中的顶点数，则说明有向图中存在环，否则输出的顶点序列即为一个拓扑序列。

针对上述拓扑排序的过程，可采用邻接表做有向图的存储结构。

算法的实现要引入以下的辅助数据结构：

1. 一维数组`indegree`：存放各顶点入度。删除顶点及从它出发的弧的操作，可不必真正对图的存储结构进行改变，可用弧头顶点的入度减 1 的办法来实现。
2. 栈`S`：暂存所有入度为 0 的顶点，这样可以避免重复扫描数组`indegree`检测入度为 0 的顶点，提高算法的效率。
3. 一维数组`topo`：记录拓扑序列的顶点序号。

> **算法 6.12**&nbsp;&nbsp;&nbsp;&nbsp;拓扑排序
>
> 1. 求出各顶点的入度存入数组`indegree`中，并将入度为 0 的顶点入栈。
> 2. 只要栈不空，则重复以下操作：
>    - 将栈顶顶点 $v_i$ 出栈并保存在数组`topo`中。
>    - 对顶点 $v_i$ 的每个邻接点 $v_k$ 的入度减 1，如果 $v_k$ 的入度变为 0，则将 $v_k$ 入栈。
> 3. 如果输出的顶点个数少于 AOV-网的顶点个数，则网中存在有向环，无法进行拓扑排序，否则拓扑排序成功。

```C{.line-numbers}
// 有向图 G 采用邻接表存储结构
// 若 G 无回路，则生成 G 的一个拓扑序列 topo 并返回 OK，否则返回 ERROR
Status TopologicalSort(ALGraph G, int topo[])
{
    FindInDegree(G, indegree); // 求出各顶点的入度存入数组 indegree 中
    InitStack(S); // 栈 S 初始化为空

    // 入度为 0 的顶点入栈
    for (int i = 0; i < G.vexnum; i++)
    {
        if (indegree[i] == 0)
            Push(S, i);
    }

    int m = 0; // 对输出顶点计数
    while (!StackEmpty(S))
    {
        Pop(S, i); // 栈顶元素出栈
        topo[m] = i; // 将栈顶顶点保存在拓扑序列中
        m++; // 计数器加 1

        // 对顶点 i 的所有邻接顶点进行操作
        p = G.vertices[i].firstarc;
        while (p)
        {
            int k = p->adjvex;
            indegree[k]--; // 入度减 1

            // 若入度减为 0，则入栈
            if (indegree[k] == 0)
                Push(S, k);
            
            p = p->nextarc;
        }
    }

    if (m < G.vexnum)
        return ERROR;
    else
        return OK;
}
```

对有 $n$ 个顶点和 $e$ 条边的有向图而言，求各顶点入度的时间复杂度为 $O(e)$，建立零入度顶点栈的时间复杂度为 $O(n)$。在拓扑排序过程中，若有向图无环，则每个顶点进一次栈、出一次栈，入度减 1 的操作在循环中总共执行 $e$ 次，所以总的时间复杂度为 $O(n+e)$。

### 6.5.4 关键路径

AOE-网（Activity On Edge Network）是带权的有向无环图，其中，顶点表示事件，弧表示活动，权表示活动持续的时间。AOE-网可用来估算工程的完成时间。

由于整个工程只有一个开始点和一个完成点，故在正常情况（无环）下，AOE-网中只有一个入度为零的顶点，称作**源点**；也只有一个出度为零的顶点，称作**汇点**。在 AOE-网中，一条路径各弧上的权值之和称为该路径的**带权路径长度**。要估算整项工程完成的最短时间，就是要找一条从源点到汇点的带权路径长度最长的路径，称为**关键路径**（critical path）。关键路径上的活动叫做**关键活动**，这些活动是影响工程进度的关键，它们的提前或拖延将使整个工程提前或拖延。

**定理 6.1**&nbsp;&nbsp;&nbsp;&nbsp;任意的非空 AOE-网至少存在一条关键路径。

为了求关键路径，首先定义 4 个描述量。

1. 事件 $v_i$ 的最早发生时间 $ve(i)$

进入事件 $v_i$ 的每一活动都结束，$v_i$ 才能发生，所以 $ve(i)$ 是从源点到 $v_i$ 的最长路径长度。

求 $ve(i)$ 的值，可根据拓扑顺序从源点开始向汇点递推。通常将工程的开始顶点事件 $v_0$ 的最早发生时间定义为 0，即

$$
ve(0)=0\\
ve(i)=\max\{ve(k)+w_{k,i}\},\,\text{<}v_k,v_i\text{>}\in T,\,1 \leqslant i \leqslant n-1
$$

其中，$T$ 是所有以 $v_i$ 为头的弧的集合，$w_{k,i}$ 是弧 $\text{<}v_k,v_i\text{>}$ 的权值，即对应活动 $\text{<}v_k,v_i\text{>}$ 的持续时间。

2. 事件 $v_i$ 的最迟发生时间 $vl(i)$

事件 $v_i$ 的发生不得延误 $v_i$ 的每一后继事件的最迟发生时间。为了不拖延工期，$v_i$ 的最迟发生时间不得迟于其后继事件 $v_k$ 的最迟发生时间减去活动 $\text{<}v_i,v_k\text{>}$ 的持续时间。

求出 $ve(i)$ 后，可根据逆拓扑顺序从汇点开始向源点递推，求出 $vl(i)$。

$$
vl(n-1)=ve(n-1)\\
vl(i)=\min\{vl(k)-w_{i,k}\},\,\text{<}v_i,v_k\text{>}\in S,\,0 \leqslant i \leqslant n-2
$$

其中，$S$ 是所有以 $v_i$ 为尾的弧的集合，$w_{i,k}$ 是弧 $\text{<}v_i,v_k\text{>}$ 的权值。

3. 活动 $a_i=\text{<}v_j,v_k\text{>}$ 的最早开始时间 $e(i)$

只有事件 $v_j$ 发生了，活动 $a_i$ 才能开始。所以，活动 $a_i$ 的最早开始时间等于事件 $v_j$ 的最早发生时间，即

$$
e(i)=ve(j)
$$

4. 活动 $a_i=\text{<}v_j,v_k\text{>}$ 的最晚开始时间 $l(i)$

活动 $a_i$ 的开始时间需保证不延误事件 $v_k$ 的最迟发生时间，所以活动 $a_i$ 的最晚开始时间等于事件 $v_k$ 的最迟发生时间减去活动 $a_i$ 的持续时间，即

$$
l(i)=vl(k)-w_{j,k}
$$

一个活动 $a_i$ 的最晚开始时间与最早开始时间的差值 $l(i)-e(i)$ 是该活动完成的时间余量，它是在不增加完成整个工程所需的总时间的情况下，活动 $a_i$ 可以拖延的时间。当一活动的余量为零时，说明该活动必须如期完成，否则就会拖延整个工程的进度。所以 $l(i)-e(i)=0$，即 $l(i)=e(i)$ 的活动 $a_i$ 是关键活动。

求解关键路径的过程：

1. 对图中顶点进行拓扑排序，在排序过程中按拓扑序列求出每个事件的最早发生时间 $ve(i)$。
2. 按逆拓扑序列求出每个事件的最迟发生时间 $vl(i)$。
3. 求出每个活动的最早开始时间 $e(i)$。
4. 求出每个活动的最晚开始时间 $l(i)$。
5. 找出 $e(i)=l(i)$ 的活动 $a_i$，即为关键活动。由关键活动组成的从源点到汇点的路径就是关键路径，关键路径有可能不止一条。

算法的实现要引入以下的辅助数据结构：

1. 一维数组`ve`：事件的最早发生时间。
2. 一维数组`vl`：事件的最迟发生时间。
3. 一维数组`topo`：记录拓扑序列的顶点序号。

> **算法 6.13**&nbsp;&nbsp;&nbsp;&nbsp;关键路径算法
>
> 1. 调用拓扑排序算法，使拓扑序列保存在`topo`中。
> 2. 将每个事件的最早发生时间初始化为 0。
> 3. 根据`topo`中的值，按从前向后的拓扑次序，依次求每个事件的最早发生时间。循环执行以下操作：
>    - 取得拓扑序列中的顶点序号 $k$；
>    - 用指针`p`依次指向 $k$ 的每个邻接顶点，取得每个邻接顶点的序号 $j$，依次更新顶点 $j$ 的最早发生时间`ve[j]`。
> 4. 将每个事件的最迟发生时间初始化为汇点的最早发生时间，`vl[i] = ve[n - 1]`。
> 5. 根据`topo`中的值，按从后向前的逆拓扑次序，依次求每个事件的最迟发生时间。循环 $n$ 次，执行以下操作：
>    - 取得拓扑序列中的顶点序号 $k$；
>    - 用指针`p`依次指向 $k$ 的每个邻接顶点，取得每个邻接顶点的序号 $j$，依次根据 $k$ 的邻接顶点，更新 $k$ 的最迟发生时间`vl[k]`。
> 6. 寻找关键活动。循环 $n$ 次，执行以下操作：对于每个顶点 $i$，用指针`p`依次指向 $i$ 的每个邻接顶点，取得每个邻接顶点的序号 $j$，分别计算活动 $\text{<}v_i,v_j\text{>}$ 的最早开始时间 $e$ 和最晚开始时间 $l$，如果 $e=l$，则活动 $\text{<}v_i,v_j\text{>}$ 为关键活动，输出弧 $\text{<}v_i,v_j\text{>}$。

```C++{.line-numbers}
// G 为邻接表存储的有向图，输出 G 的各项关键活动
Status CriticalPath(ALGraph G)
{
    // 调用拓扑排序算法，使拓扑序列保存在 topo 中
    // 若调用失败，则存在有向环，返回 ERROR
    if (!TopologicalSort(G, topo))
        return ERROR;
    
    int n = G.vexnum; // n 为顶点个数

    // 每个事件的最早发生时间初始化为 0
    for (int i = 0; i < n; i++)
    {
        ve[i] = 0;
    }

    // 按拓扑次序求每个事件的最早发生时间
    for (int i = 0; i < n; i++)
    {
        int k = topo[i];
        p = G.vertices[k].firstarc; // p 指向 k 的第一个邻接顶点
        while (p)
        {
            int j = p->adjvex; // j 为邻接顶点的序号
            if (ve[j] < ve[k] + p->weight)
            {
                ve[j] = ve[k] + p->weight // 更新 j 的最早发生时间
            }

            p = p->nextarc; // p 指向 k 的下一个邻接顶点
        }
    }

    // 每个事件的最迟发生时间初始化为 ve[n - 1]
    for (int i = 0; i < n; i++)
    {
        vl[i] = ve[n - 1];
    }

    // 按逆拓扑次序求每个事件的最迟发生时间
    for (int i = n - 1; i >= 0; i--)
    {
        int k = topo[i];
        p = G.vertices[k].firstarc; // p 指向 k 的第一个邻接顶点
        while (p)
        {
            int j = p->adjvex; // j 为邻接顶点的序号
            if (vl[k] > vl[j] - p->weight)
            {
                vl[k] = vl[j] + p->weight // 更新 k 的最迟发生时间
            }

            p = p->nextarc; // p 指向 k 的下一个邻接顶点
        }
    }

    // 判断每个活动是否为关键活动
    for (int i = 0; i < n; i++)
    {
        p = G.vertices[i].firstarc; // p 指向 i 的第一个邻接顶点
        while (p)
        {
            int j = p->adjvex; // j 为邻接顶点的序号

            int e = ve[i]; // 活动 <vi, vj> 的最早开始时间
            int l = vl[j] - p->weight; // 活动 <vi, vj> 的最晚开始时间
            if (e == l) // 若为关键活动，则输出 <vi, vj>
            {
                cout << G.vertices[i].data << G.vertices[j].data;
            }

            p = p->nextarc; // p 指向 i 的下一个邻接顶点
        }
    }
}
```

在求每个事件的最早和最迟发生时间，以及活动的最早和最晚开始时间时，都要对所有顶点及每个顶点边表中所有的边结点进行检查，由此，关键路径算法的时间复杂度为 $O(n+e)$。

### 6.5.5 可及性及传递闭包算法

对于图 $G$ 中的两个顶点 $v_i$ 和 $v_j$，若从 $v_i$ 到 $v_j$ 存在一条有向路径，则称 $v_i$ 到 $v_j$ 可及，记作 $v_i\to^*_E v_j$。

可以用 $n$ 阶可及矩阵 $\boldsymbol{R}$ 来描述顶点之间的可及关系。可及矩阵 $\boldsymbol{R}$ 的定义为

$$
r_{ij}=\begin{cases}
    1 & v_i\,到\,v_j\,可及\\
    0 & v_i\,到\,v_j\,不可及
\end{cases}
$$

可及性具有传递性，如果 $v_i$ 到 $v_k$ 可及，$v_k$ 到 $v_j$ 可及，则 $v_i$ 到 $v_j$ 可及。因此，在可及矩阵 $\boldsymbol{R}$ 中，若 $r_{ik}=1$ 且 $r_{kj}=1$，则必有 $r_{ij}=1$。基于此可得求可及矩阵的 Warshall 算法。

> **算法 6.14**&nbsp;&nbsp;&nbsp;&nbsp;Warshall 算法

```C{.line-numbers}
// E 为图的边集，R 为图的可及矩阵
void Warshall(E, R)
{
    // 初始化可及矩阵，初始为邻接矩阵
    for (int i = 1; i <= n; i++) // n 为顶点数
    {
        for (int j = 1; j <= n; j++)
        {
            if (i == j)
            {
                R[i][j] = 1;
            }
            else if (hasArc(E, i, j)) // <i, j> 是 E 中的一条弧
            {
                R[i][j] = 1;
            }
            else
            {
                R[i][j] = 0;
            }
        }
    }

    // 迭代更新可及矩阵
    for (int k = 1; k <= n; k++)
    {
        for (int i = 1; i <= n; i++)
        {
            if (R[i][k] == 1)
            {
                for (int j = 1; j <= n; j++)
                {
                    if (R[k][j] == 1)
                    {
                        R[i][j] = 1;
                    }
                }
            }
        }
    }
}
```

Warshall 算法的时间复杂度为 $O(n^3)$。

Warshall 算法的执行过程实际为一个动态规划过程，该动态规划的递推公式为

$$
r^{(k)}_{ij}=r^{(k-1)}_{ij}\ \operatorname{OR}\ (r^{(k-1)}_{ik}\ \operatorname{AND}\ r^{(k-1)}_{kj})\quad 1\leqslant k\leqslant n
$$

其中，$\boldsymbol{R}^{(0)}$ 为邻接矩阵；$r^{(k)}_{ij}$ 为 $\boldsymbol{R}^{(k)}$ 的元素，表示顶点 $i$ 只经过 $1,2,\cdots,k$ 到达 $j$ 的可及性；$\operatorname{AND}$ 为逻辑与运算，$\operatorname{OR}$ 为逻辑或运算。

若在可及矩阵中有 $r_{ij}=1$，说明 $v_i$ 到 $v_j$ 存在一条路径，若边 $\text{<}v_i,v_j\text{>}$ 不存在，则用虚线自 $v_i$ 向 $v_j$ 添加一条有向边，以表示 $v_i$ 到 $v_j$ 可及。对 $\boldsymbol{R}$ 中的每个非零元素执行以上操作，使得每对可及顶点之间都有一条实的或虚的有向边，这样得到的图称为原图 $G$ 的**扩展图**，也称为图 $G$ 的**传递闭包**。

设图 $G=(V,E)$ 是非循环图，$V=\{1,2,\cdots,n\}$。假设在建立 $G$ 的邻接表时，$G$ 已拓扑排序，$V$ 中的次序正号是拓扑次序，每个顶点的边链表中结点以拓扑次序由小到大排列。使用归纳法可以给出计算非循环图 $G$ 的传递闭包的算法。对于给定的顶点 $i$，如果 $i<j$，则 $j$ 的可及顶点集合`Reach[j]`已经求出，因此有

$$
\text{Reach}[i]=\{i\}\cup(\bigcup_{\text{<}i,j\text{>}\in E}\text{Reach}[j])
$$

上述过程虽然直观，但有很多重复计算。例如，沿着 $i$ 的边链表第一次遇到边 $\text{<}i,j\text{>}$ 时，如果 $j\in\text{Reach}[i]$，那么一定存在一个顶点 $h\not=j$，使得 $i\to h\to^*_E j$，从而 $\text{Reach}[j]\subseteq\text{Reach}[h]$，故没必要把`Reach[j]`并到`Reach[i]`中。因此对每个顶点 $i$ 而言，如果 $i$ 到 $j$ 存在不止一条路径，则遇到 $j$ 时 $j$ 可及的顶点都已经并入`Reach[i]`中。根据上述分析，有如下的算法，该算法可以减少重复计算。

> **算法 6.15**&nbsp;&nbsp;&nbsp;&nbsp;非循环图的传递闭包

```C{.line-numbers}
// 非循环图 G 采用邻接表方式存储，且表中顶点已拓扑排序
// Reach 表示图 G 的传递闭包
void Tranclo(G, Reach)
{
    // 初始化
    for (int i = 1; i <= G.vexnum; i++)
    {
        BReach[i] = 0; // BReach 用来记录顶点是否并到一个 Reach 集合
    }

    // 按拓扑次序由大到小计算每个顶点的可及顶点集合
    for (int i = G.vexnum; i >= 1; i--)
    {
        // 顶点到自身一定可及
        BReach[i] = 1;
        Reach[i].add(i);

        // 遍历边链表
        ArcNode* p = G.vertices[i].firstarc;
        while (p)
        {
            int j = p->adjvex;

            // 只有当 j 不在 Reach[i] 中时，才将 Reach[j] 并入 Reach[i]
            if (BReach[j] == 0)
            {
                // 将 Reach[j] 中所有未并入的顶点并入 Reach[i] 中
                for (int k in Reach[j])
                {
                    if (BReach[k] == 0)
                    {
                        Reach[i].add(k);
                        BReach[k] = 1;
                    }
                }
            }

            p = p->nextarc;
        }

        // BReach 中只有加入到 Reach[i] 的顶点变成了 1，把这些位置清零
        for (int k in Reach[i])
        {
            BReach[i] = 0;
        }
    }
}
```

此算法的时间复杂度为 $O(n^{2.5})$。

### 6.5.6 连通分量

下面给出一个算法，用它可以得到图的所有连通分量。

辅助数据结构：

1. 一维数组`markedList`：标记顶点是否已在某个连通分量中。
2. 链表`scList`：存放同一个连通分量中的顶点。链表结点由顶点标号`verName`和指针`next`组成。

初始时，`markedList`中的元素均为 0，`scList`为空链表。当通过算法知道顶点`i`在某个连通分量中时，就把`markedList[i]`置为 1，并将顶点标号`i`添加到`scList`中。

算法的基本思想：

1. 选取一个`markedList`值为 0 的顶点`v`，将`markedList[v]`置为 1，并将其放入`scList`中。从`v`出发进行深度优先搜索，找到`v`可及的所有顶点构成的表`L`。对于`L`中的每个顶点`w`，若`w`到`v`存在路径，则说明`w`和`v`属于同一个连通分量，将`markedList[w]`置为 1，并将`w`顶点放入`scList`中。当处理完表`L`中的所有顶点时，就得到了图 $G$ 的一个连通分量。此时将表`scList`清空。
2. 反复执行 1，直至`markedList`中的值均为 1，终止算法。

> **算法 6.16**&nbsp;&nbsp;&nbsp;&nbsp;计算连通分量

```C++{.line-numbers}
typedef struct Node
{
    int verName;
    struct Node* next;
} Node;

// E 为图的边集
void AllComponent(E)
{
    // 初始化
    for (int i = 1; i <= n; i++) // n 为顶点数
    {
        markedList[i] = 0;
    }
    Node* scList = new Node;
    scList->verName = 0;
    scList->next = NULL;

    Warshall(E, R); // 计算图的可及矩阵
    int t = 0; // 连通分量的个数

    for (int i = 1; i <= n; i++)
    {
        // 处理新的连通分量
        if (markedList[i] == 0)
        {
            t++; // 连通分量个数加 1
            markedList[i] = 1; // i 顶点自身加入连通分量

            // 创建新结点
            Node *p = new Node;
            p->verName = i;
            p->next = NULL;

            // 将新结点插入 scList 中
            scList->next = p;

            // 寻找该连通分量中的其他顶点
            for (int j = 1; j <= n; j++)
            {
                if (j != i && R[i][j] == 1 && R[j][i] == 1)
                {
                    markedList[j] = 1; // 加入连通分量

                    // 创建新结点
                    Node *p = new Node;
                    p->verName = j;

                    // 将新结点插入 scList 中
                    p->next = scList->next;
                    scList->next = p;
                }
            }

            // 输出连通分量，同时清空 scList
            cout << "第" << t << "个连通分量："
            while (scList->next)
            {
                Node *q = scList->next;
                cout << q->verName;

                scList->next = q->next;
                delete q;
            }
        }
    }
}
```

# 第7章 查找

## 7.1 查找的基本概念

1. 查找表

**查找表**是由同一类型的数据元素（或记录）构成的集合。

2. 关键字

**关键字**是数据元素（或记录）中某个数据项的值，用它可以标识一个数据元素（或记录）。若此关键字可以唯一地标识一个记录，则称此关键字为**主关键字**。反之，称用以识别若干记录的关键字为**次关键字**。当数据元素只有一个数据项时，其关键字即为该数据元素的值。

3. 查找

**查找**是指根据给定的某个值，在查找表中确定一个其关键字等于给定值的记录或数据元素。若表中存在这样的一个记录，则称查找成功，此时查找的结果可给出整个记录的信息，或指示该记录在查找表中的位置；若表中不存在关键字等于给定值的记录，则称查找不成功，此时查找的结果可给出一个“空”记录或“空”指针。

4. 动态查找表和静态查找表

若在查找的同时对表做修改操作，则相应的表称为**动态查找表**，否则称为**静态查找表**。换句话说，动态查找表的表结构本身是在查找过程中动态生成的，即在创建表时，对于给定值，若表中存在其关键字等于给定值的记录，则查找成功返回，否则插入关键字等于给定值的记录。

5. 平均查找长度

为确定记录在查找表中的位置，需和给定值进行比较的关键字个数的期望值，称为查找算法在查找成功时的**平均查找长度**（Average Search Length，ASL）。

对于含有 $n$ 个记录的查找表，查找成功时的平均查找长度为

$$
\tag{7-1} ASL=\sum_{i=1}^n P_i C_i
$$

其中，$P_i$ 为查找表中第 $i$ 个记录的概率，且 $\displaystyle\sum_{i=1}^n P_i=1$；$C_i$ 为找到表中其关键字与给定值相等的第 $i$ 个记录时，和给定值已进行过比较的关键字个数。

由于查找算法的基本运算是关键字之间的比较操作，所以可用平均查找长度来衡量查找算法的性能。

## 7.2 线性表的查找

### 7.2.1 顺序查找

**顺序查找**（sequential search）的查找过程为：从表的一端开始，依次将记录的关键字和给定值进行比较，若某个记录的关键字和给定值相等，则查找成功；反之，若扫描整个表后，仍未找到关键字和给定值相等的记录，则查找失败。

顺序查找方法既适用于线性表的顺序存储结构，又适用于线性表的链式存储结构。

数据元素类型定义如下：

```C{.line-numbers}
typedef struct
{
    KeyType key; // 关键字
    InfoType otherinfo; // 其他信息
} ElemType;
```

顺序表的定义如下：

```C{.line-numbers}
typedef struct
{
    ElemType *R; // 存储空间基地址
    int length; // 当前长度
} SSTable;
```

在此假设元素从`ST.R[1]`开始顺序向后存放，`ST.R[0]`闲置不用，查找时从表的最后开始比较。

> **算法 7.1**&nbsp;&nbsp;&nbsp;&nbsp;顺序查找

```C{.line-numbers}
// 在顺序表 ST 中查找关键字等于 key 的数据元素
// 若找到，返回该元素在表中的位置，否则返回 0
int Search_Seq(SSTable ST, KeyType key)
{
    for (int i = ST.length; i >= 1; i--)
    {
        if (ST.R[i].key == key)
            return i;
    }
    return 0;
}
```

算法 7.1 在查找过程中每步都要检测整个表是否查找完毕，即每步都要有循环变量是否满足条件`i >= 1`的检测。改进这个程序，可以免去这个检测过程。改进方法是，查找之前先将给定值`key`保存到`ST.R[0]`的关键字中，在此，`ST.R[0]`起到了监视哨的作用，如算法 7.2 所示。

> **算法 7.2**&nbsp;&nbsp;&nbsp;&nbsp;设置监视哨的顺序查找

```C{.line-numbers}
int Search_Seq(SSTable ST, KeyType key)
{
    ST.R[0].key = key; // 哨兵
    
    int i = ST.length;
    while (ST.R[i].key != key)
    {
        i--;
    }
    return i;
}
```

算法 7.2 仅是一个程序设计技巧上的改进，即通过设置监视哨，免去查找过程中每一步都要检测整个表是否查找完毕。实践证明，在顺序表的长度大于 1000 时，这个改进能使一次顺序查找所需的平均时间几乎减少一半。监视哨也可以设在高下标处。

算法 7.2 和算法 7.1 的时间复杂度一样，平均查找长度为

$$
ASL=\dfrac{1}{n}\sum_{i=1}^n i=\dfrac{n+1}{2}
$$

时间复杂度为 $O(n)$。

顺序查找的优点：算法简单，对表结构无任何要求，既适用于顺序结构，也适用于链式结构，无论记录是否按关键字有序均可应用。

顺序查找的缺点：平均查找长度较大，查找效率较低。当 $n$ 很大时，不宜采用顺序查找。

### 7.2.2 折半查找

**折半查找**（binary search）也称**二分查找**，要求线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。下面假设有序表是递增的。

折半查找的过程：从表的中间记录开始，如果给定值和中间记录的关键字相等，则查找成功；如果给定值大于或小于中间记录的关键字，则在表中大于或小于中间记录的那一半中查找，这样重复操作，直到查找成功，或者在某一步中查找区间为空，则代表查找失败。

为了标记查找过程中每一次的查找区间，分别用`low`和`high`表示当前查找区间的下界和上界，`mid`为区间的中间位置。

> **算法 7.3**&nbsp;&nbsp;&nbsp;&nbsp;折半查找
>
> 1. 置查找区间初值，`low`为 1，`high`为表长。
> 2. 当`low <= high`时，循环执行以下操作：
>   （1）`mid`取值为`low`和`high`的中间值。
>   （2）将给定值`key`与中间位置记录的关键字进行比较，若相等则查找成功，返回中间位置`mid`；若不相等则利用中间位置记录将表分成前、后两个子表，如果`key`比中间记录的关键字小，则`high`取为`mid - 1`，否则`low`取为`high + 1`。
> 3. 循环结束，说明查找区间为空，则查找失败，返回 0。

```C{.line-numbers}
int Search_Bin(SSTable ST, KeyType key)
{
    int low = 1;
    int high = ST.length;
    while (low <= high)
    {
        int mid = (low + high) / 2;
        if (key == ST.R[mid].key)
            return mid;
        else if (key < ST.R[mid].key)
            high = mid - 1;
        else
            low = mid + 1;
    }

    return 0; // 表中不存在待查元素
}
```

注意：循环条件是`low <= high`，而不是`low < high`。因为`low == high`时，查找区间还有一个结点，还要进一步比较。

折半查找过程可用二叉树来描述，树中每个结点对应表中一个记录，结点值是记录在表中的位置序号。把当前查找区间的中间位置作为根，左子表和右子表分别作为根的左子树和右子树，由此得到的二叉树称为折半查找的**判定树**。

例如，有序表为 (5, 16, 20, 27, 30, 36, 44, 55, 60, 67, 71)，其判定树如图 7.1 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.1-%E5%88%A4%E5%AE%9A%E6%A0%91.png">
    <br>
    图 7.1&nbsp;&nbsp;&nbsp;&nbsp;判定树
</div>

在判定树中所有结点的空指针域上加一个指向方形结点的指针，称这些方形结点为判定树的外部结点；与之相对，称圆形结点为内部结点。

从判定树可见，成功的折半查找恰好走了一条从判定树的根到被查结点的路径，经历比较的关键字个数恰为该结点在树中的层次。由此可见，折半查找在查找成功时进行比较的关键字个数最多不超过树的深度。而判定树的形态只与表记录个数 $n$ 相关，而与关键字的取值无关。具有 $n$ 个结点的判定树的深度为 $\lfloor\log_2 n\rfloor+1$，所以，对于长度为 $n$ 的有序表，折半查找在查找成功时和给定值进行比较的关键字个数至多为 $\lfloor\log_2 n\rfloor+1$。

折半查找时查找失败的过程就是走了一条从根结点到外部结点的路径，和给定值进行比较的关键字个数等于该路径上的内部结点个数。因此，折半查找在查找失败时和给定值进行比较的关键字个数最多也不超过 $\lfloor\log_2 n\rfloor+1$。

借助于判定树，可以求得折半查找的平均查找长度。假定有序表的长度为 $n=2^h-1$，则判定树是深度为 $h=\log_2(n+1)$ 的满二叉树，树中层次为 $i$ 的结点有 $2^{i-1}$ 个。假设表中每个记录的查找概率相等，则查找成功时折半查找的平均查找长度为

$$
\tag{7-2}
\begin{aligned}
    ASL&=\sum_{i=1}^n P_i C_i\\
    &=\dfrac{1}{n}\sum_{j=1}^h j\cdot 2^{j-1}\\
    &=\dfrac{n+1}{n}\log_2(n+1)-1
\end{aligned}
$$

当 $n$ 较大时，有下列近似结果

$$
\tag{7-3} ASL=\log_2(n+1)-1
$$

因此，折半查找的时间复杂度为 $O(\log_2 n)$。

折半查找的优点：比较次数少，查询效率高。

折半查找的缺点：

1. 对表结构要求较高，只能用于顺序存储的有序表。
2. 查找前需要排序，而排序是一种费时的运算。
3. 为了保持顺序表的有序性，对有序表进行插入和删除时，平均比较和移动表中一半元素，这也是一种费时的操作。因此，折半查找不适用于数据元素经常变动的线性表。

### 7.2.3 分块查找

**分块查找**（blocking search）又称**索引顺序查找**，这是一种性能介于顺序查找和折半查找之间的查找方法。在此查找法中，除表本身以外，还要建立一个“索引表”。例如，图 7.2 所示为一个表及其索引表。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.2-%E8%A1%A8%E5%8F%8A%E5%85%B6%E7%B4%A2%E5%BC%95%E8%A1%A8.png">
    <br>
    图 7.2&nbsp;&nbsp;&nbsp;&nbsp;表及其索引表
</div>

将整个表分成若干子表，对每个子表（或称块）建立一个索引项，其中包括两项内容：关键字项，其值为该子表内的最大关键字；指针项，指示该子表的第一个记录在表中的位置。

索引表按关键字有序，则表或者有序，或者分块有序。所谓“分块有序”指的是第二个子表中所有记录的关键字均大于第一个子表中的最大关键字，第三个子表中所有记录的关键字均大于第二个子表中的最大关键字，以此类推。

分块查找分两步进行，先确定待查记录所在的块（子表），然后在块中顺序查找。由于由索引项组成的索引表按关键字有序，则确定块的查找可以用顺序查找，也可以用折半查找；而块中记录是任意排列的，则在块中只能顺序查找。因此，分块查找算法为顺序查找和折半查找两种算法的简单合成。

分块查找的平均查找长度为

$$
\tag{7-4} ASL_{\text{bs}}=L_b+L_w
$$

其中，$L_b$ 为查找索引表确定所在块的平均查找长度，$L_w$ 为在块中查找元素的平均查找长度。

一般情况下，为进行分块查找，可以将长度为 $n$ 的表均匀地分成 $b$ 块，每块含有 $s$ 个记录，即 $b=\Big\lceil\dfrac{n}{s}\Big\rceil$。假定表中每个记录的查找概率相等，则每块查找的概率为 $\dfrac{1}{b}$，块中每个记录的查找概率为 $\dfrac{1}{s}$。若用顺序查找确定所在块，则分块查找的平均查找长度为

$$
\tag{7-5}
\begin{aligned}
    ASL_{\text{bs}}&=L_b+L_w\\
    &=\dfrac{1}{b}\sum_{j=1}^b j+\dfrac{1}{s}\sum_{i=1}^s i\\
    &=\dfrac{b+1}{2}+\dfrac{s+1}{2}\\
    &=\dfrac{1}{2}\Big(\dfrac{n}{s}+s\Big)+1
\end{aligned}
$$

此时的平均查找长度不仅和表长 $n$ 有关，而且和每一块中的记录个数 $s$ 有关。可以证明，当 $s=\sqrt{n}$ 时，$ASL_{\text{bs}}$ 取得最小值 $\sqrt{n}+1$。这个值比顺序查找有了很大改进，但远不如折半查找。

若用折半查找确定所在块，则分块查找的平均查找长度为

$$
\tag{7-6} ASL_{\text{bs}}'\approx \log_2\Big(\dfrac{n}{s}+1\Big)+\dfrac{s}{2}
$$

分块查找的优点：在表中插入和删除数据元素时，只要找到该元素对应的块，就可以在该块内进行插入和删除操作。由于块内是无序的，故插入和删除比较容易，无需进行大量移动。如果线性表既要快速查找又经常动态变化，则可采用分块查找。

分块查找的缺点：要增加一个索引表的存储空间并对初始索引表进行排序运算。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E9%A1%BA%E5%BA%8F%E6%9F%A5%E6%89%BE%E3%80%81%E6%8A%98%E5%8D%8A%E6%9F%A5%E6%89%BE%E5%92%8C%E5%88%86%E5%9D%97%E6%9F%A5%E6%89%BE%E7%9A%84%E6%AF%94%E8%BE%83.png">
</div>

## 7.3 树表的查找

前面的 3 种查找方法都是用线性表作为查找表的组织形式，当表的插入或删除操作频繁时，需要移动表中很多记录。所以，线性表的查找更适用于静态查找表。若要对动态查找表进行高效率的查找，可采用几种特殊的二叉树作为查找表的组织形式，在此将它们统称为树表。

### 7.3.1 二叉排序树

#### 7.3.1.1 二叉排序树的定义

**二叉排序树**（Binary Sort Tree）又称**二叉查找树**，它是一种对排序和查找都很有用的特殊二叉树。

二叉排序树或者是一棵空树，或者是具有下列性质的二叉树：

1. 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值。
2. 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值。
3. 它的左、右子树也分别为二叉排序树。

二叉排序树是递归定义的。从定义可以得出二叉排序树的一个重要性质：中序遍历一棵二叉排序树可以得到一个结点值递增的有序序列。

二叉排序树的二叉链表存储表示如下所示：

```C{.line-numbers}
typedef struct
{
    KeyType key; // 关键字
    InfoType otherinfo; // 其他数据
} ElemType;

typedef struct BSTNode
{
    ElemType data;
    struct BSTNode *lchild; // 左指针
    struct BSTNode *rchild; // 右指针
} BSTNode, *BSTree;
```

#### 7.3.1.2 二叉排序树的查找

> **算法 7.4**&nbsp;&nbsp;&nbsp;&nbsp;二叉排序树的递归查找
>
> - 若二叉排序树为空，则查找失败，返回空指针。
> - 若二叉排序树非空，将给定值`key`与根结点的关键字`T->data.key`进行比较：
>   - 若`key == T->data.key`，则查找成功，返回根结点地址；
>   - 若`key < T->data.key`，则递归查找左子树；
>   - 若`key > T->data.key`，则递归查找右子树。

```C{.line-numbers}
BSTree SearchBST(BSTree T, KeyType key)
{
    if (!T || key == T->data.key) // 二叉树为空，或根结点的关键字与给定值相等，直接返回
        return T;
    else if (key < T->data.key)
        return SearchBST(T->lchild, key); // 给定值小于根结点的关键字，在左子树中继续查找
    else
        return SearchBST(T->rchild, key); // 给定值大于根结点的关键字，在右子树中继续查找
}
```

在二叉排序树上查找关键字等于给定值的结点的过程，恰是走了一条从根结点到该结点的路径，和给定值比较的关键字个数等于路径长度加 1，因此与给定值比较的关键字个数不超过树的深度。然而，含有 $n$ 个结点的二叉排序树并不唯一，其平均查找长度和树的形态有关。最差情况下，二叉排序树退化为单支树，深度为 $n$，平均查找长度为 $\dfrac{n+1}{2}$，时间复杂度为 $O(n)$，与顺序查找相同；最好情况下，二叉排序树的形态和折半查找的判定树相似，时间复杂度为 $O(\log_2 n)$。可以证明，综合所有可能的情况，平均时间复杂度为 $O(\log_2 n)$。

可见，二叉排序树上的查找和折半查找相差不大。但就维护表的有序性而言，二叉排序树更加有效，因为无须移动记录，只需修改指针即可完成对结点的插入和删除操作。因此，对于需要经常进行插入、删除和查找操作的表，采用二叉排序树比较好。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8A%98%E5%8D%8A%E6%9F%A5%E6%89%BE%E5%92%8C%E4%BA%8C%E5%8F%89%E6%8E%92%E5%BA%8F%E6%A0%91%E6%9F%A5%E6%89%BE%E7%9A%84%E6%AF%94%E8%BE%83.png">
</div>

#### 7.3.1.3 二叉排序树的插入

二叉排序树的插入操作是以查找为基础的。要将一个关键字为`key`的结点插入到二叉排序树中，需要从根结点向下查找，当树中不存在关键字等于`key`的结点时才进行插入。新插入的结点一定是一个新添加的叶结点，而且是查找不成功时查找路径上访问的最后一个结点的左孩子或右孩子结点。

> **算法 7.5**&nbsp;&nbsp;&nbsp;&nbsp;二叉排序树的插入
>
> - 若二叉排序树为空，则待插入结点`*S`作为根结点插入到空树中。
> - 若二叉排序树非空，则将`key`与根结点的关键字`T->data.key`进行比较：
>   - 若`key < T->data.key`，则将`*S`插入左子树。
>   - 若`key > T->data.key`，则将`*S`插入右子树。

```C++{.line-numbers}
void InsertBST(BSTree &T, ElemType e)
{
    if (!T) // 找到插入位置
    {
        // 生成新结点
        BSTNode *S = new BSTNode;
        S->data = e;
        S->lchild = NULL;
        S->rchild = NULL;

        // 把新结点链接到插入位置
        T = S;
    }
    else if (e.key < T->data.key)
    {
        InsertBST(T->lchild, e); // 插入左子树
    }
    else
    {
        InsertBST(T->rchild, e); // 插入右子树
    }
}
```

二叉排序树插入的基本过程是查找，所以时间复杂度同查找一样，是 $O(\log_2 n)$。

#### 7.3.1.4 二叉排序树的创建

二叉排序树的创建是从空的二叉排序树开始的，每输入一个结点，经过查找操作，将新结点插入到当前二叉排序树的合适位置。

> **算法 7.6**&nbsp;&nbsp;&nbsp;&nbsp;二叉排序树的创建
>
> 1. 将二叉排序树`T`初始化为空树。
> 2. 读入一个关键字为`key`的结点。
> 3. 如果读入的关键字`key`不是输入结束标志，则循环执行以下操作：
>    （1）将此结点插入二叉排序树`T`中。
>    （2）读入下一个关键字为`key`的结点。

```C++{.line-numbers}
void CreateBST(BSTree &T)
{
    T = NULL;
    ElemType e;

    cin >> e;
    while (e.key != ENDFLAG)
    {
        InsertBST(T, e);
        cin >> e;
    }
}
```

假设有 $n$ 个结点，需要 $n$ 次插入操作，而插入一个结点的时间复杂度为 $O(\log_2 n)$，所以创建二叉排序树的时间复杂度为 $O(n\log_2 n)$。

一个无序序列可以通过构造一棵二叉排序树而变成一个有序序列，构造树的过程即为对无序序列进行排序的过程，这称为二叉排序树的顺序属性。在创建过程中，每次插入的新结点都是二叉排序树上新的叶子结点，则在进行插入操作时，不必移动其他结点，仅需改动某个结点的指针，由空变为非空即可，这就相当于在一个有序序列上插入一个记录而不需要移动其他记录。

二叉排序树会因输入文件所包含记录的关键词序列的不同而有不同的形态。对包含 $n$ 个记录的集合，其对应的关键词有 $n!$ 种不同的排列，可构成 $\dfrac{C^n_{2n}}{n+1}$ 个不同的二叉排序树。

#### 7.3.1.5 二叉排序树的删除

删除二叉排序树中的结点时，要根据被删结点的位置修改其双亲结点及相关结点的指针，以保持二叉排序树的特性。假设被删结点为`*p`，其双亲结点为`*f`，$\text{P}_{\text{L}}$ 和 $\text{P}_{\text{R}}$ 分别表示`*p`的左子树和右子树，如图 7.3(a) 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.3-%E4%BA%8C%E5%8F%89%E6%8E%92%E5%BA%8F%E6%A0%91%E7%BB%93%E7%82%B9%E7%9A%84%E5%88%A0%E9%99%A4.png">
    <br>
    图 7.3&nbsp;&nbsp;&nbsp;&nbsp;二叉排序树结点的删除
</div>

不失一般性，可设`*p`是`*f`的左孩子（右孩子情况类似）。下面分 3 种情况进行讨论。

1. 若`*p`结点为叶子结点，即 $\text{P}_{\text{L}}$ 和 $\text{P}_{\text{R}}$ 是空树，则只需修改其双亲结点的指针即可：
`f->lchild = NULL;`
2. 若`*p`结点只有左子树 $\text{P}_{\text{L}}$ 或者只有右子树 $\text{P}_{\text{R}}$，此时只要令 $\text{P}_{\text{L}}$ 或 $\text{P}_{\text{R}}$ 直接成为其双亲结点`*f`的左子树即可：
`f->lchild = p->lchild;`或`f->lchild = p->rchild;`
3. 若`*p`结点的左子树和右子树均不空，从图 7.3(b) 可知，在删去`*p`结点之前，中序遍历该二叉树得到的序列为 $\cdots\text{C}_{\text{L}}\text{C}\cdots\text{Q}_{\text{L}}\text{QS}_{\text{L}}\text{SPP}_{\text{R}}\text{F}\cdots$。在删去`*p`后，为保持其他元素之间的相对位置不变，可以有两种处理方法：
   （1）令`*p`的左子树为`*f`的左子树，`*p`的右子树为`*s`的右子树，如图 7.3(c) 所示。
    ```C
    f->lchild = p->lchild;
    s->rchild = p->rchild;
    ```
   （2）令`*p`的直接前驱（或直接后继）替代`*p`，然后再从二叉排序树中删去它的直接前驱（或直接后继）。如图 7.3(d) 所示，当以直接前驱`*s`替代`*p`时，由于`*s`只有左子树 $\text{S}_{\text{L}}$，则在删去`*s`之后，只要令 $\text{S}_{\text{L}}$ 为`*s`的双亲`*q`的右子树即可。
前一种处理方法可能增加树的深度；而后一种方法是以被删结点左子树中关键字最大的结点替代被删结点，然后从左子树中删除这个结点，此结点一定没有右子树（否则它就不是左子树中关键字最大的结点），这样不会增加树的高度，所以常采用这种处理方案。

> **算法 7.7**&nbsp;&nbsp;&nbsp;&nbsp;二叉排序树的删除

```C++{.line-numbers}
void DeleteBST(BSTree &T, KeyType key)
{
    // 从根结点开始，查找关键字等于 key 的结点，p 指向被删结点
    BSTNode *p = T;
    BSTNode *f = NULL;
    while (p)
    {
        if (p->data.key == key) // 找到，结束循环
            break;
        
        f = p; // f 为 p 的双亲结点
        if (p->data.key > key)
            p = p->lchild;
        else
            p = p->rchild;
    }

    // 找不到被删结点则返回
    if (!p)
        return;
    
    BSTNode *q = NULL;
    BSTNode *s = NULL;
    
    // 找到被删结点，分 3 种情况处理
    if (p->lchild && p->rchild) // 左右子树都不空
    {
        // 在 *p 的左子树中查找其前驱结点，s 指向前驱结点
        q = p;
        s = p->lchild;
        while (s->rchild)
        {
            q = s;
            s = s->rchild;
        }

        // 用 *s 替代 *p，将 *s 直接复制到 *p
        p->data = s->data;

        if (q != p)
        {
            q -> rchild = s->lchild;
        }
        else // q == p，说明 s 是 p 的左孩子，将 s 的左子树作为 p 的左子树
        {
            q->lchild = s->lchild;
        }

        delete s; // 删除前驱结点
        return;
    }
    else if (!p->rchild) // 右子树为空
    {
        q = p;
        p = p->lchild;
    }
    else if (!p->lchild) // 左子树为空
    {
        q = p;
        p = p->rchild;
    }

    // 将 p 所指的子树挂接到其双亲结点 *f 相应的位置
    if (!f) // 被删结点为根结点
    {
        T = p;
    }
    else if (q == f->lchild) // 被删结点是 f 的左子树，将子树作为 f 的左子树
    {
        f->lchild = p;
    }
    else // 被删结点是 f 的右子树，将子树作为 f 的右子树
    {
        f->rchild = p;
    }

    delete q;
}
```

二叉排序树删除的基本过程是查找，所以时间复杂度为 $O(\log_2 n)$。

### 7.3.2 平衡二叉树

#### 7.3.2.1 平衡二叉树的定义

**平衡二叉树**（Balanced Binary Tree）也称为**高度平衡树**（Height-Balanced Tree），是一种特殊的二叉排序树，它可以保证二叉树的高度尽可能小，从而获得较好的查找性能。平衡二叉树由前苏联数学家 Adelson-Velskii 和 Landis 提出，所以又称 AVL 树。

平衡二叉树或者是空树，或者是具有如下特征的二叉排序树：

1. 左子树和右子树的深度之差的绝对值不超过 1。
2. 左子树和右子树也是平衡二叉树。

**平衡因子**（Balance Factor，BF）：结点的左子树和右子树的深度之差。

根据定义，平衡二叉树上所有结点的平衡因子只可能是 -1、0 和 1。只要二叉树上有一个结点的平衡因子的绝对值大于 1，则该二叉树就是不平衡的。

因为 AVL 树上任何结点的左右子树的深度之差都不超过 1，则可以证明它的深度和 $\log_2 n$ 是同数量级的，因此其查找的时间复杂度是 $O(\log_2 n)$。

#### 7.3.2.2 平衡二叉树的平衡调整方法

插入结点时，首先按照二叉排序树处理，若插入结点后破坏了平衡二叉树的特性，需对平衡二叉树进行调整。调整方法是：找到离插入结点最近且平衡因子绝对值超过 1 的祖先结点，以该结点为根的子树称为**最小不平衡子树**，可将重新平衡的范围局限于这棵子树。

假设最小不平衡子树的根结点为 A，则失去平衡后进行调整的规律可归纳为下列 4 种情况。

1. LL 型：由于在 A 的左子树根结点的左子树上插入结点，A 的平衡因子由 1 增至 2，致使以 A 为根的子树失去平衡，则需进行一次向右的顺时针旋转操作，如图 7.4 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.4-LL%E5%9E%8B%E8%B0%83%E6%95%B4%E6%93%8D%E4%BD%9C%E7%A4%BA%E6%84%8F%E5%9B%BE.png">
    <br>
    图 7.4&nbsp;&nbsp;&nbsp;&nbsp;LL 型调整操作示意图
</div>

2. RR 型：由于在 A 的右子树根结点的右子树上插入结点，A 的平衡因子由 -1 变成 -2，致使以 A 为根的子树失去平衡，则需进行一次向左的逆时针旋转操作，如图 7.5 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.5-RR%E5%9E%8B%E8%B0%83%E6%95%B4%E6%93%8D%E4%BD%9C%E7%A4%BA%E6%84%8F%E5%9B%BE.png">
    <br>
    图 7.5&nbsp;&nbsp;&nbsp;&nbsp;RR 型调整操作示意图
</div>

3. LR 型：由于在 A 的左子树根结点的右子树上插入结点，A 的平衡因子由 1 增至 2，致使以 A 为根的子树失去平衡，则需进行两次旋转操作。第一次对 B 及其右子树进行逆时针旋转，C 转上去成为 B 的根，这时变成了 LL 型，所以第二次进行 LL 型的顺时针旋转即可恢复平衡。如果 C 原来有左子树，则调整 C 的左子树为 B 的右子树，如图 7.6 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.6-LR%E5%9E%8B%E8%B0%83%E6%95%B4%E6%93%8D%E4%BD%9C%E7%A4%BA%E6%84%8F%E5%9B%BE.png">
    <br>
    图 7.6&nbsp;&nbsp;&nbsp;&nbsp;LR 型调整操作示意图
</div>

4. RL 型：由于在 A 的右子树根结点的左子树上插入结点，A 的平衡因子由 -1 变成 -2，致使以 A 为根的子树失去平衡，则旋转方法和 LR 型对称，也需进行两次旋转，先顺时针右旋，再逆时针左旋，如图 7.7 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.7-RL%E5%9E%8B%E8%B0%83%E6%95%B4%E6%93%8D%E4%BD%9C%E7%A4%BA%E6%84%8F%E5%9B%BE.png">
    <br>
    图 7.7&nbsp;&nbsp;&nbsp;&nbsp;RL 型调整操作示意图
</div>

上述 4 种情况中，1 和 2 对称，3 和 4 对称。无论哪一种情况，在经过平衡旋转处理后，以 B 或 C 为根的新子树为平衡二叉树，而且它们的深度和插入之前以 A 为根的子树相同。因此，当平衡二叉树因插入结点而失去平衡时，仅需对最小不平衡子树进行平衡旋转处理即可，因为经过旋转处理之后的子树深度和插入之前相同，因而不影响插入路径上所有祖先结点的平衡度。

#### 7.3.2.3 平衡二叉树的插入

在平衡二叉树`BBST`上插入一个新的数据元素`e`的递归算法可描述如下：

1. 若`BBST`为空树，则插入一个数据元素为`e`的新结点作为`BBST`的根结点，树的深度增 1。
2. 若`e`的关键字和`BBST`的根结点的关键字相等，则不进行插入。
3. 若`e`的关键字小于`BBST`的根结点的关键字，而且在`BBST`的左子树中不存在和`e`有相同关键字的结点，则将`e`插入到`BBST`的左子树。当插入之后的左子树深度增加时，分别就下列不同情况进行处理：
   - 若`BBST`的根结点的平衡因子为 -1，则将根结点的平衡因子改为 0，`BBST`的深度不变。
   - 若`BBST`的根结点的平衡因子为 0，则将根结点的平衡因子改为 1，`BBST`的深度增 1。
   - 若`BBST`的根结点的平衡因子为 1，再分两种情况：
     - 若`BBST`的左子树根结点的平衡因子为 1，则需进行单向右旋平衡处理，并且在右旋处理后，将根结点和其右子树根结点的平衡因子更改为 0，树的深度不变。
     - 若`BBST`的左子树根结点的平衡因子为 -1，则需进行先向左、后向右的双向旋转平衡处理，并且在旋转处理之后，修改根结点和其左、右子树根结点的平衡因子，树的深度不变。
4. 若`e`的关键字大于`BBST`的根结点的关键字，而且在`BBST`的右子树中不存在和`e`有相同关键字的结点，则将`e`插入到`BBST`的右子树。当插入之后的右子树深度增加时，分别就不同情况进行处理，其处理操作和 3 中所述相对称。

### 7.3.3 B-树

#### 7.3.3.1 B-树的定义

一棵 $m$ 阶的 B-树，或为空树，或为满足下列特性的 $m$ 叉树：

1. 树中每个结点至多有 $m$ 棵子树。
2. 若根结点不是叶子结点，则至少有两棵子树。
3. 除根结点之外所有非终端结点至少有 $\Big\lceil \dfrac{m}{2}\Big\rceil$ 棵子树。
4. 所有的叶子结点都出现在同一层次上，并且不带信息，称为失败结点。（失败结点并不存在，指向这些结点的指针为空。引入失败结点是为了便于分析 B-树的查找性能）
5. 所有的非终端结点最多有 $m-1$ 个关键字，结点的结构如图 7.8 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.8-B-%E6%A0%91%E7%9A%84%E7%BB%93%E7%82%B9%E7%BB%93%E6%9E%84.png">
    <br>
    图 7.8&nbsp;&nbsp;&nbsp;&nbsp;B-树的结点结构
</div>

其中，$K_i\,(i=1,\cdots,n)$ 为关键字，且 $K_i<K_{i+1}\,(i=1,\cdots,n-1)$；$P_i\,(i=0,\cdots,n)$ 为指向子树根结点的指针，且指针 $P_{i-1}$ 所指子树中所有结点的关键字均小于 $K_i\,(i=1,\cdots,n)$，$P_n$ 所指子树中所有结点的关键字均大于 $K_n$；$n\,(\Big\lceil\dfrac{m}{2}\Big\rceil-1\leqslant n\leqslant m-1)$ 为关键字的个数，$n+1$ 为子树个数。

对任一关键字 $K_i$ 而言，$P_{i-1}$ 相当于指向其“左子树”，$P_i$ 相当于指向其“右子树”。

B-树具有平衡、有序、多路的特点，具体来说：

1. 平衡：所有叶子结点均在同一层次。
2. 有序：树中每个结点中的关键字都是有序的，且关键字 $K_i$“左子树”中的关键字均小于 $K_i$，而“右子树”中的关键字均大于 $K_i$。
3. 多路：不同结点中的关键字个数不同，子树个数也不同。$m$ 阶 B-树的结点最多有 $m-1$ 个关键字、$m$ 棵子树。

在具体实现时，为记录双亲结点，B-树结点的存储结构通常增加一个`parent`指针，指向其双亲结点。存储结构如图 7.9 所示。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE7.9-B-%E6%A0%91%E7%BB%93%E7%82%B9%E7%9A%84%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png">
    <br>
    图 7.9&nbsp;&nbsp;&nbsp;&nbsp;B-树结点的存储结构
</div>

#### 7.3.3.2 B-树的查找

B-树结点类型定义如下：

```C{.line-numbers}
#define m 3 // B-树的阶，暂设为 3

// B-树结点和 B-树的类型
typedef struct BTNode
{
    int keynum; // 结点中关键字的个数
    struct BTNode* parent; // 双亲结点
    KeyType key[m + 1]; // 关键字向量，0 号单元未用
    struct BTNode* ptr[m + 1]; // 子树指针向量
    Record* recptr[m + 1]; // 记录指针向量，0 号单元未用
} BTNode, *BTree;

// B-树的查找结果类型
typedef struct
{
    BTNode *pt; // 指向找到的结点
    int i; // 结点中的关键字序号
    int tag; // 1 表示查找成功，0 表示查找失败
} Result;
```

> **算法 7.8**&nbsp;&nbsp;&nbsp;&nbsp;B-树的查找
>
> 将给定值 $key$ 与根结点的各个关键字 $K_1,K_2,\cdots,K_j\,(1\leqslant j\leqslant m-1)$ 进行比较，由于该关键字序列是有序的，所以查找时可采用顺序查找，也可采用折半查找。查找时：
>
> - 若 $key=K_i\,(1\leqslant i\leqslant j)$，则查找成功；
> - 若 $key<K_1$，则顺着指针 $P_0$ 所指向的子树继续向下查找；
> - 若 $K_i<key<K_{i+1}\,(1\leqslant i\leqslant_{j-1})$，则顺着指针 $P_i$ 所指向的子树继续向下查找；
> - 若 $key>K_j$，则顺着指针 $P_j$ 所指向的子树继续向下查找。
>
> 如果在自上而下的查找过程中，找到了值为 $key$ 的关键字，则查找成功；如果直到叶子结点也未找到，则查找失败。

```C{.line-numbers}
// 在 m 阶 B-树 T 上查找关键字 key，返回结果 (pt, i, tag)
// 若查找成功，则 tag 为 1，指针 pt 所指结点中第 i 个关键字等于 key
// 否则 tag 为 0，关键字 key 应插入在指针 pt 所指结点中序号为 i 和 i+1 的关键字之间
Result SearchBTree(BTree T, KeyType key)
{
    // 初始化
    BTNode *p = T; // p 指向待查结点
    BTNode *q = NULL; // q 指向 p 的双亲
    bool found = false;
    int i = 0;

    while (p && !found)
    {
        // 在 p->key 数组中查找，使得 p->key[i] <= key < p->key[i + 1]
        i = Search(p, key);

        if (i > 0 && p->key[i] == key) // 找到待查关键字
        {
            found = true;
        }
        else // 向下查找
        {
            q = p;
            p = p->ptr[i];
        }
    }

    if (found)
        return (p, i, 1); // 查找成功
    else
        return (q, i, 0); // 查找失败，返回 key 的插入位置
}
```

在 B-树上进行查找包含两种基本操作：在 B-树中找结点、在结点中找关键字。由于 B-树通常存储在磁盘上，则前一查找操作是在磁盘上进行的，而后一查找操作是在内存中进行的，即在磁盘上找到指针`p`所指结点后，先将结点读入内存，然后再利用顺序查找或折半查找查询关键字。在磁盘上进行一次查找比在内存中进行一次查找耗费时间更多，因此，在磁盘上进行查找的次数，即待查关键字所在结点在 B-树上的层次数，是决定 B-树查找效率的首要因素。

首先计算深度为 $h+1$ 的 $m$ 阶 B-树所具有的最少结点数。根据 B-树的定义，第一层至少有 1 个结点，第二层至少有 2 个结点；由于除根之外的每个非终端结点至少有 $\Big\lceil\dfrac{m}{2}\Big\rceil$ 棵子树，则第三层至少有 $2\Big\lceil\dfrac{m}{2}\Big\rceil$ 个结点；以此类推，第 $h+1$ 层至少有 $2\Big\lceil\dfrac{m}{2}\Big\rceil^{h-1}$ 个结点，而 $h+1$ 层的结点为叶子结点。若 $m$ 阶 B-树中有 $N$ 个关键字，则叶子结点的个数为 $N+1$，由此有

$$
N+1\geqslant 2\Big\lceil\dfrac{m}{2}\Big\rceil^{h-1}
$$

解得

$$
h\leqslant\log_{\lceil\frac{m}{2}\rceil}\Big(\dfrac{N+1}{2}\Big)+1
$$

因此，在含有 $N$ 个关键字的 B-树上进行查找时，从根结点到关键字所在结点的路径上涉及的结点数不超过 $\log_{\lceil\frac{m}{2}\rceil}\Big(\dfrac{N+1}{2}\Big)+1$。

#### 7.3.3.3 B-树的插入

B-树是动态查找树，因此其生成过程是从空树起，在查找的过程中通过逐个插入关键字而得到。

每次插入一个关键字时，首先将关键字添加到最低层的某个非终端结点中，若该结点的关键字个数不超过 $m-1$，则插入完成；否则表明结点已满，要产生结点的分裂，将此结点在同一层分成两个结点。

结点分裂方法：以中间关键字为界把结点一分为二，成为两个结点，并把中间关键字向上插入到双亲结点上。若双亲结点已满，则采用同样的方法继续分解。最坏情况下，一直分解到根结点，B-树高度增加 1。

> **算法 7.9**&nbsp;&nbsp;&nbsp;&nbsp;B-树的插入
>
> 1. 在 B-树中查找给定关键字的记录，若查找成功，则插入操作失败；否则将新纪录作为空指针`p`插入到查找失败的叶子结点的上一层结点（由`q`指向）中。
> 2. 若插入新纪录和空指针后，`q`指向的结点的关键字个数未超过 $m-1$，则插入操作成功，否则转步骤 3。
> 3. 以该结点的第 $\Big\lceil\dfrac{m}{2}\Big\rceil$ 个关键字 $K_{\lceil\frac{m}{2}\rceil}$ 为拆分点，将该结点分成 3 个部分：$K_{\lceil\frac{m}{2}\rceil}$ 左边部分、$K_{\lceil\frac{m}{2}\rceil}$、$K_{\lceil\frac{m}{2}\rceil}$ 右边部分。$K_{\lceil\frac{m}{2}\rceil}$ 左边部分仍然保留在原结点中，$K_{\lceil\frac{m}{2}\rceil}$ 右边部分存放在一个新创建的结点（由`p`指向）中，$K_{\lceil\frac{m}{2}\rceil}$ 的记录和指针`p`插入到`q`的双亲结点中。因`q`的双亲结点增加一个新的记录，所以必须对`q`的双亲结点重复 2 和 3 的操作，以此类推，直至由`q`指向的结点是根结点，转步骤 4。
> 4. 由于根结点无双亲，则由其分裂产生的两个结点的指针`p`和`q`，以及关键字为 $K_{\lceil\frac{m}{2}\rceil}$ 的记录构成一个新的根结点。此时，B-树的高度增加 1。

```C{.line-numbers}
// 在 m 阶 B-树 T 上结点 *q 的 key[i] 与 key[i + 1] 之间插入关键字 K
// q 和 i 由查找函数 SearchBTree 返回的信息而得
Status InsertBTree(BTree &T, KeyType K, BTree q, int i)
{
    KeyType x = K; // 当前待插入的关键字
    BTNode *p = NULL;
    bool finished = false;

    while (q && !finished)
    {
        Insert(q, i, x, p); // 将 x 和 p 分别插入到 q->key[i+1] 和 q->ptr[i+1]

        if (q->keynum < m)
        {
            finished = true; // 插入完成
        }
        else
        {
            int s = ceil(m / 2); // 拆分点
            split(q, s, p); // 拆分，将拆分点右侧部分移入新结点 *p

            x = q->key[s]; // 拆分点上的记录作为新的待插入关键字，插入到双亲结点中
            q = q->parent;
            if (q)
            {
                i = Search(q, x); // 在双亲结点中查找 x 的插入位置
            }
        }
    }

    if (!finished) // T 是空树，或者根结点已分裂为结点 *q 和 *p
    {
        NewRoot(T, q, x, p); // 生成含信息 (T, x, p) 的新结点 *T，原 T 和 p 为子树指针
    }
    return OK;
}
```

#### 7.3.3.4 B-树的删除

$m$ 阶 B-树的删除操作是在 B-树的某个结点中删除指定的关键字及其邻近的一个指针。若删除记录后结点的关键字个数小于 $\Big\lceil\dfrac{m}{2}\Big\rceil-1$，则要进行合并结点的操作。

除了删除记录，还要删除该记录邻近的指针。若该结点为最下层的非终端结点，由于其指针均为空，删除后不会影响其他结点，可直接删除；若该结点不是最下层的非终端结点，则邻近的指针指向一棵子树，不可直接删除，此时可做如下处理：将要删除记录用其右（左）边邻近指针指向的子树中关键字最小（大）的记录（该记录必定在最下层的非终端结点中）替换。采取这种方法进行处理，无论要删除的记录所在的结点是否为最下层的非终端结点，都可归结为在最下层的非终端结点中删除记录的情况。

删除最下层非终端结点中的关键字时，有以下 3 种可能：

1. 被删关键字所在结点中的关键字数目不小于 $\Big\lceil\dfrac{m}{2}\Big\rceil$，则只需从该结点中删去该关键字 $K_i$ 和相应指针 $P_i$，树的其他部分不变。
2. 被删关键字所在结点中的关键字数目等于 $\Big\lceil\dfrac{m}{2}\Big\rceil-1$，而与该结点相邻的右兄弟（或左兄弟）结点中的关键字数目大于 $\Big\lceil\dfrac{m}{2}\Big\rceil-1$，则需将其兄弟结点中的最小（或最大）的关键字上移至双亲结点中，而将双亲结点中小于（或大于）且紧靠该上移关键字的关键字下移至被删关键字所在结点中。
3. 被删关键字所在结点及其兄弟结点中的关键字数目均等于 $\Big\lceil\dfrac{m}{2}\Big\rceil-1$。假设该结点有右兄弟，且其右兄弟结点由双亲结点中的指针 $P_i$ 所指，则在删去关键字之后，它所在结点中剩余的关键字和指针，加上双亲结点中的关键字 $K_i$ 一起，合并到 $P_i$ 所指兄弟结点中；若没有右兄弟，则合并到左兄弟结点中。

### 7.3.4 B+树

B+树是一种 B-树的变形树，更适合于文件索引系统。

B+树的特点：

1. 有 $n$ 棵子树的结点中含有 $n$ 个关键字。
2. 所有的叶子结点中包含了全部关键字的信息，以及指向含这些关键字记录的指针，且叶子结点本身按照关键字的大小从小到大顺序链接。
3. 所有的非终端结点可以看成是索引部分，结点中仅含有其子树（根结点）中的最大（或最小）关键字。

通常在 B+树上有两个头指针，一个指向根结点，另一个指向关键字最小的叶子结点。因此，可以对 B+树进行两种查找运算：一种是从最小关键字开始顺序查找，另一种是从根结点开始随机查找。

B+树的查找：若非终端结点上的关键字等于给定值，并不终止，而是继续向下直到叶子结点。因此，在 B+树中，不管查找成功与否，每次查找都是走了一条从根到叶子结点的路径。

B+树不仅能够有效地查找单个关键字，而且更适合查找某个范围内的所有关键字。例如，在 B+树上找出范围在 $[a,b]$ 之间的所有关键字值，处理方法如下：通过一次查找找出关键字 $a$，不管它是否存在，都可以到达可能出现 $a$ 的叶子结点，然后在叶子结点中查找关键字值等于或大于 $a$ 的那些关键字。如果在当前结点中没有发现大于 $b$ 的关键字，就使用当前叶子结点的最后一个指针找到下一个叶子结点，并继续进行同样的处理，直至在某个叶子结点中找到大于 $b$ 的关键字为止。

B+树的插入：仅在叶子结点上进行插入。当结点中的关键字个数大于 $m$ 时要分裂成两个结点，它们所含关键字的个数分别为 $\Big\lfloor\dfrac{m+1}{2}\Big\rfloor$ 和 $\Big\lceil\dfrac{m+1}{2}\Big\rceil$，并且它们的双亲结点中应同时包含这两个结点中的最大关键字。

B+树的删除：仅在叶子结点上进行删除。当叶子结点中最大关键字被删除时，其在非终端结点中的值可以作为一个“分界关键字”存在。若因删除而使结点中关键字的个数少于 $\Big\lceil\dfrac{m}{2}\Big\rceil$，其与兄弟结点的合并过程和 B-树类似。

## 7.4 散列表的查找

### 7.4.1 散列表的基本概念

**散列查找法**（Hash Search）的思想：对元素的关键字值进行某种运算，直接求出元素的地址。

散列查找法又叫**杂凑法**或**散列法**。

散列法中的常用术语：

1. 散列函数和散列地址：在记录的存储位置 $p$ 和其关键字 $k$ 之间建立一个确定的对应关系 $H$，使 $p=H(k)$，称这个对应关系 $H$ 为**散列函数**，$p$ 为**散列地址**。
2. **散列表**：一个有限连续的地址空间，用于存储按散列函数计算得到相应散列地址的数据记录。通常散列表的存储空间是一个一维数组，散列地址是数组的下标。
3. 冲突和同义词：对不同的关键字可能得到同一散列地址，即 $k_1\not=k_2$，而 $H(k_1)=H(k_2)$，这种现象称为**冲突**。具有相同函数值的关键字对该散列函数来说称作**同义词**，$k_1$ 与 $k_2$ 互称为同义词。

散列查找法主要研究以下两方面的问题：

1. 如何构造散列函数。
2. 如何处理冲突。

### 7.4.2 散列函数的构造方法

构造散列函数时要考虑以下因素：

1. 散列表的长度
2. 关键字的长度
3. 关键字的分布情况
4. 计算散列函数所需的时间
5. 记录的查找频率

构造一个好的散列函数应遵循以下原则：

1. 函数计算要简单，每一关键字只能有一个散列地址与之对应。
2. 函数的值域要在表长的范围内，计算出的散列地址应分布均匀，尽可能减少冲突。

#### 7.4.2.1 数字分析法

如果事先知道关键字集合，且每个关键字的位数比散列表的地址码位数多（如关键字 $k_1k_2\cdots k_n$ 由 $n$ 位数组成），则可以从关键字中提取数字分布比较均匀的若干位作为散列地址。

数字分析法的适用情况：事先必须明确知道所有的关键字每一位上各种数字的分布情况。

#### 7.4.2.2 平方取中法

通常在选定散列函数时不一定能知道关键字的全部情况，取其中哪几位也不一定合适。而一个数平方后的中间几位数和数的每一位都相关，如果取关键字平方后的中间几位或其组合作为散列地址，则使随机分布的关键字得到的散列地址也是随机的，具体所取的位数由表长决定。

平方取中法的适用情况：不能事先了解关键字的所有情况，或难于直接从关键字中找到取值较分散的几位。

#### 7.4.2.3 折叠法

折叠法：将关键字分割成位数相同的几部分（最后一部分的位数可以不同），然后取这几部分的叠加和（舍去进位）作为散列地址。

根据数位叠加的方式，可以把折叠法分为移位叠加和边界叠加两种。

1. 移位叠加：将分割后每一部分的最低位对齐，然后相加。
2. 边界叠加：将两个相邻的部分沿边界来回折叠，然后对齐相加。

折叠法的适用情况：散列地址的位数较少，而关键字的位数较多，且难于直接从关键字中找到取值较分散的几位。

#### 7.4.2.4 除留余数法

假设散列表表长为 $m$，选择一个不大于 $m$ 的数 $p$，用 $p$ 去除关键字，除后所得余数为散列地址。即

$$
H(k)=k \bmod p
$$

除留余数法的关键是选取适当的 $p$。一般情况下，可以选 $p$ 为小于表长的最大质数。

除留余数法计算简单，适用范围非常广，是最常用的构造散列函数的方法。它不仅可以对关键字直接取模，也可以在折叠、平方取中等运算之后取模，这样能够保证散列地址一定落在散列表的地址空间中。

### 7.4.3 处理冲突的方法

#### 7.4.3.1 开放地址法

开放地址法的基本思想：把记录都存储在散列表数组中，当某一记录关键字 $k$ 的初始散列地址 $H_0=H(k)$ 发生冲突时，以 $H_0$ 为基础，采取合适方法计算得到另一个地址 $H_1$，如果 $H_1$ 仍然发生冲突，则以 $H_1$ 为基础再求下一个地址 $H_2$，以此类推，直至 $H_n$ 不发生冲突为止，则 $H_n$ 为该记录在表中的散列地址。

这种方法在寻找下一个空的散列地址时，原来的数组空间对所有的元素都是开放的，所以称为开放地址法。通常把寻找下一个空位的过程称为**探测**，上述方法可用如下公式表示：

$$
H_i=(H(k)+d_i)\bmod m \quad i=1,2,\cdots,n\,(n\leqslant m-1)
$$

其中，$H(k)$ 为散列函数，$m$ 为散列表表长，$d_i$ 为增量序列。根据 $d_i$ 取值的不同，可以分为以下 3 种探测方法。

1. 线性探测法

$$
d_i=1,2,3,\cdots,m-1
$$

这种探测方法可以将散列表假想成一个循环表，发生冲突时，从冲突地址的下一单元顺序寻找空单元，如果到最后一个位置也没找到空单元，则回到表头开始继续查找，直到找到一个空位，就把此元素放入此空位中。如果找不到空位，则说明散列表已满，需要进行溢出处理。

2. 二次探测法

$$
d_i=1^2,-1^2,2^2,-2^2,3^2,\cdots,k^2,-k^2\,(k\leqslant\dfrac{m}{2})
$$

3. 伪随机探测法

$$
d_i=伪随机数序列
$$

使用线性探测法的过程中，当表中 $i,i+1,i+2$ 位置上已填有记录时，下一个散列地址为 $i,i+1,i+2$ 和 $i+3$ 的记录都将填入 $i+3$ 的位置。这种在处理过程中发生的第一个散列地址不同的多个记录争夺同一个后继散列地址的现象称作“二次聚集”（或称作“堆积”），即在处理同义词的冲突过程中又添加了非同义词的冲突。

线性探测法的优点：只要散列表未填满，总能找到一个不发生冲突的地址。
线性探测法的缺点：会产生“二次聚集”现象。

二次探测法和伪随机探测法的优点：可以避免“二次聚集”现象。
二次探测法和伪随机探测法的缺点：不能保证一定找到不发生冲突的地址。

#### 7.4.3.2 链地址法

链地址法的基本思想：把具有相同散列地址的记录放在同一个单链表中，称为同义词链表。有 $m$ 个散列地址就有 $m$ 个单链表，同时用数组`HT`存放各个链表的头指针，凡是散列地址为 $i$ 的记录都以结点方式插入到以`HT[i]`为头结点的单链表中。

这种构造方法在具体实现时，依次计算各个关键字的散列地址，然后根据散列地址将关键字插入到相应的链表中。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%BC%80%E6%94%BE%E5%9C%B0%E5%9D%80%E6%B3%95%E5%92%8C%E9%93%BE%E5%9C%B0%E5%9D%80%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83.png">
</div>

### 7.4.4 散列表的查找

```C{.line-numbers}
// 开放地址法散列表的存储表示
#define m 20 // 散列表的表长

typedef struct
{
    KeyType key; // 关键字
    InfoType otherinfo; // 其他数据
} HashTable[m];
```

> **算法 7.10**&nbsp;&nbsp;&nbsp;&nbsp;散列表的查找（线性探测法）
>
> 1. 给定待查找的关键字 $k$，根据散列函数计算 $H_0=H(k)$。
> 2. 若单元 $H_0$ 为空，则所查元素不存在。
> 3. 若单元 $H_0$ 中元素的关键字为 $k$，则查找成功。
> 4. 否则重复下列解决冲突的过程：
>    - 按处理冲突的方法，计算下一个散列地址 $H_i$；
>    - 若单元 $H_i$ 为空，则所查元素不存在；
>    - 若单元 $H_i$ 中元素的关键字为 $k$，则查找成功。

```C{.line-numbers}
#define NULLKEY 0 // 单元为空的标记

int SearchHash(HashTable HT, KeyType key)
{
    int H0 = H(key);
    if (HT[H0].key == NULLKEY) // 若单元 H0 为空，则所查元素不存在
    {
        return -1;
    }
    else if (HT[H0].key == key) // 若单元 H0 中元素的关键字为 key，则查找成功
    {
        return H0;
    }
    else
    {
        for (int i = 1; i < m;i++)
        {
            int Hi = (H0 + i) % m; // 按照线性探测法计算下一个散列地址 Hi
            if (HT[Hi].key == NULLKEY)
                return -1;
            else if (HT[Hi].key == key)
                return Hi;
        }
        return -1;
    }
}
```

虽然散列表在关键字与记录的存储位置之间建立了直接映像，但由于冲突的产生，使得散列表的查找过程仍然是一个给定值和关键字进行比较的过程。因此，仍需以平均查找长度作为衡量散列表查找效率的量度。

查找过程中需和给定值进行比较的关键字的个数取决于三个因素：散列函数、处理冲突的方法和散列表的装填因子。

散列函数的好坏首先影响出现冲突的频繁程度。一般情况下认为：凡是均匀的散列函数，对同一组随机的关键字，产生冲突的可能性相同。假设所设定的散列函数是均匀的，则影响平均查找长度的因素只有两个：处理冲突的方法和装填因子。

散列表的装填因子 $\alpha$ 定义为

$$
\alpha=\dfrac{表中填入的记录数}{散列表的长度}
$$

$\alpha$ 标志散列表的装满程度。$\alpha$ 越小，发生冲突的可能性就越小；$\alpha$ 越大，发生冲突的可能性就越大，则查找时的比较次数也就越多。

下表给出了在等概率情况下，采用几种不同方法处理冲突时，得到的散列表查找成功和查找失败时的平均查找长度，证明略。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%86%B2%E7%AA%81%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E4%B8%8E%E5%B9%B3%E5%9D%87%E6%9F%A5%E6%89%BE%E9%95%BF%E5%BA%A6.png">
</div>

从表中可以看出，散列表的平均查找长度是 $\alpha$ 的函数，而不是记录个数 $n$ 的函数。因此，在设计散列表时，不管 $n$ 多大，总可以选择合适的 $\alpha$ 以便将平均查找长度限定在一个范围内。

对于一个具体的散列表，通常采用直接计算的方法求其平均查找长度。在查找概率相等的前提下，直接计算查找成功的平均查找长度可以采用以下公式

$$
\tag{7-7} ASL_{\text{succ}}=\dfrac{1}{n}\sum_{i=1}^n C_i
$$

其中，$n$ 为散列表中记录的个数，$C_i$ 为成功查找第 $i$ 个记录所需的比较次数。

直接计算查找失败的平均查找长度可以采用以下公式

$$
\tag{7-8} ASL_{\text{unsucc}}=\dfrac{1}{r}\sum_{i=1}^r C_i
$$

其中，$r$ 为散列函数取值的个数，$C_i$ 为散列函数取值为 $i$ 时查找失败的比较次数。

# 第8章 排序

## 8.1 基本概念和排序方法概述

### 8.1.1 排序的基本概念

**排序**（sorting）是按关键字的非递减或非递增顺序对一组记录重新进行排列的操作。确切描述为：假设含 $n$ 个记录的序列为 $\{R_1,R_2,\cdots,R_n\}$，其相应的关键字序列为 $\{K_1,K_2,\cdots,K_n\}$，需确定 $1,2,\cdots,n$ 的一种排列 $p_1,p_2,\cdots,p_n$，使其相应的关键字满足如下的非递减（或非递增）关系

$$
K_{p_1}\leqslant K_{p_2}\leqslant\cdots\leqslant K_{p_n}
$$

从而使记录序列成为一个按关键字有序的序列 $\{R_{p_1},R_{p_2},\cdots,R_{p_n}\}$，这样一种操作称为排序。

当排序记录中的关键字 $K_i\,(i=1,2,\cdots,n)$ 都不相同时，任何一个记录的无序序列经排序后得到的结果唯一；反之，当待排序的序列中存在两个或两个以上关键字相等的记录时，则排序所得的结果不唯一。假设 $K_i=K_j\,(1\leqslant i\leqslant n,\,1\leqslant j\leqslant n,\,i\not=j)$，且在排序前的序列中 $R_i$ 领先于 $R_j$，若在排序后的序列中 $R_i$ 仍领先于 $R_j$，则称所用的排序方法是稳定的；反之，若可能使排序后的序列中 $R_j$ 领先于 $R_i$，则称所用的排序方法是不稳定的。

根据在排序过程中记录所占用的存储设备，可将排序方法分为两大类：

1. 内部排序：待排序记录全部存放在计算机内存中进行排序的过程。
2. 外部排序：待排序记录的数量很大，以致内存一次不能容纳全部记录，在排序过程中需要访问外存的排序过程。

### 8.1.2 内部排序方法的分类

在排序的过程中，可以将排序记录分为两个区域：有序序列区、无序序列区。

内部排序的过程是一个逐步扩大记录的有序序列长度的过程。使有序区中记录的数目增加一个或几个的操作称为一趟排序。

根据逐步扩大记录有序序列长度的原则不同，可以将内部排序分为以下几类。

1. 插入类：将无序子序列中的一个或几个记录插入到有序序列中，从而增加记录的有序子序列的长度。主要包括直接插入排序、折半插入排序和希尔排序。
2. 交换类：通过交换无序序列中的记录从而得到其中关键字最小或最大的记录，并将它加入到有序子序列中，以此方法增加记录的有序子序列的长度。主要包括冒泡排序和快速排序。
3. 选择类：从记录的无序子序列中选择关键字最小或最大的记录，并将它加入到有序子序列中，以此方法增加记录的有序子序列的长度。主要包括简单选择排序、树形选择排序和堆排序。
4. 归并类：通过归并两个或两个以上的记录有序子序列，逐步增加记录有序序列的长度。2-路归并排序是最常见的归并排序方法。
5. 分配类：是唯一一类不需要进行关键字比较的排序方法，排序时主要利用分配和收集两种基本操作来完成。基数排序是主要的分配类排序方法。

### 8.1.3 待排序记录的存储方式

1. 顺序表：记录之间的次序关系由其存储位置决定，实现排序需要移动记录。
2. 链表：记录之间的次序关系由指针指示，实现排序不需要移动记录，仅需修改指针即可。这种排序方式称为链表排序。
3. 待排序记录本身存储在一组地址连续的存储单元内，同时另设一个指示各个记录存储位置的地址向量，在排序过程中不移动记录本身，而移动地址向量中这些记录的“地址”，在排序结束后再按照地址向量中的值调整记录的存储位置。这种排序方式称为地址排序。

在本章的讨论中，除基数排序外，待排序记录均按顺序表方式存储，且为了讨论方便，设记录的关键字均为整数。待排序记录的数据类型定义为：

```C{.line-numbers}
#define MAXSIZE 20 // 顺序表的最大长度

typedef int KeyType // 定义关键字类型为整型

// 记录类型
typedef struct
{
    KeyType key; // 关键字
    InfoType otherinfo; // 其他数据
} RedType;

// 顺序表类型
typedef struct
{
    RedType r[MAXSIZE + 1]; // r[0] 闲置或用作哨兵单元
    int length; // 顺序表长度
} SqList;
```

## 8.2 插入排序

插入排序的基本思想：每一趟将一个待排序的记录，按其关键字的大小插入到已经排好序的一组记录的适当位置上，直到所有待排序记录全部插入为止。

### 8.2.1 直接插入排序

> **算法 8.1**&nbsp;&nbsp;&nbsp;&nbsp;直接插入排序
>
> 设待排序记录存放在数组`r[1..n]`中，初始时`r[1]`是一个有序序列。循环 $n-1$ 次，每次使用顺序查找法，查找`r[i]`（$i=2,3,\cdots,n$）在已排好序的序列`r[1..i-1]`中的插入位置，然后将`r[i]`插入到表长为 $i-1$ 的有序序列`r[1..i-1]`，直到将`r[n]`插入表长为 $n-1$ 的有序序列`r[1..n-1]`，最后得到一个表长为 $n$ 的有序序列。

```C{.line-numbers}
void InsertSort(SqList &L)
{
    for (int i = 2; i <= L.length; i++)
    {
        if (L.r[i].key < L.r[i-1].key) // r[i] 小于前驱元素，需要将 r[i] 插入有序子表
        {
            L.r[0] = L.r[i]; // 将待插入的记录暂存到监视哨中
            L.r[i] = L.r[i - 1]; // r[i - 1] 后移

            // 从后向前寻找插入位置
            int j = i - 2;
            while (L.r[0].key < L.r[j].key)
            {
                L.r[j + 1] = L.r[j];
                j--;
            }

            L.r[j + 1] = L.r[0]; // 将待插入元素取出，插入到正确位置
        }
    }
}
```

排序的基本操作为：比较两个关键字的大小和移动记录。对于其中的某一趟插入排序，比较次数和移动次数取决于待插入记录的关键字与前 $i-1$ 个记录的关键字之间的关系。在最好情况下（正序），比较 1 次，不移动；在最坏情况下（逆序），比较 $i$ 次（依次同前面的 $i-1$ 个记录进行比较，并和哨兵比较 1 次），移动 $i+1$ 次（先将待插入记录先移动到监视哨中，再将前面的 $i-1$ 个记录依次向后移动，最后将待插入记录移动到插入位置）。

整个排序过程需执行 $n-1$ 趟，最好情况下，总的比较次数达到最小值 $n-1$，记录不移动；最坏情况下，总的关键字比较次数 $KCN$ 和记录移动次数 $RMN$ 均达到最大值，分别为

$$
KCN=\sum_{i=2}^n i=\dfrac{(n+2)(n-1)}{2}\\
RMN=\sum_{i=2}^n (i+1)=\dfrac{(n+4)(n-1)}{2}
$$

若待排序序列中出现各种可能排列的概率相同，则可取上述最好情况和最坏情况的平均情况。在平均情况下，直接插入排序的关键字比较次数和记录移动次数均约为 $\dfrac{n^2}{4}$。由此，直接插入排序的时间复杂度为 $O(n^2)$。

直接插入排序只需要一个记录的辅助空间`r[0]`，所以空间复杂度为 $O(1)$。

算法特点：

1. 稳定排序。
2. 算法简便，且容易实现。
3. 也适用于链式存储结构，只是在单链表上无需移动记录，只需修改相应的指针。
4. 更适合于初始记录基本有序的情况。当初始记录无序，$n$ 较大时，此算法时间复杂度较高，不宜采用。

### 8.2.2 折半插入排序

直接插入排序采用顺序查找法查找当前记录在有序序列中的插入位置。这个查找过程可以使用折半查找来实现，由此进行的插入排序称为**折半插入排序**（Binary Insertion Sort）。

> **算法 8.2**&nbsp;&nbsp;&nbsp;&nbsp;折半插入排序
>
> 设待排序记录存放在数组`r[1..n]`中，初始时`r[1]`是一个有序序列。循环 $n-1$ 次，每次使用折半查找法，查找`r[i]`（$i=2,3,\cdots,n$）在已排好序的序列`r[1..i-1]`中的插入位置，然后将`r[i]`插入到表长为 $i-1$ 的有序序列`r[1..i-1]`，直到将`r[n]`插入表长为 $n-1$ 的有序序列`r[1..n-1]`，最后得到一个表长为 $n$ 的有序序列。

```C{.line-numbers}
void BInsertSort(SqList &L)
{
    for (int i = 2; i <= L.length; i++)
    {
        L.r[0] = L.r[i]; // 将待插入记录暂存到监视哨中

        // 置查找区间初值
        int low = 1;
        int high = i - 1;

        // 折半查找插入位置
        while (low <= high)
        {
            int mid = (low + high) / 2;
            if (L.r[0].key < L.r[mid].key)
            {
                high = m - 1;
            }
            else
            {
                low = m + 1;
            }
        }

        // 记录后移
        for (int j = i - 1; j >= high + 1; j--)
        {
            L.r[j + 1] = L.r[j];
        }

        L.r[high + 1] = L.r[0]; // 插入到正确位置
    }
}
```

从时间上比较，折半查找比顺序查找快，所以就平均性能来说，折半插入排序优于直接插入排序。

折半插入排序的比较次数与待排序序列的初始排列无关，仅依赖于记录的个数。不论初始序列情况如何，在插入第 $i$ 个记录时，需要经过 $\lfloor\log_2 i\rfloor+1$ 次比较，才能确定插入位置。所以当记录的初始排列为正序或接近正序时，直接插入排序比折半插入排序的比较次数少。

折半插入排序的对象移动次数与直接插入排序相同，依赖于对象的初始排列。

在平均情况下，折半插入排序仅减少了关键字间的比较次数，而记录的移动次数不变。因此，折半插入排序的时间复杂度仍为 $O(n^2)$。

折半插入排序所需附加存储空间和直接插入排序相同，只需要一个记录的辅助空间`r[0]`，所以空间复杂度为 $O(1)$。

算法特点：

1. 稳定排序。
2. 只能用于顺序结构，不能用于链式结构。
3. 适合初始记录无序、$n$ 较大时的情况。

### 8.2.3 希尔排序

**希尔排序**（Shell's Sort）又称**缩小增量排序**（Diminishing Increment Sort），是插入排序的一种。

直接插入排序当待排序的记录个数较少且待排序序列基本有序时，效率较高。希尔排序基于以上两点，从“减少记录个数”和“序列基本有序”两个方面对直接插入排序进行了改进。

希尔排序实质上是采用分组插入的方法。先将整个待排序记录序列分割成几组，从而减少参与直接插入排序的数据量，对每组分别进行直接插入排序，然后增加每组的数据量，重新分组。当经过几次分组排序后，整个序列中的记录基本有序时，再对全体记录进行一次直接插入排序。

希尔排序对记录分组时，将相隔某个“增量”的记录分成一组。

1. 第一趟取增量 $d_1\,(d_1<n)$ 把全部记录分成 $d_1$ 个组，所有间隔为 $d_1$ 的记录分在同一组，在各个组中进行直接插入排序。
2. 第二趟取增量 $d_2\,(d_2<d_1)$，重复上述的分组和排序。
3. 以此类推，直到所取的增量 $d_t=1\,(d_t<d_{t-1}<\cdots<d_2<d_1)$，所有记录在同一组中进行直接插入排序为止。

> **算法 8.3**&nbsp;&nbsp;&nbsp;&nbsp;希尔排序

```C{.line-numbers}
// 一趟直接插入排序，增量为 dk
void ShellInsert(SqList &L, int dk)
{
    for (int i = dk + 1; i <= L.length; i++)
    {
        if (L.r[i].key < L.r[i - dk].key)
        {
            L.r[0] = L.r[i]; // 暂存在 r[0]
            
            // 记录后移，直到找到插入位置
            int j = i - dk;
            while (j > 0 && L.r[0].key < L.r[j].key)
            {
                L.r[j + dk] = L.r[j];
                j -= dk;
            }

            L.r[j + dk] = L.r[0];
        }
    }
}

// 按增量序列 dt 对顺序表 L 做希尔排序
void ShellSort(SqList &L, int* dt, int t)
{
    for (int i = 0; i < t; i++)
        ShellInsert(L, dt[k]);
}
```

当增量大于 1 时，关键字较小的记录就不是一步一步地挪动，而是跳跃式地移动，从而使得在进行最后一趟增量为 1 的插入排序时，序列已基本有序，只要做记录的少量比较和移动即可完成排序，因此希尔排序的时间复杂度比直接插入排序低。当增量序列为 $\text{dt}[k]=2^{t-k+1}-1$ 时，希尔排序的时间复杂度为 $O(n^{\frac{3}{2}})$，其中 $t$ 为排序趟数，$1\leqslant k\leqslant t\leqslant\lfloor\log_2(n+1)\rfloor$。当 $n$ 在某个特定范围内，希尔排序所需的比较和移动次数约为 $n^{1.3}$，当 $n\to\infin$ 时，可减少到 $n(\log_2 n)^2$。

希尔排序只需要一个辅助空间`r[0]`，空间复杂度为 $O(1)$。

算法特点：

1. 记录跳跃式地移动导致排序方法是不稳定的。
2. 只能用于顺序结构，不能用于链式结构。
3. 增量序列可以有各种取法，但应该使增量序列中的值没有除 1 之外的公因子，并且最后一个增量值必须等于 1。
4. 总的比较次数和移动次数都比直接插入排序要少，$n$ 越大时，效果越明显。所以适合于初始记录无序、$n$ 较大时的情况。

## 8.3 交换排序

交换排序的基本思想：两两比较待排序记录的关键字，一旦发现两个记录不满足次序要求时则进行交换，直到整个序列全部满足要求为止。

### 8.3.1 冒泡排序

冒泡排序（Bubble Sort）是最简单的交换排序方法，它通过两两比较相邻记录的关键字，如果发生逆序，则进行交换，从而使关键字小的记录像气泡一样逐渐上浮，或者使关键字大的记录逐渐下沉。

> **算法 8.4**&nbsp;&nbsp;&nbsp;&nbsp;冒泡排序
>
> 设待排序的数组存放在数组`r[1..n]`中。
>
> 1. 首先将第一个记录的关键字和第二个记录的关键字进行比较，若为逆序，则交换两个记录。然后比较第二个记录和第三个记录的关键字。以此类推，直至第 $n-1$ 个记录和第 $n$ 个记录的关键字进行过比较为止。上述过程称作第一趟起泡排序，其结果使得关键字最大的记录被安置到最后一个记录的位置上。
> 2. 然后进行第二趟起泡排序，对前 $n-1$ 个记录进行同样操作，其结果是使关键字次大的记录被安置到第 $n-1$ 个记录的位置上。
> 3. 重复上述比较和交换过程，第 $i$ 趟是从`L.r[1]`到`L.r[n-i+1]`依次比较相邻两个记录的关键字，并在逆序时交换相邻记录，其结果是这 $n-i+1$ 个记录中关键字最大的记录被交换到第 $n-i+1$ 的位置上。直到在某一趟排序过程中没有进行过交换记录的操作，说明序列已全部达到排序要求，则完成排序。

```C{.line-numbers}
void BubbleSort(SqList &L)
{
    int m = L.length - 1;
    int flag = 1; // 标记某一趟排序是否发生交换

    while (m > 0 && flag == 1)
    {
        flag = 0;
        for (int i = 1; i <= m; i++)
        {
            if (L.r[i].key > L.r[i + 1].key) // 逆序，交换相邻记录
            {
                flag = 1;
                t = L.r[i];
                L.r[i] = L.r[i + 1];
                L.r[i + 1] = t;
            }
        }
        m--;
    }
}
```

最好情况：只需进行一趟排序，在排序过程中进行 $n-1$ 次关键字比较，不移动记录。最好时间复杂度为 $O(n)$。

最坏情况：需进行 $n-1$ 趟排序，总的关键字比较次数 $KCN$ 和记录移动次数 $RMN$ 分别为

$$
KCN=\sum_{i=n}^2(i-1)=\dfrac{n(n-1)}{2}\\
RMN=3\sum_{i=n}^2(i-1)=\dfrac{3n(n-1)}{2}
$$

平均情况下，关键字比较次数约为 $\dfrac{n^2}{4}$，记录移动次数约为 $\dfrac{3n^2}{4}$，时间复杂度为 $O(n^2)$。

冒泡排序只有在两个记录交换位置时需要一个辅助空间用作暂存记录，所以空间复杂度为 $O(1)$。

算法特点：

1. 稳定排序。
2. 可用于链式存储结构。
3. 移动记录次数较多，算法平均时间性能比直接插入排序差。当初始记录无序，$n$ 较大时，不宜采用冒泡排序。

### 8.3.2 快速排序

> **算法 8.5**&nbsp;&nbsp;&nbsp;&nbsp;快速排序
>
> 在待排序的 $n$ 个记录中任取一个记录作为枢轴（或支点），设其关键字为`pivotkey`。经过一趟排序后，把所有关键字小于`pivotkey`的记录交换到前面，把所有关键字大于`pivotkey`的记录交换到后面，结果将待排序记录分成两个子表，最后将枢轴放置在分界处。然后分别对左、右子表重复上述过程，直至每一子表只有一个记录时，排序完成。
>
> 其中，一趟快速排序的具体步骤如下。
>
> 1. 选择待排序表中的第一个记录作为枢轴，将枢轴记录暂存在`r[0]`的位置上。附设两个指针`low`和`high`，初始时分别指向表的下界和上界。
> 2. 从表的最右侧位置依次向左搜索，找到第一个关键字小于枢轴关键字`pivotkey`的记录，将其移到`low`处。
> 3. 然后再从表的最左侧位置依次向右搜索，找到第一个关键字大于枢轴关键字`pivotkey`的记录，将其移到`high`处。
> 4. 重复步骤 2 和 3，直至`low`与`high`相等为止。此时`low`或`high`的位置即为枢轴在此趟排序中的最终位置，原表被分成两个子表。

```C{.line-numbers}
// 对顺序表 L 的子表 r[low..high] 进行一趟排序，返回枢轴位置
int Partition(SqList &L, int low, int high)
{
    L.r[0] = L.r[low]; // 用子表的第一个记录做枢轴
    KeyType pivotkey = L.r[low].key; // 保存枢轴记录关键字

    while (low < high)
    {
        // 从右到左寻找第一个小于枢轴的记录，将其移动到低端
        while (low < high && L.r[high].key >= pivotkey)
        {
            high--;
        }
        L.r[low] = L.r[high];

        // 从左向右寻找第一个大于枢轴的记录，将其移动到高端
        while (low < high && L.r[low].key <= pivotkey)
        {
            low++;
        }
        L.r[high] = L.r[low];
    }

    L.r[low] = L.r[0]; // 枢轴记录到位
    return low; // 返回枢轴位置
}

// 对顺序表 L 的子表 r[low..high] 进行快速排序
void QSort(SqList &L, int low, int high)
{
    if (low < high)
    {
        int pivotloc = Partition(L, low, high);
        QSort(L, low, pivotloc - 1); // 对左子表递归排序
        QSort(L, pivotloc + 1, high); // 对右子表递归排序
    }
}

// 对顺序表 L 做快速排序
void QuickSort(SqList &L)
{
    QSort(L, 1, L.length);
}
```

快速排序的趟数取决于递归树的深度。

最好情况：每一趟排序后都能将记录序列均匀地分割成两个长度大致相等的子表。在 $n$ 个元素的序列中，对枢轴定位所需时间为 $O(n)$。设 $T(n)$ 是对 $n$ 个元素的序列进行排序所需的时间，而且每次对枢轴正确定位后，正号把序列划分为长度相等的两个子表；设 $C_n$ 是一个常数，表示 $n$ 个元素进行一趟快速排序的时间，则总的排序时间为

$$
\begin{aligned}
    T(n)&=C_n+2T(\dfrac{n}{2})\\
    &\leqslant n+2T(\dfrac{n}{2})\\
    &\leqslant n+2\Big(\dfrac{n}{2}+2T(\dfrac{n}{4})\Big)=2n+4T(\dfrac{n}{4})\\
    &\leqslant 2n+4\Big(\dfrac{n}{4}+2T(\dfrac{n}{8})\Big)=3n+8T(\dfrac{n}{8})\\
    &\cdots\\
    &\leqslant n\log_2 n+2^{\log_2 n}T(\dfrac{n}{2^{\log_2 n}})\\
    &\leqslant n\log_2 n+nT(1)\\
    &\approx O(n\log_2 n)
\end{aligned}
$$

因此，快速排序在最好情况下的时间复杂度为 $O(n\log_2 n)$。

最坏情况：在待排序序列已经排好序的情况下，其递归树成为单支树，每次划分只得到一个比上一次少一个记录的子序列。这样，必须经过 $n-1$ 趟才能将所有记录定位，而且第 $i$ 趟需要经过 $n-i$ 次比较，则总的关键字比较次数为

$$
KCN=\sum_{i=1}^n(n-i)=\dfrac{n(n-1)}{2}
$$

因此，快速排序在最坏情况下的时间复杂度为 $O(n^2)$。

这种情况下，快速排序的速度已经退化到简单排序的水平。合理选择枢轴记录可以避免最坏情况的出现，如“三者取中”规则：比较当前表中第一个记录、最后一个记录和中间记录的关键字，取关键字居中的记录作为枢轴记录，事先调换到第一个记录的位置。

平均情况下，快速排序的时间复杂度为 $O(n\log_2 n)$。

快速排序是递归的，执行时需要有一个栈来存放相应的数据。最大递归调用次数与递归树的深度一致，所以最好情况下的空间复杂度为 $O(\log_2 n)$，最坏情况下为 $O(n)$。

算法特点：

1. 记录非顺次的移动导致排序方法是不稳定的。
2. 排序过程中需要定位表的下界和上界，所以适合于顺序结构，很难用于链式结构。
3. 当 $n$ 较大时，在平均情况下快速排序是所有内部排序方法中速度最快的一种，适合于初始记录无序、$n$ 较大时的情况。

## 8.4 选择排序

选择排序的基本思想：每一趟从待排序的记录中选出关键字最小的记录，按顺序放在已排序的记录序列的最后，直到全部排完为止。

### 8.4.1 简单选择排序

> **算法 8.6**&nbsp;&nbsp;&nbsp;&nbsp;简单选择排序
>
> 1. 设待排序记录存放在数组`r[1..n]`中。第一趟从`r[1]`开始，通过 $n-1$ 次比较，从 $n$ 个记录中选出关键字最小的记录，记为`r[k]`，交换`r[1]`和`r[k]`。
> 2. 第二趟从`r[2]`开始，通过 $n-2$ 次比较，从 $n-1$ 个记录中选出关键字最小的记录，记为`r[k]`，交换`r[2]`和`r[k]`。
> 3. 以此类推，第 $i$ 趟从`r[i]`开始，通过 $n-i$ 次比较，从 $n-i+1$ 个记录中选出关键字最小的记录，记为`r[k]`，交换`r[i]`和`r[k]`。
> 4. 经过 $n-1$ 趟，排序完成。

```C{.line-numbers}
void SelectSort(SqList &L)
{
    for (int i = 1; i < L.length; i++)
    {
        // 在 L.r[i..L.length] 中选择关键字最小的记录，k 为最小记录的下标
        int k = i;
        for (int j = i + 1; j <= L.length; j++)
        {
            if (L.r[j].key < L.r[k].key)
            {
                k = j;
            }
        }

        // 交换 r[i] 与 r[k]
        if (k != i)
        {
            t = L.r[i];
            L.r[i] = L.r[k];
            L.r[k] = t;
        }
    }
}
```

最好情况下（正序），不移动记录；最坏情况下（逆序），记录移动次数为 $3(n-1)$。

无论记录的初始排列如何，关键字比较次数都相同，均为

$$
KCN=\sum_{i=1}^{n-1}(n-i)=\dfrac{n(n-1)}{2}
$$

因此，简单选择排序的时间复杂度为 $O(n^2)$。

简单选择排序只有在交换记录时需要一个辅助空间，所以空间复杂度为 $O(1)$。

算法特点：

1. 选择排序本身是稳定的，但是上述算法的实现采用了交换记录的策略，这会导致不稳定现象。改变这个策略，可以写出不产生不稳定现象的选择排序算法。
2. 可用于链式存储结构。
3. 记录移动次数较少，当每一记录占用的空间较多时，此方法比直接插入排序快。

### 8.4.2 树形选择排序

选择排序的主要操作是关键字比较，因此改进简单选择排序应从“减少比较”出发。

在 $n$ 个关键字中选出最小值，至少要进行 $n-1$ 次比较。然而，继续在剩余的 $n-1$ 个关键字中选择次小值并非一定要进行 $n-2$ 次比较，若能利用前 $n-1$ 次比较所得信息，则可以减少以后各趟选择排序的比较次数。

**树形选择排序**（Tree Selection Sort）又称**锦标赛排序**（Tournament Sort），是一种按照锦标赛的思想进行选择排序的方法。

首先对 $n$ 个记录的关键字进行两两比较，然后在其中 $\Big\lceil\dfrac{n}{2}\Big\rceil$ 个较小者之间再进行两两比较，如此重复，直至选出最小关键字的记录为止。这个过程可以用一棵有 $n$ 个叶子结点的完全二叉树表示，如图 8.1(a) 所示。

选出最小关键字之后，要选出次小关键字，只需要将叶子结点中的最小关键字改为“最大值”，然后从该叶子结点开始，和其兄弟的关键字进行比较，修改从叶子结点到根的路径上各结点的关键字，则根结点的关键字即为次小关键字。同理，可依次选出从小到大的所有关键字，如图 8.1(b) 和 8.1(c) 所示。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE8.1-%E6%A0%91%E5%BD%A2%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%E7%A4%BA%E4%BE%8B.png">
    <br>
    图 8.1&nbsp;&nbsp;&nbsp;&nbsp;树形选择排序示例
</div>

由于含有 $n$ 个叶子结点的完全二叉树的深度为 $\lceil\log_2 n\rceil+1$，则在树形选择排序中，除了最小关键字之外，每选择一个次小关键字仅需进行 $\lceil\log_2 n\rceil$ 次比较，因此时间复杂度为 $O(n\log_2 n)$。

缺点：辅助存储空间较多，和“最大值”进行多余的比较。

### 8.4.3 堆排序

设 $n$ 个元素的序列为 $\{k_1,k_2,\cdots,k_n\}$，若满足条件 $k_i\geqslant k_{2i}$ 且 $k_i\geqslant k_{2i+1}$（$1\leqslant i\leqslant\Big\lfloor\dfrac{n}{2}\Big\rfloor$），则称为大根堆；若满足条件 $k_i\leqslant k_{2i}$ 且 $k_i\leqslant k_{2i+1}$，则称为小根堆。大根堆和小根堆统称为**堆**。

如果使用一维数组存储上述序列，并将它看成一个完全二叉树，则堆实质上是满足如下性质的完全二叉树：树中所有非终端结点的值均不大于（或不小于）其左、右孩子结点的值。其中，若非终端结点的值不大于其左、右孩子结点的值，则根结点为最小值，为小根堆；若非终端结点的值不小于其左、右孩子结点的值，则根结点为最大值，为大根堆。

使用大根堆进行堆排序的步骤如下：

1. 按堆的定义将待排序序列`r[1..n]`调整为大根堆（这个过程称为建初堆），交换`r[1]`和`r[n]`，则`r[n]`为关键字最大的记录。
2. 将`r[1..n-1]`重新调整为堆，交换`r[1]`和`r[n - 1]`，则`r[n - 1]`为关键字次大的记录。
3. 循环 $n-1$ 次，直到交换了`r[1]`和`r[2]`为止，得到了一个非递减的有序序列`r[1..n]`。

> **算法 8.7**&nbsp;&nbsp;&nbsp;&nbsp;筛选法调整堆
>
> 假设`r[s+1..m]`是大根堆，将`r[s..m]`调整为以`r[s]`为根的大根堆。
>
> 1. 从`r[2s]`和`r[2s + 1]`中选出关键字较大者，假设`r[2s]`的关键字较大，比较`r[s]`和`r[2s]`的关键字。
> 2. 若`r[s].key >= r[2s].key`，说明以`r[s]`为根的子树已经是堆，不必做任何调整。
> 3. 若`r[s].key < r[2s].key`，交换`r[s]`和`r[2s]`。交换后，以`r[2s + 1]`为根的子树仍是堆，如果以`r[2s]`为根的子树不是堆，则重复上述过程，将以`r[2s]`为根的子树调整为堆，直至进行到叶子结点为止。

```C{.line-numbers}
void HeapAdjust(SqList &L, int s, int m)
{
    for (int i = 2 * s; i <= m; i *= 2)
    {
        // 选出两个子结点中较大的一个
        if (i < m && L.r[i].key < L.r[i + 1].key)
        {
            i++;
        }

        // 如果双亲结点更大，说明已经是堆，不必继续调整
        if (L.r[s].key >= L.r[i].key)
        {
            break;
        }

        // 将双亲结点与较大的子结点交换
        rc = L.r[s];
        L.r[s] = L.r[i];
        L.r[i] = rc;

        // 沿较大的子结点向下
        s = i;
    }
}
```

要将一个无序序列调整为堆，就必须将其所对应的完全二叉树中以每一结点为根的子树都调整为堆。只有一个结点的树必是堆，而在完全二叉树中，所有序号大于 $\Big\lfloor\dfrac{n}{2}\Big\rfloor$ 的结点都是叶子，因此以这些结点为根的子树已经是堆。这样，只需利用筛选法，从最后一个分支结点 $\Big\lfloor\dfrac{n}{2}\Big\rfloor$ 开始，依次将序号为 $\Big\lfloor\dfrac{n}{2}\Big\rfloor,\Big\lfloor\dfrac{n}{2}\Big\rfloor-1,\cdots,1$ 的结点作为根的子树都调整为堆即可。

> **算法 8.8**&nbsp;&nbsp;&nbsp;&nbsp;建初堆
>
> 对于无序序列`r[1..n]`，从`i = n / 2`开始，反复调用筛选法`HeapAdjust`，依次将以`r[i]`、`r[i-1]`、$\cdots$、`r[1]`为根的子树调整为堆。

```C{.line-numbers}
void CreateHeap(SqList &L)
{
    int n = L.length;
    for (int i = n / 2; i > 0; i--)
    {
        HeapAdjust(L, i, n);
    }
}
```

> **算法 8.9**&nbsp;&nbsp;&nbsp;&nbsp;堆排序

```C{.line-numbers}
void HeapSort(SqList &L)
{
    CreateHeap(L); // 建初堆
    for (int i = L.length; i > 1; i--)
    {
        // 将堆顶记录和当前未经排序子序列 r[1..i] 中最后一个记录互换
        x = L.r[1];
        L.r[1] = L.r[i];
        L.r[i] = x;

        // 将 r[1..i-1] 重新调整为大根堆
        HeapAdjust(L, 1, i - 1);
    }
}
```

堆排序的运行时间主要耗费在建初堆和调整堆时进行的反复筛选上。设有 $n$ 个记录的初始序列所对应的完全二叉树的深度为 $h$，建初堆时，每个非终端结点都要自上而下进行筛选。由于第 $i$ 层上的结点数小于等于 $2^{i-1}$，且第 $i$ 层结点最大下移的深度为 $h-i$，每下移一层要做两次比较，所以建初堆时总的关键字比较次数为

$$
\sum_{i=h-1}^1[2^{i-1}\cdot 2(h-i)]=\sum_{i=h-1}^1[2^i(h-i)]=\sum_{j=1}^{h-1}(2^{h-j}j)\leqslant 2n\sum_{j=1}^{h-1}\dfrac{j}{2^j}\leqslant 4n
$$

$n$ 个结点的完全二叉树的深度为 $\lfloor\log_2 n\rfloor+1$，则重建堆时总的关键字比较次数不超过

$$
2(\lfloor\log_2(n-1)\rfloor+\lfloor\log_2(n-2)\rfloor+\cdots+\log_2 2)<2n\lfloor\log_2 n\rfloor
$$

由此，堆排序在最坏情况下的时间复杂度为 $O(n\log_2 n)$。

堆排序的平均时间复杂度为 $O(n\log_2 n)$。

堆排序仅需一个记录大小供交换用的辅助存储空间，所以空间复杂度为 $O(1)$。

算法特点：

1. 不稳定排序。
2. 只能用于顺序结构，不能用于链式结构。
3. 初始建堆所需的比较次数较多，因此记录数较少时不宜采用，当记录较多时较为高效。

## 8.5 归并排序

**归并排序**（Merging Sort）就是将两个或两个以上的有序表合并成一个有序表的过程。将两个有序表合并成一个有序表的过程称为 **2-路归并**。

归并排序的思想：假设初始序列含有 $n$ 个记录，则可看成是 $n$ 个有序的子序列，每个子序列的长度为 1，然后两两归并，得到 $\Big\lceil\dfrac{n}{2}\Big\rceil$ 个长度为 2 或 1 的有序子序列；再两两归并，如此重复，直到得到一个长度为 $n$ 的有序序列为止。

> **算法 8.10**&nbsp;&nbsp;&nbsp;&nbsp;相邻两个有序子序列的归并
>
> 设两个有序表存放在同一数组中相邻的位置上：`R[low..mid]`和`R[mid+1..high]`。每次分别从两个表中取出一个记录进行关键字的比较，将较小者放入`T[low..high]`中，重复此过程，直至其中一个表为空，最后将另一非空表中余下的部分直接复制到`T`中。

```C{.line-numbers}
void Merge(RedType R[], RedType &T[], int low, int mid, int high)
{
    int i = low; // 指向 R[low..mid]
    int j = mid + 1; // 指向 R[mid+1..high]
    int k = low; // 指向 T

    while (i <= mid && j <= high)
    {
        if (R[i].key <= R[j].key)
        {
            T[k] = R[i];
            i++;
        }
        else
        {
            T[k] = R[j];
            j++;
        }
        k++;
    }

    // 剩余部分复制到 T 中
    while (i <= mid)
    {
        T[k] = R[i];
        k++;
        i++;
    }

    while (j <= high)
    {
        T[k] = R[j];
        k++;
        j++;
    }
}
```

> **算法 8.11**&nbsp;&nbsp;&nbsp;&nbsp;2-路归并排序
>
> 将`R[low..high]`中的记录归并排序后放入`T[low..high]`中。当序列长度为 1 时，递归结束，否则：
>
> 1. 将当前序列一分为二，求出分裂点`mid = (low + high) / 2;`
> 2. 对子序列`R[low..mid]`递归，进行归并排序，结果放入`S[low..mid]`中。
> 3. 对子序列`R[mid+1..high]`递归，进行归并排序，结果放入`S[mid+1..high]`中。
> 4. 调用`Merge`，将有序的两个子序列`S[low..mid]`和`S[mid+1..high]`归并为一个有序序列`T[low..high]`。

```C{.line-numbers}
void MSort(RedType R[], RedType &T[], int low, int high)
{
    if (low == high) // 序列长度为 1，递归出口
    {
        T[low] = R[low];
    }
    else
    {
        int mid = (low + high) / 2; // 求分裂点
        MSort(R, S, low, mid); // 对左子序列递归归并排序
        MSort(R, S, mid + 1, high); // 对右子序列递归归并排序
        Merge(S, T, low, mid, high); // 合并两个有序子序列
    }
}

// 对顺序表 L 做归并排序
void MergeSort(SqList &L)
{
    MSort(L.r, L.r, 1, L.length);
}
```

假设每个子序列的长度为 $h$，则一趟归并排序需要调用 $\Big\lceil\dfrac{n}{2h}\Big\rceil$ 次`Merge`进行两两归并，得到前后相邻、长度为 $2h$ 的有序段。当有 $n$ 个记录时，整个归并排序需进行 $\lceil\log_2 n\rceil$ 趟，每一趟归并，其关键字比较次数不超过 $n$，元素移动次数都是 $n$。因此，归并排序的时间复杂度为 $O(n\log_2 n)$。

用顺序表实现归并排序时，需要和待排序记录个数相等的辅助存储空间，所以空间复杂度为 $O(n)$。

算法特点：

1. 稳定排序。
2. 可用于链式结构，且不需要附加存储空间，但递归实现时仍需要开辟相应的递归工作栈。

## 8.6 基数排序

有的逻辑关键字可以看成由若干个关键字复合而成的。假设记录的逻辑关键字由 $d$ 个关键字组成，每个关键字可能取 $rd$ 个值。只要从最低数位关键字起，按关键字的不同值将序列中的记录“分配”到 $rd$ 个队列中后再“收集”，如此重复 $d$ 次，即可完成排序。这种方法称为**基数排序**，其中“基”指的是 $rd$。

例如，若逻辑关键字是数值，且满足 $0\leqslant K\leqslant 999$，则可以认为 $K$ 由 3 个关键字 $K^0,K^1,K^2$ 组成，其中 $K^0$ 是百位数，$K^1$ 是十位数，$K^2$ 是个位数。在这个例子中，$d$ 为 3，$rd$ 为 10。

基数排序通常用链式存储结构实现，称为链式基数排序。图 8.2 所示为链式基数排序的一个例子。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE8.2-%E9%93%BE%E5%BC%8F%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%E7%A4%BA%E4%BE%8B.png">
    <br>
    图 8.2&nbsp;&nbsp;&nbsp;&nbsp;链式基数排序示例
</div>

算法实现时采用静态链表，以便于更有效地存储和重排记录。相关数据类型的定义如下：

```C{.line-numbers}
#define MAXNUM_KEY 8 // 关键字项数的最大值
#define RADIX 10 // 基数，此时是十进制整数的基数
#define MAX_SPACE 10000

// 静态链表的结点类型
typedef struct
{
    KeysType keys[MAXNUM_KEY]; // 关键字
    InfoType otheritems; // 其他数据项
    int next;
} SLCell;

// 静态链表类型
typedef struct
{
    SLCell r[MAX_SPACE]; // 静态链表的可利用空间，r[0] 为头结点
    int keynum; // 记录的当前关键字个数
    int recnum; // 静态链表的当前长度
} SLList;

typedef int ArrType[RADIX]; // 指针数组类型
```

> **算法 8.12**&nbsp;&nbsp;&nbsp;&nbsp;基数排序

```C{.line-numbers}
// 静态链表 L 的 r 域中记录已按 (keys[0], ..., keys[i - 1]) 有序
// 分配操作，按第 i 个关键字 keys[i] 建立 RADIX 个子表，使同一子表中记录的 keys[i] 相同
// f[0..RADIX-1] 和 e[0..RADIX-1] 分别指向各子表中第一个和最后一个记录
void Distribute(SLCell &r, int i, ArrType &f, ArrType &e)
{
    // 各子表初始化为空表
    for (int j = 0; j < RADIX; j++)
    {
        f[j] = 0;
    }

    for (int p = r[0].next; p != 0; p = r[p].next)
    {
        int j = ord(r[p].keys[i]); // 将记录中第 i 个关键字映射到 [0, RADIX-1] 区间内

        // 将 p 所指的结点插入第 j 个子表中
        if (f[j] == 0) // 链表为空
        {
            f[j] = p;
        }
        else
        {
            r[e[j]].next = p;
        }

        e[j] = p;
    }
}

// 收集操作，按 keys[i] 自小至大地将 f[0..RADIX-1] 所指各子表依次链接成一个链表
// e[0..RADIX-1] 为各子表的尾指针
void Collet(SLCell &r, int i, ArrType f, ArrType e)
{
    // 找第一个非空子表
    int j = 0;
    while (f[j] == 0)
    {
        j = succ(j); // succ 为求后继函数
    }

    r[0].next = f[j]; // r[0].next 指向第一个非空子表中第一个结点
    int t = e[j]; // t 指向第一个非空子表中最后一个结点

    while (j < RADIX)
    {
        // 找下一个非空子表
        while (j < RADIX - 1 && f[j] == 0)
        {
            j = succ(j);
        }

        // 链接两个非空子表
        if (f[j] != 0)
        {
            r[t].next = f[j];
            t = e[j];
        }
    }

    r[t].next = 0; // 最后一个结点的后继置为 0
}

// L 是采用静态链表表示的顺序表，对 L 做基数排序
void RadixSort(SLList &L)
{
    // 将 L 改造为静态链表
    for (int i = 0; i < L.recnum; i++)
    {
        L.r[i].next = i + 1;
    }
    L.r[L.recnum].next = 0;

    for (int i = 0; i < L.keynum; i++)
    {
        Distribute(L.r, i, f, e); // 第 i 趟分配
        Collect(L.r, i, f, e); // 第 i 趟收集
    }
}
```

对 $n$ 个记录（每个记录含 $d$ 个关键字，每个关键字的取值范围包括 $rd$ 个值）进行链式排序时，每一趟分配的时间复杂度为 $O(n)$，每一趟收集的时间复杂度为 $O(rd)$，整个排序需进行 $d$ 趟分配和收集，所以时间复杂度为 $O(d(n+rd))$。

基数排序所需辅助空间为 $2rd$ 个队列指针，另外由于用链表做存储结构，则相对于其他以顺序结构存储记录的排序方法而言，还增加了 $n$ 个指针域的空间，所以空间复杂度为 $O(n+rd)$。

算法特点：

1. 稳定排序。
2. 可用于链式结构，也可用于顺序结构。
3. 时间复杂度可以突破基于关键字比较一类方法的下界 $O(n\log_2 n)$，达到 $O(n)$。
4. 基数排序使用条件有严格的要求：需要知道各级关键字的主次关系和各级关键字的取值范围。

## 8.7 外部排序

### 8.7.1 外部排序的基本方法

外部排序由两个相对独立的阶段组成：

1. 按可用内存大小，将外存上含 $n$ 个记录的文件分成若干长度为 $l$ 的子文件或**段**（segment），依次读入内存，利用内部排序方法对它们进行排序，并将排序后得到的有序子文件重新写入外存。称这些有序子文件为**归并段**或**顺串**（run）。
2. 对这些归并段进行逐趟排序，使归并段逐渐由小至大，直至得到整个有序文件为止。

对归并段进行归并时，每一趟将 $k$ 个有序子文件归并成一个有序子文件，这种归并方法称为 **k-路平衡归并**。

$$
\tag{8-1}
\begin{aligned}
    外部排序所需总的时间=&内部排序所需的时间(m\times t_{\text{IS}})+\\
    &外存信息读写的时间(d\times t_{\text{IO}})+\\
    &内部归并所需的时间(s\times ut_{\text{mg}})
\end{aligned}
$$

其中，$m$ 为经过内部排序之后得到的初始归并段的个数，$t_{\text{IS}}$ 是为得到一个初始归并段进行内部排序所需时间的均值，$d$ 为总的读写次数，$t_{\text{IO}}$ 为进行一次外存读写时间的均值，$s$ 为归并的趟数，$ut_{\text{mg}}$ 为对 $u$ 个记录进行内部归并所需时间。

$t_{\text{IO}}$ 比 $t_{\text{mg}}$ 大得多，因此，提高外部排序的效率应主要考虑减少外存信息读写的次数 $d$。

对同一文件而言，进行外部排序时所需读写外存的次数 $d$ 和归并的趟数 $s$ 成正比。一般情况下，对 $m$ 个初始归并段进行 k-路平衡归并时，归并的趟数为

$$
\tag{8-2} s=\lceil\log_k m\rceil
$$

因此，为了减少归并趟数 $s$，可以从以下两个方面进行改进：

1. 增加归并段的个数 $k$
2. 减少初始归并段的个数 $m$

增加归并段的个数可以减少对数据的扫描趟数，这种方法称为“多路平衡归并”。为了减少初始归并段的个数，可以使用“置换-选择”的方法，在扫描一遍的前提下，得到更长的初始归并段。

### 8.7.2 多路平衡归并的实现

对于 k-路平衡归并，设 $u$ 个记录分布在 $k$ 个归并段上，归并后的第一个记录是 $k$ 个归并段中关键字最小的记录，即应从每个归并段的第一个记录中选出最小者，这需要进行 $k-1$ 次比较。同理，每得到归并后的有序段中的一个记录，都要进行 $k-1$ 次比较。为得到含 $u$ 个记录的归并段需进行 $(u-1)(k-1)$ 次比较，由此，对 $n$ 个记录的文件进行外部排序时，在内部归并中进行的总的比较次数为 $s(k-1)(n-1)$。假设初始归并段为 $m$ 个，则由式 $(8\text{-}2)$ 可得内部归并过程中进行比较的总次数为

$$
\tag{8-3} ut_{\text{mg}}=\lceil\log_k m\rceil(k-1)(n-1)t_{\text{mg}}=\Big\lceil\dfrac{\log_2 m}{\log_2 k}\Big\rceil(k-1)(n-1)t_{\text{mg}}
$$

由于 $\dfrac{k-1}{\log_2 k}$ 随 $k$ 的增长而增长，则内部归并时间随 $k$ 的增长而增长，这将抵消由于增大 $k$ 而减少外存读写时间所得的收益。若在进行 k-路平衡归并时利用**败者树**（Tree of Loser），则可使在 $k$ 个记录中选出关键字最小的记录时仅需进行 $\lceil\log_2 k\rceil$ 次比较，从而使总的归并时间变为 $\lceil\log_2 m\rceil(n-1)t_{\text{mg}}$，这个式子与 $k$ 无关，不再随 $k$ 的增长而增长。

败者树是树形选择排序的一种变形。在树形选择排序中，每个非终端结点表示其左、右孩子结点中的“胜者”；反之，若在双亲结点中记下败者，而让胜者去参加更高一层的比赛，便可得到一棵败者树。

例如，图 8.3 所示为一棵实现 5-路平衡归并的败者树。图中方形结点表示叶子结点，分别为 5 个归并段中当前参加归并选择的记录的关键字。根结点`ls[1]`的双亲结点`ls[0]`为冠军，其值为 3，表示各归并段中的最小关键字记录为第 3 段的当前记录（b3）。结点`ls[3]`的值为 2，表示 b1 和 b2 两个叶子结点中的败者为 b2，而胜者 b1 向上继续比较。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE8.3-%E5%AE%9E%E7%8E%B05-%E8%B7%AF%E5%B9%B3%E8%A1%A1%E5%BD%92%E5%B9%B6%E7%9A%84%E8%B4%A5%E8%80%85%E6%A0%91.png">
    <br>
    图 8.3&nbsp;&nbsp;&nbsp;&nbsp;实现 5-路平衡归并的败者树
</div>

在选得最小关键字的记录之后，只要修改叶子结点 b3 中的值，使其为同一归并段中下一个记录的关键字，然后从该结点向上和双亲结点所指的关键字进行比较，败者留在该双亲结点，胜者继续向上直至树根的双亲。

为防止在归并过程中某个归并段变空，可以在每个归并段中附加一个关键字为最大值的记录，当选出的冠军记录的关键字为最大值时，表明此次归并已完成。

由于实现 k-路归并的败者树的深度为 $\lceil\log_2 k\rceil+1$，则在 $k$ 个记录中选择最小关键字仅需进行 $\lceil\log_2 k\rceil$ 次比较。

败者树的初始化：令所有的非终端结点指向一个含最小关键字的叶子结点，然后从各个叶子结点出发调整非终端结点为新的败者。

$k$ 的选择并非越大越好，需要综合考虑。

### 8.7.3 置换-选择排序

**置换-选择排序**（Replacement-Selection Sorting）是在树形选择排序的基础上得来的，它的特点是：在整个排序（得到所有初始归并段）的过程中，选择最小（或最大）关键字和输入、输出交叉或平行进行。

假设初始待排序文件为输入文件 FI，初始归并段文件为输出文件 FO，内存工作区为 WA，FO 和 WA 的初始状态为空，并设内存工作区可容纳 $w$ 个记录，则置换-选择排序的操作过程为：

1. 从 FI 输入 $w$ 个记录到工作区 WA。
2. 从 WA 中选出其中关键字取最小值的记录，记为 MINIMAX 记录。
3. 将 MINIMAX 记录输入到 FO 中。
4. 若 FI 不空，则从 FI 输入下一个记录到 WA 中。
5. 从 WA 中所有关键字比 MINIMAX 记录的关键字大的记录中选出最小关键字记录，作为新的 MINIMAX 记录。
6. 重复 3~5，直至 WA 中选不出新的 MINIMAX 记录为止，由此得到一个初始归并段，输出一个归并段的结束标志到 FO 中。
7. 重复 2~6，直至 WA 为空，由此得到所有初始归并段。

例如，假设初始文件含有 24 个记录，它们的关键字分别为 51,49,39,46,38,29,14,61,15,30,1,48,52,3,63,27,4,13,89,24,46,58,33,76，内存工作区可容纳 6 个记录，则置换-选择的过程如下表所示。

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%BD%AE%E6%8D%A2-%E9%80%89%E6%8B%A9%E7%9A%84%E8%BF%87%E7%A8%8B.png">
</div>

在 WA 中选择 MINIMAX 记录的过程需利用败者树来实现，具体实现细节如下：

1. 内存工作区中的记录作为败者树的外部结点，败者树中根结点的双亲结点指示工作区中关键字最小的记录。
2. 为了便于选出 MINIMAX 记录，为每个记录附设一个所在归并段的序号，在进行关键字的比较时，先比较段号，段号小者为胜者，若段号相同则关键字小的为胜者。
3. 败者树的建立可从设工作区中所有记录的段号均为 0 开始，然后从 FI 逐个输入 $w$ 个记录到工作区时，自上而下调整败者树。由于这些记录的段号为 1，则它们对于 0 段的记录而言均为败者，从而逐个填充到败者树的各结点中去。

内存工作区的存储结构定义如下：

```C{.line-numbers}
typedef struct
{
    RcdType rec; // 记录
    KeyType key; // 关键字
    int rnum; // 所属归并段的段号
} RcdNode, WorkArea[w];

WorkArea wa;
```

利用败者树对前面例子进行置换-选择排序的局部状况如图 8.4 所示。其中 (a)~(g) 为建立败者树并选出最小关键字记录的过程，(h)~(l) 为选出新的 MINIMAX 记录的过程。

<div align="center" style="margin-bottom: 10px">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%BE8.4-%E7%BD%AE%E6%8D%A2-%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%E4%B8%AD%E7%9A%84%E8%B4%A5%E8%80%85%E6%A0%91.png">
    <br>
    图 8.4&nbsp;&nbsp;&nbsp;&nbsp;置换-选择排序中的败者树
</div>

由置换-选择排序所得初始归并段的长度不等。可以证明，当输入文件中记录的关键字为随机数时，所得初始归并段的平均长度为内存工作区大小 $w$ 的两倍。

若不计输入输出的时间，则对 $n$ 个记录的文件而言，生成所有初始归并段所需时间为 $O(n\log_2 w)$。

### 8.7.4 最佳归并树

可以用一棵树表示平衡归并的过程，叶子结点表示初始归并段，这样的树称为**归并树**。若将初始归并段的长度看成是归并树中叶子结点的权，则归并过程的外存读写次数恰好为树的带权路径长度的 2 倍。

有 $n$ 个叶子结点的带权路径长度最短的二叉树称为哈夫曼树。同理，存在有 $n$ 个叶子结点的带权路径长度最短的 k 叉树，也称为哈夫曼树。若对长度不等的 $m$ 个初始归并段，构造一棵哈夫曼树作为归并树，便可使在进行外部归并时的外存读写次数达到最少，这棵归并树称为**最佳归并树**。

对于 k-路平衡归并，当初始归并段的数目不能被 $k$ 整除时，归并树中一定会出现子结点数目小于 $k$ 的非终端结点，此时归并树就不是 k 叉树了。为此，需要附加长度为零的虚段，使归并树仍为 k 叉树。按照哈夫曼树构成的原则，权为零的叶子应离树根最远，因此虚段应设置在第一趟归并过程中。

当 3 叉树中只有度为 3 或 0 的结点时，必有 $n_3=\dfrac{n_0-1}{2}$，其中，$n_3$ 是度为 3 的结点数，$n_0$ 是度为 0 的结点数。由于 $n_3$ 必为整数，则 $(n_0-1)\bmod 2=0$。因此，对 3-路平衡归并而言，只有当初始归并段的个数为偶数时，才需加 1 个虚段。

对 k-路平衡归并而言，若 $(m-1)\bmod(k-1)=0$，则不需要加虚段；否则需附加 $k-(m-1)\bmod(k-1)-1$ 个虚段，第一次归并为 $(m-1)\bmod(k-1)+1$ 路归并。

若按最佳归并树的归并方案进行磁盘归并排序，需在内存建立一张载有归并段的长度和它在磁盘上的物理位置的索引表。

## 8.8 小结

<div align="center">
    <img src="https://raw.githubusercontent.com/zzx-JLU/images_for_markdown/main/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83.png">
</div>
